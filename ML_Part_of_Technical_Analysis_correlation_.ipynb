{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhinav70291/TechnicalAnalysis-for-intra-day-trading/blob/main/ML_Part_of_Technical_Analysis_correlation_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sMBbkr1sy_R",
        "outputId": "28794929-4cf1-4462-b424-a0ec611a5b9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q --upgrade ipywidgets matplotlib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from ipywidgets import interact, SelectMultiple, SelectionRangeSlider\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TBdBBj8o7bH"
      },
      "outputs": [],
      "source": [
        "\n",
        "from scipy.signal import argrelextrema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "UlQ0h6HewQ6q",
        "outputId": "cd763816-48a2-4c60-8042-91b1d141f6a7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "repr_error": "0",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-efab2b85-b51e-4375-8267-dea36378f2ff\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2492</th>\n",
              "      <td>2020-04-28T14:35:00</td>\n",
              "      <td>123.90</td>\n",
              "      <td>124.25</td>\n",
              "      <td>123.7</td>\n",
              "      <td>124.15</td>\n",
              "      <td>289726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2493</th>\n",
              "      <td>2020-04-28T14:45:00</td>\n",
              "      <td>124.15</td>\n",
              "      <td>125.80</td>\n",
              "      <td>124.1</td>\n",
              "      <td>125.80</td>\n",
              "      <td>1706683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2494</th>\n",
              "      <td>2020-04-28T14:55:00</td>\n",
              "      <td>125.80</td>\n",
              "      <td>125.80</td>\n",
              "      <td>125.8</td>\n",
              "      <td>125.80</td>\n",
              "      <td>145240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2495</th>\n",
              "      <td>2020-04-28T15:05:00</td>\n",
              "      <td>125.80</td>\n",
              "      <td>131.50</td>\n",
              "      <td>125.8</td>\n",
              "      <td>130.85</td>\n",
              "      <td>3162404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2496</th>\n",
              "      <td>2020-04-28T15:15:00</td>\n",
              "      <td>130.95</td>\n",
              "      <td>130.95</td>\n",
              "      <td>129.6</td>\n",
              "      <td>129.75</td>\n",
              "      <td>221556</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-efab2b85-b51e-4375-8267-dea36378f2ff')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-efab2b85-b51e-4375-8267-dea36378f2ff button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-efab2b85-b51e-4375-8267-dea36378f2ff');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-48af45a5-14e4-4232-b156-ce441b2c1416\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-48af45a5-14e4-4232-b156-ce441b2c1416')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-48af45a5-14e4-4232-b156-ce441b2c1416 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                     Date    Open    High    Low   Close   Volume\n",
              "2492  2020-04-28T14:35:00  123.90  124.25  123.7  124.15   289726\n",
              "2493  2020-04-28T14:45:00  124.15  125.80  124.1  125.80  1706683\n",
              "2494  2020-04-28T14:55:00  125.80  125.80  125.8  125.80   145240\n",
              "2495  2020-04-28T15:05:00  125.80  131.50  125.8  130.85  3162404\n",
              "2496  2020-04-28T15:15:00  130.95  130.95  129.6  129.75   221556"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df=pd.read_csv(\"/content/Manappuram_10minute.csv\")\n",
        "df.tail(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kccokUZvwTB0"
      },
      "outputs": [],
      "source": [
        "# Converting Date column into datetime dftype\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df.set_index('Date', inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdbGR-Gvw6XJ"
      },
      "source": [
        "# **State the Values you want to consider for this backtesting and technical analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhNt1CUIL9z0"
      },
      "outputs": [],
      "source": [
        "# Initialize a DataFrame to store metrics for each parameter\n",
        "metrics_df = pd.DataFrame(columns=['indicator', 'hit_rate', 'profit_factor', 'sharpe_ratio', 'max_drawdown', 'total_profit', 'profit_percentage', 'avg_win_to_avg_loss_ratio', 'sortino_ratio', 'num_trades'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUbftZqFzmRa"
      },
      "source": [
        "# **Defining ALL indicator functions  here**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NumbTc4Azuzt"
      },
      "outputs": [],
      "source": [
        "# calculates SMA using \"n\" as the rolling window size\n",
        "def ma_calc(df, n):\n",
        "  df[\"sma\"] = df.Close.rolling(window=n).mean()\n",
        "  return df\n",
        "\n",
        "# calculates SMA using \"m\" and \"n\" as the rolling window size\n",
        "def longshort_ma_calc(df, m, n):\n",
        "  df[\"sma_short\"] = df.Close.rolling(window=min(m,n)).mean()\n",
        "  df[\"sma_long\"] = df.Close.rolling(window=max(m,n)).mean()\n",
        "  return df\n",
        "\n",
        "# calculates EMA using \"n\" as the rolling window size\n",
        "def ema_calc(df, n):\n",
        "  df[\"ema\"] = df.Close.ewm(span=n, adjust=False).mean()\n",
        "  return df\n",
        "\n",
        "\n",
        "def longshort_ema_calc(df, m, n):\n",
        "  df[\"ema_short\"] = df.Close.ewm(span=min(m,n), adjust=False).mean()\n",
        "  df[\"ema_long\"] = df.Close.ewm(span=max(m,n), adjust=False).mean()\n",
        "  return df\n",
        "\n",
        "# calculates RSI using \"n\" as the lookback period\n",
        "def rsi_calc(df, n):\n",
        "  df['rsi'] = 100 - (100 / (1 + df['Close'].diff().apply(lambda x: x if x > 0 else 0).rolling(window=n).mean() / df['Close'].diff().apply(lambda x: -x if x < 0 else 0).rolling(window=n).mean()))\n",
        "  return df\n",
        "\n",
        "# calculates OBV\n",
        "def obv_calc(df):\n",
        "  df['obv'] = (np.sign(df['Close'].diff()) * df['Volume']).fillna(0).cumsum()\n",
        "  return df\n",
        "\n",
        "def bb_calc(df, n):\n",
        "  df[\"sma\"] = df.Close.rolling(window=n).mean()\n",
        "  df[\"std\"] = df.Close.rolling(window=n).std()\n",
        "  df[\"upper_bb\"] = df[\"sma\"] + (2 * df[\"std\"])\n",
        "  df[\"lower_bb\"] = df[\"sma\"] - (2 * df[\"std\"])\n",
        "  return df\n",
        "\n",
        "# Volume weighted average price\n",
        "def vwap_calc(df):\n",
        "    df['vwap'] = (df['Volume'] * df['Close']).cumsum() / df['Volume'].cumsum()\n",
        "    return df\n",
        "\n",
        "# Supertrend Indicator\n",
        "def supertrend_calc(df, period, multiplier):\n",
        "    # Calculate basic upper and lower bands\n",
        "    df['hl_avg'] = (df['High'] + df['Low']) / 2\n",
        "    df['range'] = df['High'] - df['Low']\n",
        "    df['upper_band'] = df['hl_avg'] + multiplier * df['range']\n",
        "    df['lower_band'] = df['hl_avg'] - multiplier * df['range']\n",
        "\n",
        "    # Calculate final upper and lower bands\n",
        "    df['upper_band_final'] = np.where((df['upper_band'] < df['upper_band'].shift(1)) | (df['Close'] > df['upper_band'].shift(1)), df['upper_band'], df['upper_band'].shift(1))\n",
        "    df['lower_band_final'] = np.where((df['lower_band'] > df['lower_band'].shift(1)) | (df['Close'] < df['lower_band'].shift(1)), df['lower_band'], df['lower_band'].shift(1))\n",
        "\n",
        "    # Calculate Supertrend\n",
        "    df['supertrend'] = np.where(df['Close'] <= df['upper_band_final'], df['upper_band_final'], df['lower_band_final'])\n",
        "    df['supertrend'] = np.where(df['Close'] >= df['lower_band_final'], df['lower_band_final'], df['supertrend'])\n",
        "\n",
        "    return df\n",
        "\n",
        "# calculates Average Directional Index (ADX)\n",
        "def adx_calc(df, n):\n",
        "    df['hl_diff'] = df['High'] - df['Low']\n",
        "    df['hc_diff'] = abs(df['High'] - df['Close'].shift(1))\n",
        "    df['lc_diff'] = abs(df['Low'] - df['Close'].shift(1))\n",
        "    df['tr'] = df[['hl_diff', 'hc_diff', 'lc_diff']].max(axis=1)\n",
        "    df['+dm'] = np.where((df['High'] > df['High'].shift(1)) & (df['High'] - df['High'].shift(1) > df['Low'].shift(1) - df['Low']), df['High'] - df['High'].shift(1), 0)\n",
        "    df['-dm'] = np.where((df['Low'] < df['Low'].shift(1)) & (df['High'].shift(1) - df['High'] < df['Low'].shift(1) - df['Low']), df['Low'].shift(1) - df['Low'], 0)\n",
        "    df['tr_ema'] = df['tr'].ewm(span=n, adjust=False).mean()\n",
        "    df['+dm_ema'] = df['+dm'].ewm(span=n, adjust=False).mean()\n",
        "    df['-dm_ema'] = df['-dm'].ewm(span=n, adjust=False).mean()\n",
        "    df['+di'] = (df['+dm_ema'] / df['tr_ema']) * 100\n",
        "    df['-di'] = (df['-dm_ema'] / df['tr_ema']) * 100\n",
        "    df['dx'] = (abs(df['+di'] - df['-di']) / (df['+di'] + df['-di'])) * 100\n",
        "    df['adx'] = df['dx'].rolling(window=n).mean()\n",
        "\n",
        "    return df\n",
        "\n",
        "# calculates MACD\n",
        "def macd_calc(df, short_n, long_n, signal_n):\n",
        "    df['ema_short'] = df['Close'].ewm(span=short_n, adjust=False).mean()\n",
        "    df['ema_long'] = df['Close'].ewm(span=long_n, adjust=False).mean()\n",
        "    df['macd_line'] = df['ema_short'] - df['ema_long']\n",
        "    df['signal_line'] = df['macd_line'].ewm(span=signal_n, adjust=False).mean()\n",
        "    df['macd_histogram'] = df['macd_line'] - df['signal_line']\n",
        "\n",
        "    return df\n",
        "\n",
        "def find_extrema(df, n):\n",
        "    df['min'] = df.iloc[argrelextrema(df['Close'].values, np.less_equal, order=n)[0]]['Close']\n",
        "    df['max'] = df.iloc[argrelextrema(df['Close'].values, np.greater_equal, order=n)[0]]['Close']\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JwEWimEszK9"
      },
      "source": [
        "# **Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saJzfeB2pD_B"
      },
      "outputs": [],
      "source": [
        "df=find_extrema(df,16)\n",
        "df=ma_calc(df,524)\n",
        "df=longshort_ma_calc(df,564,4)\n",
        "df=ema_calc(df,63)\n",
        "df=longshort_ema_calc(df,374,5)\n",
        "df=rsi_calc(df,118)\n",
        "df=adx_calc(df,32)\n",
        "\n",
        "# columns_to_drop = ['hl_diff', 'hc_diff', 'lc_diff', 'tr', '+dm', '-dm', 'tr_ema', '+dm_ema', '-dm_ema', '+di', '-di', 'dx']\n",
        "\n",
        "# # Drop the columns\n",
        "# df = df.drop(columns=columns_to_drop)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iSkMBcpp_bd"
      },
      "outputs": [],
      "source": [
        " # Initialize the signal column with hold signals\n",
        "df['true_signal'] = 0\n",
        "\n",
        "# Generate buy signals at local minima\n",
        "df.loc[df['min'].notna(), 'true_signal'] = 1\n",
        "\n",
        "# Generate sell signals at local maxima\n",
        "df.loc[df['max'].notna(), 'true_signal'] = -1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emNZ669yqiNS",
        "outputId": "c7831d75-952b-4e37-f506-fdb0055e25d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              " 0    2390\n",
              " 1      55\n",
              "-1      52\n",
              "Name: true_signal, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.true_signal.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98ul-_8Tqq0y"
      },
      "outputs": [],
      "source": [
        "# As the buy/sell signals themselves are sparse,I'd predict positions instead of signals\n",
        "for day in np.unique(df.index.date):\n",
        "    indices = df[df.index.date == day].index\n",
        "    for i in range(len(indices) - 1):  # subtracting 1 because we're looking ahead by 1 row\n",
        "        if df.loc[indices[i], \"true_signal\"] == 1 and df.loc[indices[i + 1], \"true_signal\"] == 0:\n",
        "            df.loc[indices[i + 1], \"true_signal\"] = 1\n",
        "        elif df.loc[indices[i], \"true_signal\"] == -1 and df.loc[indices[i + 1], \"true_signal\"] == 0:\n",
        "            df.loc[indices[i + 1], \"true_signal\"] = -1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL7XHgvGrNKM",
        "outputId": "d0a8987f-fc57-4d90-c5be-99fbdd0732ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              " 0    971\n",
              "-1    811\n",
              " 1    715\n",
              "Name: true_signal, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.true_signal.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSVqgTNYsBVL"
      },
      "source": [
        "the last position of the data, if at all, one is in position , should be to \"Sell\". but using \"Sell\" position as the last transaction data will be of no use in prediction as the features(indicators) used for prediction do not contain information about the trade being the last trade of the day. \"Sell\" position can be inforced manually also, as a postprocessing, after the ML Model makes it's predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 882
        },
        "id": "IWGeD5LSrPzI",
        "outputId": "b4d8c04e-5b89-4d27-9151-7f7f677ae367"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-9bd96142-a5ff-4375-87cb-78fb5bc2f8d7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "      <th>sma</th>\n",
              "      <th>sma_short</th>\n",
              "      <th>sma_long</th>\n",
              "      <th>...</th>\n",
              "      <th>+dm</th>\n",
              "      <th>-dm</th>\n",
              "      <th>tr_ema</th>\n",
              "      <th>+dm_ema</th>\n",
              "      <th>-dm_ema</th>\n",
              "      <th>+di</th>\n",
              "      <th>-di</th>\n",
              "      <th>dx</th>\n",
              "      <th>adx</th>\n",
              "      <th>true_signal</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-01-21 09:15:00</th>\n",
              "      <td>179.30</td>\n",
              "      <td>180.20</td>\n",
              "      <td>178.25</td>\n",
              "      <td>180.15</td>\n",
              "      <td>173897</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.950000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-21 09:25:00</th>\n",
              "      <td>180.00</td>\n",
              "      <td>181.30</td>\n",
              "      <td>180.00</td>\n",
              "      <td>180.50</td>\n",
              "      <td>175277</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.910606</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.489294</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-21 09:35:00</th>\n",
              "      <td>180.50</td>\n",
              "      <td>181.05</td>\n",
              "      <td>180.25</td>\n",
              "      <td>180.55</td>\n",
              "      <td>110920</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.843297</td>\n",
              "      <td>0.062626</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.397514</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-21 09:45:00</th>\n",
              "      <td>180.55</td>\n",
              "      <td>181.50</td>\n",
              "      <td>180.05</td>\n",
              "      <td>181.35</td>\n",
              "      <td>80456</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>181.35</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>180.6375</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.819460</td>\n",
              "      <td>0.086103</td>\n",
              "      <td>0.012121</td>\n",
              "      <td>4.732362</td>\n",
              "      <td>0.666198</td>\n",
              "      <td>75.319414</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-21 09:55:00</th>\n",
              "      <td>181.35</td>\n",
              "      <td>181.65</td>\n",
              "      <td>181.00</td>\n",
              "      <td>181.30</td>\n",
              "      <td>73996</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>180.9250</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.748584</td>\n",
              "      <td>0.089976</td>\n",
              "      <td>0.011387</td>\n",
              "      <td>5.145648</td>\n",
              "      <td>0.651189</td>\n",
              "      <td>77.532943</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-28 14:35:00</th>\n",
              "      <td>123.90</td>\n",
              "      <td>124.25</td>\n",
              "      <td>123.70</td>\n",
              "      <td>124.15</td>\n",
              "      <td>289726</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>107.540935</td>\n",
              "      <td>123.8500</td>\n",
              "      <td>106.497872</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.773377</td>\n",
              "      <td>0.248342</td>\n",
              "      <td>0.026264</td>\n",
              "      <td>32.111333</td>\n",
              "      <td>3.396051</td>\n",
              "      <td>80.871298</td>\n",
              "      <td>79.639203</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-28 14:45:00</th>\n",
              "      <td>124.15</td>\n",
              "      <td>125.80</td>\n",
              "      <td>124.10</td>\n",
              "      <td>125.80</td>\n",
              "      <td>1706683</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>107.598187</td>\n",
              "      <td>124.3500</td>\n",
              "      <td>106.556915</td>\n",
              "      <td>...</td>\n",
              "      <td>1.55</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.829536</td>\n",
              "      <td>0.327230</td>\n",
              "      <td>0.024673</td>\n",
              "      <td>39.447359</td>\n",
              "      <td>2.974254</td>\n",
              "      <td>85.977650</td>\n",
              "      <td>80.222201</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-28 14:55:00</th>\n",
              "      <td>125.80</td>\n",
              "      <td>125.80</td>\n",
              "      <td>125.80</td>\n",
              "      <td>125.80</td>\n",
              "      <td>145240</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>107.656489</td>\n",
              "      <td>124.8875</td>\n",
              "      <td>106.616046</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.779261</td>\n",
              "      <td>0.307398</td>\n",
              "      <td>0.023177</td>\n",
              "      <td>39.447359</td>\n",
              "      <td>2.974254</td>\n",
              "      <td>85.977650</td>\n",
              "      <td>80.587223</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-28 15:05:00</th>\n",
              "      <td>125.80</td>\n",
              "      <td>131.50</td>\n",
              "      <td>125.80</td>\n",
              "      <td>130.85</td>\n",
              "      <td>3162404</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>130.85</td>\n",
              "      <td>107.724905</td>\n",
              "      <td>126.6500</td>\n",
              "      <td>106.681649</td>\n",
              "      <td>...</td>\n",
              "      <td>5.70</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.077488</td>\n",
              "      <td>0.634222</td>\n",
              "      <td>0.021773</td>\n",
              "      <td>58.861207</td>\n",
              "      <td>2.020675</td>\n",
              "      <td>93.361983</td>\n",
              "      <td>81.142447</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-28 15:15:00</th>\n",
              "      <td>130.95</td>\n",
              "      <td>130.95</td>\n",
              "      <td>129.60</td>\n",
              "      <td>129.75</td>\n",
              "      <td>221556</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>107.791794</td>\n",
              "      <td>128.0500</td>\n",
              "      <td>106.746365</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.094004</td>\n",
              "      <td>0.595785</td>\n",
              "      <td>0.020453</td>\n",
              "      <td>54.459104</td>\n",
              "      <td>1.869553</td>\n",
              "      <td>93.361983</td>\n",
              "      <td>81.697672</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2497 rows × 28 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9bd96142-a5ff-4375-87cb-78fb5bc2f8d7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9bd96142-a5ff-4375-87cb-78fb5bc2f8d7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9bd96142-a5ff-4375-87cb-78fb5bc2f8d7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b8fb38f2-e3f3-4d89-8640-1206c32d2724\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b8fb38f2-e3f3-4d89-8640-1206c32d2724')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b8fb38f2-e3f3-4d89-8640-1206c32d2724 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e6ee604e-45c4-4824-9b4c-eae1c32953f1\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e6ee604e-45c4-4824-9b4c-eae1c32953f1 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                       Open    High     Low   Close   Volume  min     max  \\\n",
              "Date                                                                        \n",
              "2020-01-21 09:15:00  179.30  180.20  178.25  180.15   173897 -1.0   -1.00   \n",
              "2020-01-21 09:25:00  180.00  181.30  180.00  180.50   175277 -1.0   -1.00   \n",
              "2020-01-21 09:35:00  180.50  181.05  180.25  180.55   110920 -1.0   -1.00   \n",
              "2020-01-21 09:45:00  180.55  181.50  180.05  181.35    80456 -1.0  181.35   \n",
              "2020-01-21 09:55:00  181.35  181.65  181.00  181.30    73996 -1.0   -1.00   \n",
              "...                     ...     ...     ...     ...      ...  ...     ...   \n",
              "2020-04-28 14:35:00  123.90  124.25  123.70  124.15   289726 -1.0   -1.00   \n",
              "2020-04-28 14:45:00  124.15  125.80  124.10  125.80  1706683 -1.0   -1.00   \n",
              "2020-04-28 14:55:00  125.80  125.80  125.80  125.80   145240 -1.0   -1.00   \n",
              "2020-04-28 15:05:00  125.80  131.50  125.80  130.85  3162404 -1.0  130.85   \n",
              "2020-04-28 15:15:00  130.95  130.95  129.60  129.75   221556 -1.0   -1.00   \n",
              "\n",
              "                            sma  sma_short    sma_long  ...   +dm  -dm  \\\n",
              "Date                                                    ...              \n",
              "2020-01-21 09:15:00   -1.000000    -1.0000   -1.000000  ...  0.00  0.0   \n",
              "2020-01-21 09:25:00   -1.000000    -1.0000   -1.000000  ...  1.10  0.0   \n",
              "2020-01-21 09:35:00   -1.000000    -1.0000   -1.000000  ...  0.00  0.0   \n",
              "2020-01-21 09:45:00   -1.000000   180.6375   -1.000000  ...  0.45  0.2   \n",
              "2020-01-21 09:55:00   -1.000000   180.9250   -1.000000  ...  0.15  0.0   \n",
              "...                         ...        ...         ...  ...   ...  ...   \n",
              "2020-04-28 14:35:00  107.540935   123.8500  106.497872  ...  0.00  0.0   \n",
              "2020-04-28 14:45:00  107.598187   124.3500  106.556915  ...  1.55  0.0   \n",
              "2020-04-28 14:55:00  107.656489   124.8875  106.616046  ...  0.00  0.0   \n",
              "2020-04-28 15:05:00  107.724905   126.6500  106.681649  ...  5.70  0.0   \n",
              "2020-04-28 15:15:00  107.791794   128.0500  106.746365  ...  0.00  0.0   \n",
              "\n",
              "                       tr_ema   +dm_ema   -dm_ema        +di       -di  \\\n",
              "Date                                                                     \n",
              "2020-01-21 09:15:00  1.950000  0.000000  0.000000   0.000000  0.000000   \n",
              "2020-01-21 09:25:00  1.910606  0.066667  0.000000   3.489294  0.000000   \n",
              "2020-01-21 09:35:00  1.843297  0.062626  0.000000   3.397514  0.000000   \n",
              "2020-01-21 09:45:00  1.819460  0.086103  0.012121   4.732362  0.666198   \n",
              "2020-01-21 09:55:00  1.748584  0.089976  0.011387   5.145648  0.651189   \n",
              "...                       ...       ...       ...        ...       ...   \n",
              "2020-04-28 14:35:00  0.773377  0.248342  0.026264  32.111333  3.396051   \n",
              "2020-04-28 14:45:00  0.829536  0.327230  0.024673  39.447359  2.974254   \n",
              "2020-04-28 14:55:00  0.779261  0.307398  0.023177  39.447359  2.974254   \n",
              "2020-04-28 15:05:00  1.077488  0.634222  0.021773  58.861207  2.020675   \n",
              "2020-04-28 15:15:00  1.094004  0.595785  0.020453  54.459104  1.869553   \n",
              "\n",
              "                             dx        adx  true_signal  \n",
              "Date                                                     \n",
              "2020-01-21 09:15:00   -1.000000  -1.000000            0  \n",
              "2020-01-21 09:25:00  100.000000  -1.000000            0  \n",
              "2020-01-21 09:35:00  100.000000  -1.000000            0  \n",
              "2020-01-21 09:45:00   75.319414  -1.000000           -1  \n",
              "2020-01-21 09:55:00   77.532943  -1.000000           -1  \n",
              "...                         ...        ...          ...  \n",
              "2020-04-28 14:35:00   80.871298  79.639203            0  \n",
              "2020-04-28 14:45:00   85.977650  80.222201            0  \n",
              "2020-04-28 14:55:00   85.977650  80.587223            0  \n",
              "2020-04-28 15:05:00   93.361983  81.142447           -1  \n",
              "2020-04-28 15:15:00   93.361983  81.697672           -1  \n",
              "\n",
              "[2497 rows x 28 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df=df.fillna(-1) # basically replacing all Nan values iwth -1 since ML/DL models do not work with Null data\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2F0xG3qRqif2"
      },
      "source": [
        "# **TRAIN-TEST-SPLIT**\n",
        "A validation set of 10 days and a train set of 55 days should do for this dataset, let's see how it goes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWXrQKTRxk74",
        "outputId": "52a41178-6e77-478d-f540-0e1c3c492e6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'min', 'max', 'sma',\n",
              "       'sma_short', 'sma_long', 'ema', 'ema_short', 'ema_long', 'rsi',\n",
              "       'hl_diff', 'hc_diff', 'lc_diff', 'tr', '+dm', '-dm', 'tr_ema',\n",
              "       '+dm_ema', '-dm_ema', '+di', '-di', 'dx', 'adx', 'true_signal'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3G9xJ4p8yPqJ"
      },
      "outputs": [],
      "source": [
        "df[\"longshort_sma_delta\"]=df[\"sma_long\"]-df[\"sma_short\"]\n",
        "df[\"longshort_ema_delta\"]=df[\"ema_long\"]-df[\"ema_short\"]\n",
        "df[\"Close_sma_delta\"]=df[\"Close\"]-df[\"sma_short\"]\n",
        "df[\"Close_ema_delta\"]=df[\"Close\"]-df[\"ema_short\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGXrhLadyLON"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtmyQBtWssAc"
      },
      "outputs": [],
      "source": [
        "train=df[:38*55]\n",
        "test=df[38*56:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VS5vRmYueTd",
        "outputId": "69cb654f-eb2a-4e59-fb6b-08641ddb047a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "369"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Nomss9duevZ"
      },
      "outputs": [],
      "source": [
        "target=train.true_signal\n",
        "indicators=train.drop([\"true_signal\"],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZqR7TfLwhxK"
      },
      "outputs": [],
      "source": [
        "val_target=test.true_signal\n",
        "val_indicators=test.drop([\"true_signal\"],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Jm6vo5qvAJ9",
        "outputId": "ec4fde4e-0c60-41da-9fdb-29aba2043bf9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              " 0    869\n",
              "-1    651\n",
              " 1    570\n",
              "Name: true_signal, dtype: int64"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ST6nAtv81sam",
        "outputId": "2ca2fc0b-dbfe-4c14-9565-7b8cf25c113f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'min', 'max', 'sma',\n",
              "       'sma_short', 'sma_long', 'ema', 'ema_short', 'ema_long', 'rsi',\n",
              "       'hl_diff', 'hc_diff', 'lc_diff', 'tr', '+dm', '-dm', 'tr_ema',\n",
              "       '+dm_ema', '-dm_ema', '+di', '-di', 'dx', 'adx', 'longshort_sma_delta',\n",
              "       'longshort_ema_delta', 'Close_sma_delta', 'Close_ema_delta'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "indicators.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWHY_sRPvCnJ"
      },
      "outputs": [],
      "source": [
        "# # !pip -q install flaml\n",
        "# from flaml import AutoML\n",
        "# automl = AutoML()\n",
        "# automl.fit(indicators, target, X_val=val_indicators,y_val=val_target,task=\"classification\", max_iter=500,metric='micro_f1',estimator_list=[\"lgbm\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VHQm6ayzlYc"
      },
      "source": [
        "Some more feature engineering is required here:\n",
        "I'd like to introduce these indicators also-\n",
        "\n",
        "1)Body Size\n",
        "\n",
        "2)Upper Shadow\n",
        "\n",
        "3)Lower Shadow\n",
        "\n",
        "4) Candle Direction\n",
        "\n",
        "5) Price Range\n",
        "\n",
        "6)Relative Price/ normalized price : $$\\frac{{\\text{{close}} - \\text{{low}}}}{{\\text{{high}} - \\text{{low}}}}$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sum7L6DbwFtj"
      },
      "outputs": [],
      "source": [
        "# 1) Body Size\n",
        "df['body_size'] = abs(df['Close'] - df['Open'])\n",
        "\n",
        "# 2) Upper Shadow\n",
        "df['upper_shadow'] = df['High'] - df[['Open', 'Close']].max(axis=1)\n",
        "\n",
        "# 3) Lower Shadow\n",
        "df['lower_shadow'] = df[['Open', 'Close']].min(axis=1) - df['Low']\n",
        "\n",
        "# 4) Candle Direction\n",
        "df['candle_direction'] = np.where(df['Close'] >= df['Open'], '1', '-1')\n",
        "\n",
        "# 5) Price Range\n",
        "df['price_range'] = df['High'] - df['Low']\n",
        "\n",
        "# 6) Relative Price / Normalized Price\n",
        "df['relative_price'] = (df['Close'] - df['Low']) / (df['High'] - df['Low'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6e1Mny-IvYgx"
      },
      "outputs": [],
      "source": [
        "df=df.drop([\"Close\",\"Open\",\"High\",\"Low\"],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qofiecp908O4"
      },
      "outputs": [],
      "source": [
        "train=df[:38*55]\n",
        "test=df[38*56:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Qs6zYXg08O5",
        "outputId": "55cc81be-086d-4751-d4c6-8c19dfd56987"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "369"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqGcrJvI08O6"
      },
      "outputs": [],
      "source": [
        "target=train.true_signal\n",
        "indicators=train.drop([\"true_signal\"],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HTPC1FK08O6"
      },
      "outputs": [],
      "source": [
        "val_target=test.true_signal\n",
        "val_indicators=test.drop([\"true_signal\"],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5Klywhe08O7",
        "outputId": "fa7ecd03-bdba-4153-f1ed-f64985baaea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              " 0    869\n",
              "-1    651\n",
              " 1    570\n",
              "Name: true_signal, dtype: int64"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6Xm1EeQ08O7",
        "outputId": "9d9cf6f0-f100-4df9-a741-5f4e9f64d71e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/296.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/296.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.7/296.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h[flaml.automl.logger: 03-18 08:18:15] {1680} INFO - task = classification\n",
            "[flaml.automl.logger: 03-18 08:18:15] {1688} INFO - Data split method: stratified\n",
            "[flaml.automl.logger: 03-18 08:18:15] {1691} INFO - Evaluation method: holdout\n",
            "[flaml.automl.logger: 03-18 08:18:15] {1789} INFO - Minimizing error metric: 1-micro_f1\n",
            "[flaml.automl.logger: 03-18 08:18:15] {1901} INFO - List of ML learners in AutoML Run: ['lgbm']\n",
            "[flaml.automl.logger: 03-18 08:18:15] {2219} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:15] {2345} INFO - Estimated sufficient time budget=10000s. Estimated necessary time budget=10s.\n",
            "[flaml.automl.logger: 03-18 08:18:15] {2392} INFO -  at 0.4s,\testimator lgbm's best error=0.5962,\tbest estimator lgbm's best error=0.5962\n",
            "[flaml.automl.logger: 03-18 08:18:15] {2219} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:15] {2392} INFO -  at 0.5s,\testimator lgbm's best error=0.5962,\tbest estimator lgbm's best error=0.5962\n",
            "[flaml.automl.logger: 03-18 08:18:15] {2219} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:15] {2392} INFO -  at 0.7s,\testimator lgbm's best error=0.5881,\tbest estimator lgbm's best error=0.5881\n",
            "[flaml.automl.logger: 03-18 08:18:15] {2219} INFO - iteration 3, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:16] {2392} INFO -  at 1.2s,\testimator lgbm's best error=0.4797,\tbest estimator lgbm's best error=0.4797\n",
            "[flaml.automl.logger: 03-18 08:18:16] {2219} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:16] {2392} INFO -  at 2.0s,\testimator lgbm's best error=0.4797,\tbest estimator lgbm's best error=0.4797\n",
            "[flaml.automl.logger: 03-18 08:18:16] {2219} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:17] {2392} INFO -  at 2.2s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:18:17] {2219} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:17] {2392} INFO -  at 2.7s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:18:17] {2219} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:17] {2392} INFO -  at 2.9s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:18:17] {2219} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:19] {2392} INFO -  at 4.1s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:18:19] {2219} INFO - iteration 9, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:19] {2392} INFO -  at 4.2s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:18:19] {2219} INFO - iteration 10, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:19] {2392} INFO -  at 4.9s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:18:19] {2219} INFO - iteration 11, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:20] {2392} INFO -  at 5.3s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:18:20] {2219} INFO - iteration 12, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:20] {2392} INFO -  at 5.4s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:18:20] {2219} INFO - iteration 13, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:20] {2392} INFO -  at 5.8s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:18:20] {2219} INFO - iteration 14, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:21] {2392} INFO -  at 6.2s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:18:21] {2219} INFO - iteration 15, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:21] {2392} INFO -  at 6.7s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:18:21] {2219} INFO - iteration 16, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:21] {2392} INFO -  at 6.8s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:18:21] {2219} INFO - iteration 17, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:22] {2392} INFO -  at 7.4s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:18:22] {2219} INFO - iteration 18, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:22] {2392} INFO -  at 8.0s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:18:22] {2219} INFO - iteration 19, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:23] {2392} INFO -  at 8.5s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:18:23] {2219} INFO - iteration 20, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:24] {2392} INFO -  at 9.1s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:18:24] {2219} INFO - iteration 21, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:24] {2392} INFO -  at 9.9s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:18:24] {2219} INFO - iteration 22, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:25] {2392} INFO -  at 10.1s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:18:25] {2219} INFO - iteration 23, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:25] {2392} INFO -  at 10.6s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:18:25] {2219} INFO - iteration 24, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:26] {2392} INFO -  at 11.1s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:26] {2219} INFO - iteration 25, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:27] {2392} INFO -  at 12.3s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:27] {2219} INFO - iteration 26, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:27] {2392} INFO -  at 12.5s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:27] {2219} INFO - iteration 27, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:27] {2392} INFO -  at 12.5s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:27] {2219} INFO - iteration 28, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:27] {2392} INFO -  at 12.6s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:27] {2219} INFO - iteration 29, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:27] {2392} INFO -  at 12.6s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:27] {2219} INFO - iteration 30, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:27] {2392} INFO -  at 12.8s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:27] {2219} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:27] {2392} INFO -  at 12.8s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:27] {2219} INFO - iteration 32, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:27] {2392} INFO -  at 12.9s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:27] {2219} INFO - iteration 33, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:27] {2392} INFO -  at 13.0s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:27] {2219} INFO - iteration 34, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:27] {2392} INFO -  at 13.0s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:27] {2219} INFO - iteration 35, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:28] {2392} INFO -  at 13.1s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:28] {2219} INFO - iteration 36, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:28] {2392} INFO -  at 13.2s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:28] {2219} INFO - iteration 37, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:28] {2392} INFO -  at 13.3s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:28] {2219} INFO - iteration 38, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:28] {2392} INFO -  at 13.3s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:28] {2219} INFO - iteration 39, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:28] {2392} INFO -  at 13.5s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:28] {2219} INFO - iteration 40, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:28] {2392} INFO -  at 13.5s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:28] {2219} INFO - iteration 41, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:28] {2392} INFO -  at 13.6s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:28] {2219} INFO - iteration 42, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:28] {2392} INFO -  at 13.8s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:28] {2219} INFO - iteration 43, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:28] {2392} INFO -  at 13.8s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:28] {2219} INFO - iteration 44, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:28] {2392} INFO -  at 13.9s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:28] {2219} INFO - iteration 45, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:28] {2392} INFO -  at 13.9s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:28] {2219} INFO - iteration 46, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:29] {2392} INFO -  at 14.1s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:29] {2219} INFO - iteration 47, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:29] {2392} INFO -  at 14.2s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:29] {2219} INFO - iteration 48, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:29] {2392} INFO -  at 14.3s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:29] {2219} INFO - iteration 49, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:29] {2392} INFO -  at 14.4s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:29] {2219} INFO - iteration 50, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:29] {2392} INFO -  at 14.6s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:29] {2219} INFO - iteration 51, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:29] {2392} INFO -  at 14.7s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:29] {2219} INFO - iteration 52, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:29] {2392} INFO -  at 14.8s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:29] {2219} INFO - iteration 53, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:29] {2392} INFO -  at 14.9s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:29] {2219} INFO - iteration 54, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:29] {2392} INFO -  at 14.9s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:29] {2219} INFO - iteration 55, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:29] {2392} INFO -  at 15.0s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:29] {2219} INFO - iteration 56, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:29] {2392} INFO -  at 15.1s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:29] {2219} INFO - iteration 57, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:30] {2392} INFO -  at 15.1s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:30] {2219} INFO - iteration 58, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:30] {2392} INFO -  at 15.2s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:30] {2219} INFO - iteration 59, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:30] {2392} INFO -  at 15.2s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:30] {2219} INFO - iteration 60, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:30] {2392} INFO -  at 15.3s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:30] {2219} INFO - iteration 61, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:30] {2392} INFO -  at 15.4s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:30] {2219} INFO - iteration 62, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:30] {2392} INFO -  at 15.5s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:30] {2219} INFO - iteration 63, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:30] {2392} INFO -  at 15.6s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:30] {2219} INFO - iteration 64, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:30] {2392} INFO -  at 15.6s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:30] {2219} INFO - iteration 65, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:30] {2392} INFO -  at 15.7s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:30] {2219} INFO - iteration 66, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:30] {2392} INFO -  at 15.8s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:30] {2219} INFO - iteration 67, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:30] {2392} INFO -  at 15.8s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:30] {2219} INFO - iteration 68, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:30] {2392} INFO -  at 15.9s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:30] {2219} INFO - iteration 69, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:30] {2392} INFO -  at 16.0s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:30] {2219} INFO - iteration 70, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:31] {2392} INFO -  at 16.1s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:31] {2219} INFO - iteration 71, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:31] {2392} INFO -  at 16.1s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:31] {2219} INFO - iteration 72, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:31] {2392} INFO -  at 16.2s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:31] {2219} INFO - iteration 73, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:31] {2392} INFO -  at 16.2s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:31] {2219} INFO - iteration 74, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:31] {2392} INFO -  at 16.3s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:31] {2219} INFO - iteration 75, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:31] {2392} INFO -  at 16.4s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:31] {2219} INFO - iteration 76, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:31] {2392} INFO -  at 16.5s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:31] {2219} INFO - iteration 77, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:31] {2392} INFO -  at 16.5s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:31] {2219} INFO - iteration 78, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:31] {2392} INFO -  at 16.6s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:18:31] {2219} INFO - iteration 79, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:31] {2392} INFO -  at 16.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:18:31] {2219} INFO - iteration 80, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:31] {2392} INFO -  at 16.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:18:31] {2219} INFO - iteration 81, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:32] {2392} INFO -  at 17.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:18:32] {2219} INFO - iteration 82, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:32] {2392} INFO -  at 17.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:18:32] {2219} INFO - iteration 83, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:32] {2392} INFO -  at 17.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:18:32] {2219} INFO - iteration 84, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:32] {2392} INFO -  at 17.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:18:32] {2219} INFO - iteration 85, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:32] {2392} INFO -  at 17.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:18:32] {2219} INFO - iteration 86, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:32] {2392} INFO -  at 17.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:18:32] {2219} INFO - iteration 87, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:32] {2392} INFO -  at 17.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:18:32] {2219} INFO - iteration 88, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:32] {2392} INFO -  at 17.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:18:32] {2219} INFO - iteration 89, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:32] {2392} INFO -  at 17.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:18:32] {2219} INFO - iteration 90, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:32] {2392} INFO -  at 18.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:18:32] {2219} INFO - iteration 91, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:33] {2392} INFO -  at 18.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:18:33] {2219} INFO - iteration 92, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:33] {2392} INFO -  at 18.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:18:33] {2219} INFO - iteration 93, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:33] {2392} INFO -  at 18.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:18:33] {2219} INFO - iteration 94, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:33] {2392} INFO -  at 18.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:18:33] {2219} INFO - iteration 95, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:33] {2392} INFO -  at 18.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:18:33] {2219} INFO - iteration 96, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:33] {2392} INFO -  at 18.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:18:33] {2219} INFO - iteration 97, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:33] {2392} INFO -  at 18.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:18:33] {2219} INFO - iteration 98, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:33] {2392} INFO -  at 18.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:18:33] {2219} INFO - iteration 99, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:33] {2392} INFO -  at 18.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:18:33] {2219} INFO - iteration 100, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:33] {2392} INFO -  at 19.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:18:33] {2219} INFO - iteration 101, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:34] {2392} INFO -  at 19.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:18:34] {2219} INFO - iteration 102, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:34] {2392} INFO -  at 19.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:18:34] {2219} INFO - iteration 103, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:34] {2392} INFO -  at 19.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:18:34] {2219} INFO - iteration 104, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:34] {2392} INFO -  at 19.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:18:34] {2219} INFO - iteration 105, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:34] {2392} INFO -  at 19.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:18:34] {2219} INFO - iteration 106, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:34] {2392} INFO -  at 19.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:18:34] {2219} INFO - iteration 107, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:34] {2392} INFO -  at 19.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:18:34] {2219} INFO - iteration 108, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:35] {2392} INFO -  at 20.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:18:35] {2219} INFO - iteration 109, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:35] {2392} INFO -  at 20.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:35] {2219} INFO - iteration 110, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:35] {2392} INFO -  at 20.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:35] {2219} INFO - iteration 111, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:35] {2392} INFO -  at 20.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:35] {2219} INFO - iteration 112, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:35] {2392} INFO -  at 20.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:35] {2219} INFO - iteration 113, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:35] {2392} INFO -  at 20.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:35] {2219} INFO - iteration 114, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:35] {2392} INFO -  at 20.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:35] {2219} INFO - iteration 115, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:35] {2392} INFO -  at 20.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:35] {2219} INFO - iteration 116, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:35] {2392} INFO -  at 20.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:35] {2219} INFO - iteration 117, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:36] {2392} INFO -  at 21.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:36] {2219} INFO - iteration 118, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:36] {2392} INFO -  at 21.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:36] {2219} INFO - iteration 119, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:36] {2392} INFO -  at 21.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:36] {2219} INFO - iteration 120, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:36] {2392} INFO -  at 21.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:36] {2219} INFO - iteration 121, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:36] {2392} INFO -  at 21.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:36] {2219} INFO - iteration 122, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:36] {2392} INFO -  at 21.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:36] {2219} INFO - iteration 123, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:36] {2392} INFO -  at 21.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:36] {2219} INFO - iteration 124, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:36] {2392} INFO -  at 21.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:36] {2219} INFO - iteration 125, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:36] {2392} INFO -  at 21.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:36] {2219} INFO - iteration 126, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:36] {2392} INFO -  at 21.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:36] {2219} INFO - iteration 127, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:36] {2392} INFO -  at 21.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:36] {2219} INFO - iteration 128, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:36] {2392} INFO -  at 22.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:36] {2219} INFO - iteration 129, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:36] {2392} INFO -  at 22.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:36] {2219} INFO - iteration 130, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:37] {2392} INFO -  at 22.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:37] {2219} INFO - iteration 131, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:37] {2392} INFO -  at 22.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:37] {2219} INFO - iteration 132, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:37] {2392} INFO -  at 22.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:37] {2219} INFO - iteration 133, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:37] {2392} INFO -  at 22.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:37] {2219} INFO - iteration 134, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:37] {2392} INFO -  at 22.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:37] {2219} INFO - iteration 135, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:37] {2392} INFO -  at 22.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:37] {2219} INFO - iteration 136, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:38] {2392} INFO -  at 23.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:38] {2219} INFO - iteration 137, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:38] {2392} INFO -  at 24.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:38] {2219} INFO - iteration 138, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:39] {2392} INFO -  at 24.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:39] {2219} INFO - iteration 139, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:39] {2392} INFO -  at 24.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:39] {2219} INFO - iteration 140, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:39] {2392} INFO -  at 24.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:39] {2219} INFO - iteration 141, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:39] {2392} INFO -  at 24.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:39] {2219} INFO - iteration 142, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:39] {2392} INFO -  at 24.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:39] {2219} INFO - iteration 143, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:39] {2392} INFO -  at 24.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:39] {2219} INFO - iteration 144, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:40] {2392} INFO -  at 25.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:40] {2219} INFO - iteration 145, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:40] {2392} INFO -  at 25.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:40] {2219} INFO - iteration 146, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:40] {2392} INFO -  at 25.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:40] {2219} INFO - iteration 147, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:40] {2392} INFO -  at 25.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:40] {2219} INFO - iteration 148, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:40] {2392} INFO -  at 25.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:40] {2219} INFO - iteration 149, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:40] {2392} INFO -  at 25.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:40] {2219} INFO - iteration 150, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:40] {2392} INFO -  at 25.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:40] {2219} INFO - iteration 151, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:40] {2392} INFO -  at 25.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:40] {2219} INFO - iteration 152, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:40] {2392} INFO -  at 25.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:40] {2219} INFO - iteration 153, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:40] {2392} INFO -  at 25.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:40] {2219} INFO - iteration 154, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:40] {2392} INFO -  at 26.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:40] {2219} INFO - iteration 155, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:41] {2392} INFO -  at 26.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:41] {2219} INFO - iteration 156, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:41] {2392} INFO -  at 26.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:41] {2219} INFO - iteration 157, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:41] {2392} INFO -  at 26.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:41] {2219} INFO - iteration 158, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:41] {2392} INFO -  at 26.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:41] {2219} INFO - iteration 159, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:41] {2392} INFO -  at 26.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:41] {2219} INFO - iteration 160, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:41] {2392} INFO -  at 26.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:41] {2219} INFO - iteration 161, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:41] {2392} INFO -  at 26.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:41] {2219} INFO - iteration 162, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:41] {2392} INFO -  at 26.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:41] {2219} INFO - iteration 163, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:41] {2392} INFO -  at 26.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:41] {2219} INFO - iteration 164, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:41] {2392} INFO -  at 26.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:41] {2219} INFO - iteration 165, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:41] {2392} INFO -  at 27.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:41] {2219} INFO - iteration 166, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:41] {2392} INFO -  at 27.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:41] {2219} INFO - iteration 167, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:42] {2392} INFO -  at 27.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:42] {2219} INFO - iteration 168, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:42] {2392} INFO -  at 27.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:42] {2219} INFO - iteration 169, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:42] {2392} INFO -  at 27.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:42] {2219} INFO - iteration 170, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:42] {2392} INFO -  at 27.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:42] {2219} INFO - iteration 171, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:42] {2392} INFO -  at 27.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:42] {2219} INFO - iteration 172, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:42] {2392} INFO -  at 27.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:42] {2219} INFO - iteration 173, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:42] {2392} INFO -  at 28.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:42] {2219} INFO - iteration 174, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:42] {2392} INFO -  at 28.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:42] {2219} INFO - iteration 175, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:43] {2392} INFO -  at 28.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:43] {2219} INFO - iteration 176, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:43] {2392} INFO -  at 28.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:43] {2219} INFO - iteration 177, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:43] {2392} INFO -  at 28.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:43] {2219} INFO - iteration 178, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:43] {2392} INFO -  at 28.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:43] {2219} INFO - iteration 179, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:43] {2392} INFO -  at 28.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:43] {2219} INFO - iteration 180, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:43] {2392} INFO -  at 28.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:43] {2219} INFO - iteration 181, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:43] {2392} INFO -  at 28.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:43] {2219} INFO - iteration 182, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:43] {2392} INFO -  at 28.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:43] {2219} INFO - iteration 183, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:43] {2392} INFO -  at 28.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:43] {2219} INFO - iteration 184, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:43] {2392} INFO -  at 28.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:43] {2219} INFO - iteration 185, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:43] {2392} INFO -  at 28.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:43] {2219} INFO - iteration 186, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:43] {2392} INFO -  at 28.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:43] {2219} INFO - iteration 187, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:43] {2392} INFO -  at 29.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:43] {2219} INFO - iteration 188, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:44] {2392} INFO -  at 29.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:44] {2219} INFO - iteration 189, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:44] {2392} INFO -  at 29.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:44] {2219} INFO - iteration 190, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:44] {2392} INFO -  at 29.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:44] {2219} INFO - iteration 191, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:44] {2392} INFO -  at 29.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:44] {2219} INFO - iteration 192, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:44] {2392} INFO -  at 29.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:44] {2219} INFO - iteration 193, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:44] {2392} INFO -  at 29.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:44] {2219} INFO - iteration 194, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:44] {2392} INFO -  at 29.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:44] {2219} INFO - iteration 195, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:44] {2392} INFO -  at 29.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:44] {2219} INFO - iteration 196, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:44] {2392} INFO -  at 29.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:44] {2219} INFO - iteration 197, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:44] {2392} INFO -  at 29.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:44] {2219} INFO - iteration 198, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:44] {2392} INFO -  at 29.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:44] {2219} INFO - iteration 199, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:44] {2392} INFO -  at 30.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:44] {2219} INFO - iteration 200, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:45] {2392} INFO -  at 30.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:45] {2219} INFO - iteration 201, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:45] {2392} INFO -  at 30.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:45] {2219} INFO - iteration 202, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:45] {2392} INFO -  at 30.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:45] {2219} INFO - iteration 203, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:45] {2392} INFO -  at 30.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:45] {2219} INFO - iteration 204, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:45] {2392} INFO -  at 30.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:45] {2219} INFO - iteration 205, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:45] {2392} INFO -  at 30.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:45] {2219} INFO - iteration 206, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:45] {2392} INFO -  at 30.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:45] {2219} INFO - iteration 207, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:45] {2392} INFO -  at 30.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:45] {2219} INFO - iteration 208, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:45] {2392} INFO -  at 30.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:45] {2219} INFO - iteration 209, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:45] {2392} INFO -  at 30.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:45] {2219} INFO - iteration 210, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:45] {2392} INFO -  at 30.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:45] {2219} INFO - iteration 211, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:45] {2392} INFO -  at 30.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:45] {2219} INFO - iteration 212, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:45] {2392} INFO -  at 31.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:45] {2219} INFO - iteration 213, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:45] {2392} INFO -  at 31.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:45] {2219} INFO - iteration 214, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:46] {2392} INFO -  at 31.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:46] {2219} INFO - iteration 215, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:46] {2392} INFO -  at 31.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:46] {2219} INFO - iteration 216, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:46] {2392} INFO -  at 31.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:46] {2219} INFO - iteration 217, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:46] {2392} INFO -  at 31.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:46] {2219} INFO - iteration 218, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:46] {2392} INFO -  at 31.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:46] {2219} INFO - iteration 219, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:46] {2392} INFO -  at 31.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:46] {2219} INFO - iteration 220, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:46] {2392} INFO -  at 31.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:46] {2219} INFO - iteration 221, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:46] {2392} INFO -  at 31.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:46] {2219} INFO - iteration 222, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:46] {2392} INFO -  at 31.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:46] {2219} INFO - iteration 223, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:46] {2392} INFO -  at 32.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:46] {2219} INFO - iteration 224, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:46] {2392} INFO -  at 32.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:46] {2219} INFO - iteration 225, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:47] {2392} INFO -  at 32.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:47] {2219} INFO - iteration 226, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:47] {2392} INFO -  at 32.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:47] {2219} INFO - iteration 227, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:47] {2392} INFO -  at 32.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:47] {2219} INFO - iteration 228, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:47] {2392} INFO -  at 32.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:47] {2219} INFO - iteration 229, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:47] {2392} INFO -  at 32.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:47] {2219} INFO - iteration 230, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:47] {2392} INFO -  at 32.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:47] {2219} INFO - iteration 231, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:47] {2392} INFO -  at 32.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:47] {2219} INFO - iteration 232, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:47] {2392} INFO -  at 32.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:47] {2219} INFO - iteration 233, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:47] {2392} INFO -  at 32.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:47] {2219} INFO - iteration 234, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:47] {2392} INFO -  at 32.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:47] {2219} INFO - iteration 235, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:47] {2392} INFO -  at 33.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:47] {2219} INFO - iteration 236, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:48] {2392} INFO -  at 33.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:48] {2219} INFO - iteration 237, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:48] {2392} INFO -  at 33.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:48] {2219} INFO - iteration 238, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:48] {2392} INFO -  at 33.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:48] {2219} INFO - iteration 239, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:48] {2392} INFO -  at 33.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:48] {2219} INFO - iteration 240, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:48] {2392} INFO -  at 33.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:48] {2219} INFO - iteration 241, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:48] {2392} INFO -  at 33.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:48] {2219} INFO - iteration 242, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:48] {2392} INFO -  at 33.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:48] {2219} INFO - iteration 243, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:48] {2392} INFO -  at 33.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:48] {2219} INFO - iteration 244, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:48] {2392} INFO -  at 33.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:48] {2219} INFO - iteration 245, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:48] {2392} INFO -  at 33.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:48] {2219} INFO - iteration 246, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:48] {2392} INFO -  at 33.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:48] {2219} INFO - iteration 247, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:48] {2392} INFO -  at 34.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:48] {2219} INFO - iteration 248, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:48] {2392} INFO -  at 34.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:48] {2219} INFO - iteration 249, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:49] {2392} INFO -  at 34.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:49] {2219} INFO - iteration 250, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:49] {2392} INFO -  at 34.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:49] {2219} INFO - iteration 251, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:49] {2392} INFO -  at 34.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:49] {2219} INFO - iteration 252, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:49] {2392} INFO -  at 34.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:49] {2219} INFO - iteration 253, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:49] {2392} INFO -  at 34.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:49] {2219} INFO - iteration 254, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:50] {2392} INFO -  at 35.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:50] {2219} INFO - iteration 255, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:51] {2392} INFO -  at 36.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:51] {2219} INFO - iteration 256, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:51] {2392} INFO -  at 36.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:51] {2219} INFO - iteration 257, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:51] {2392} INFO -  at 36.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:51] {2219} INFO - iteration 258, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:51] {2392} INFO -  at 36.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:51] {2219} INFO - iteration 259, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:51] {2392} INFO -  at 36.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:51] {2219} INFO - iteration 260, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:51] {2392} INFO -  at 36.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:51] {2219} INFO - iteration 261, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:51] {2392} INFO -  at 37.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:51] {2219} INFO - iteration 262, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:51] {2392} INFO -  at 37.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:51] {2219} INFO - iteration 263, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:52] {2392} INFO -  at 37.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:52] {2219} INFO - iteration 264, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:52] {2392} INFO -  at 37.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:52] {2219} INFO - iteration 265, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:52] {2392} INFO -  at 37.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:52] {2219} INFO - iteration 266, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:52] {2392} INFO -  at 37.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:52] {2219} INFO - iteration 267, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:52] {2392} INFO -  at 37.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:52] {2219} INFO - iteration 268, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:52] {2392} INFO -  at 37.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:52] {2219} INFO - iteration 269, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:52] {2392} INFO -  at 37.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:52] {2219} INFO - iteration 270, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:52] {2392} INFO -  at 37.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:52] {2219} INFO - iteration 271, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:52] {2392} INFO -  at 37.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:52] {2219} INFO - iteration 272, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:52] {2392} INFO -  at 37.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:52] {2219} INFO - iteration 273, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:52] {2392} INFO -  at 38.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:52] {2219} INFO - iteration 274, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:53] {2392} INFO -  at 38.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:53] {2219} INFO - iteration 275, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:53] {2392} INFO -  at 38.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:53] {2219} INFO - iteration 276, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:53] {2392} INFO -  at 38.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:53] {2219} INFO - iteration 277, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:53] {2392} INFO -  at 38.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:53] {2219} INFO - iteration 278, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:53] {2392} INFO -  at 38.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:53] {2219} INFO - iteration 279, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:53] {2392} INFO -  at 38.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:53] {2219} INFO - iteration 280, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:53] {2392} INFO -  at 38.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:53] {2219} INFO - iteration 281, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:53] {2392} INFO -  at 38.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:53] {2219} INFO - iteration 282, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:53] {2392} INFO -  at 38.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:53] {2219} INFO - iteration 283, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:53] {2392} INFO -  at 38.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:53] {2219} INFO - iteration 284, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:53] {2392} INFO -  at 38.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:53] {2219} INFO - iteration 285, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:53] {2392} INFO -  at 38.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:53] {2219} INFO - iteration 286, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:53] {2392} INFO -  at 39.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:53] {2219} INFO - iteration 287, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:54] {2392} INFO -  at 39.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:54] {2219} INFO - iteration 288, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:54] {2392} INFO -  at 39.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:54] {2219} INFO - iteration 289, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:54] {2392} INFO -  at 39.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:54] {2219} INFO - iteration 290, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:54] {2392} INFO -  at 39.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:54] {2219} INFO - iteration 291, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:54] {2392} INFO -  at 39.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:54] {2219} INFO - iteration 292, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:54] {2392} INFO -  at 39.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:54] {2219} INFO - iteration 293, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:54] {2392} INFO -  at 39.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:54] {2219} INFO - iteration 294, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:54] {2392} INFO -  at 39.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:54] {2219} INFO - iteration 295, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:54] {2392} INFO -  at 39.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:54] {2219} INFO - iteration 296, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:54] {2392} INFO -  at 40.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:54] {2219} INFO - iteration 297, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:55] {2392} INFO -  at 40.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:55] {2219} INFO - iteration 298, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:55] {2392} INFO -  at 40.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:55] {2219} INFO - iteration 299, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:55] {2392} INFO -  at 40.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:55] {2219} INFO - iteration 300, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:55] {2392} INFO -  at 40.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:55] {2219} INFO - iteration 301, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:55] {2392} INFO -  at 40.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:55] {2219} INFO - iteration 302, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:55] {2392} INFO -  at 40.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:55] {2219} INFO - iteration 303, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:55] {2392} INFO -  at 40.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:55] {2219} INFO - iteration 304, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:55] {2392} INFO -  at 40.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:55] {2219} INFO - iteration 305, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:55] {2392} INFO -  at 40.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:55] {2219} INFO - iteration 306, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:55] {2392} INFO -  at 40.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:55] {2219} INFO - iteration 307, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:55] {2392} INFO -  at 40.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:55] {2219} INFO - iteration 308, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:55] {2392} INFO -  at 41.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:55] {2219} INFO - iteration 309, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:56] {2392} INFO -  at 41.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:56] {2219} INFO - iteration 310, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:56] {2392} INFO -  at 41.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:56] {2219} INFO - iteration 311, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:56] {2392} INFO -  at 41.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:56] {2219} INFO - iteration 312, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:56] {2392} INFO -  at 41.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:56] {2219} INFO - iteration 313, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:56] {2392} INFO -  at 41.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:56] {2219} INFO - iteration 314, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:56] {2392} INFO -  at 41.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:56] {2219} INFO - iteration 315, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:56] {2392} INFO -  at 41.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:56] {2219} INFO - iteration 316, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:56] {2392} INFO -  at 41.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:56] {2219} INFO - iteration 317, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:56] {2392} INFO -  at 41.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:56] {2219} INFO - iteration 318, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:56] {2392} INFO -  at 41.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:56] {2219} INFO - iteration 319, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:56] {2392} INFO -  at 42.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:56] {2219} INFO - iteration 320, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:57] {2392} INFO -  at 42.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:57] {2219} INFO - iteration 321, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:57] {2392} INFO -  at 42.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:57] {2219} INFO - iteration 322, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:57] {2392} INFO -  at 42.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:57] {2219} INFO - iteration 323, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:57] {2392} INFO -  at 42.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:57] {2219} INFO - iteration 324, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:57] {2392} INFO -  at 42.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:57] {2219} INFO - iteration 325, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:57] {2392} INFO -  at 42.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:57] {2219} INFO - iteration 326, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:57] {2392} INFO -  at 42.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:57] {2219} INFO - iteration 327, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:57] {2392} INFO -  at 42.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:57] {2219} INFO - iteration 328, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:57] {2392} INFO -  at 42.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:57] {2219} INFO - iteration 329, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:57] {2392} INFO -  at 43.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:57] {2219} INFO - iteration 330, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:58] {2392} INFO -  at 43.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:58] {2219} INFO - iteration 331, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:58] {2392} INFO -  at 43.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:58] {2219} INFO - iteration 332, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:58] {2392} INFO -  at 43.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:58] {2219} INFO - iteration 333, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:58] {2392} INFO -  at 43.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:58] {2219} INFO - iteration 334, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:58] {2392} INFO -  at 43.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:58] {2219} INFO - iteration 335, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:58] {2392} INFO -  at 43.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:58] {2219} INFO - iteration 336, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:58] {2392} INFO -  at 43.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:58] {2219} INFO - iteration 337, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:58] {2392} INFO -  at 43.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:58] {2219} INFO - iteration 338, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:58] {2392} INFO -  at 43.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:58] {2219} INFO - iteration 339, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:58] {2392} INFO -  at 43.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:58] {2219} INFO - iteration 340, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:58] {2392} INFO -  at 44.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:58] {2219} INFO - iteration 341, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:59] {2392} INFO -  at 44.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:59] {2219} INFO - iteration 342, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:59] {2392} INFO -  at 44.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:59] {2219} INFO - iteration 343, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:59] {2392} INFO -  at 44.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:59] {2219} INFO - iteration 344, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:59] {2392} INFO -  at 44.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:59] {2219} INFO - iteration 345, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:59] {2392} INFO -  at 44.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:59] {2219} INFO - iteration 346, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:59] {2392} INFO -  at 44.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:59] {2219} INFO - iteration 347, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:59] {2392} INFO -  at 44.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:59] {2219} INFO - iteration 348, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:59] {2392} INFO -  at 44.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:59] {2219} INFO - iteration 349, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:59] {2392} INFO -  at 44.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:59] {2219} INFO - iteration 350, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:59] {2392} INFO -  at 45.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:59] {2219} INFO - iteration 351, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:18:59] {2392} INFO -  at 45.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:18:59] {2219} INFO - iteration 352, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:00] {2392} INFO -  at 45.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:00] {2219} INFO - iteration 353, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:00] {2392} INFO -  at 45.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:00] {2219} INFO - iteration 354, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:00] {2392} INFO -  at 45.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:00] {2219} INFO - iteration 355, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:00] {2392} INFO -  at 45.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:00] {2219} INFO - iteration 356, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:00] {2392} INFO -  at 45.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:00] {2219} INFO - iteration 357, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:00] {2392} INFO -  at 45.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:00] {2219} INFO - iteration 358, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:00] {2392} INFO -  at 45.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:00] {2219} INFO - iteration 359, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:00] {2392} INFO -  at 45.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:00] {2219} INFO - iteration 360, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:00] {2392} INFO -  at 45.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:00] {2219} INFO - iteration 361, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:00] {2392} INFO -  at 45.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:00] {2219} INFO - iteration 362, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:00] {2392} INFO -  at 45.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:00] {2219} INFO - iteration 363, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:00] {2392} INFO -  at 46.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:00] {2219} INFO - iteration 364, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:01] {2392} INFO -  at 46.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:01] {2219} INFO - iteration 365, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:01] {2392} INFO -  at 46.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:01] {2219} INFO - iteration 366, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:01] {2392} INFO -  at 46.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:01] {2219} INFO - iteration 367, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:01] {2392} INFO -  at 46.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:01] {2219} INFO - iteration 368, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:01] {2392} INFO -  at 46.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:01] {2219} INFO - iteration 369, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:01] {2392} INFO -  at 46.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:01] {2219} INFO - iteration 370, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:02] {2392} INFO -  at 47.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:02] {2219} INFO - iteration 371, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:03] {2392} INFO -  at 48.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:03] {2219} INFO - iteration 372, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:03] {2392} INFO -  at 48.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:03] {2219} INFO - iteration 373, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:03] {2392} INFO -  at 48.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:03] {2219} INFO - iteration 374, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:03] {2392} INFO -  at 48.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:03] {2219} INFO - iteration 375, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:03] {2392} INFO -  at 48.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:03] {2219} INFO - iteration 376, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:03] {2392} INFO -  at 48.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:03] {2219} INFO - iteration 377, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:03] {2392} INFO -  at 48.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:03] {2219} INFO - iteration 378, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:03] {2392} INFO -  at 48.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:03] {2219} INFO - iteration 379, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:03] {2392} INFO -  at 48.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:03] {2219} INFO - iteration 380, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:03] {2392} INFO -  at 49.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:03] {2219} INFO - iteration 381, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:03] {2392} INFO -  at 49.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:03] {2219} INFO - iteration 382, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:04] {2392} INFO -  at 49.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:04] {2219} INFO - iteration 383, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:04] {2392} INFO -  at 49.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:04] {2219} INFO - iteration 384, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:04] {2392} INFO -  at 49.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:04] {2219} INFO - iteration 385, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:04] {2392} INFO -  at 49.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:04] {2219} INFO - iteration 386, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:04] {2392} INFO -  at 49.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:04] {2219} INFO - iteration 387, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:04] {2392} INFO -  at 49.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:04] {2219} INFO - iteration 388, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:04] {2392} INFO -  at 49.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:04] {2219} INFO - iteration 389, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:04] {2392} INFO -  at 49.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:04] {2219} INFO - iteration 390, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:04] {2392} INFO -  at 49.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:04] {2219} INFO - iteration 391, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:04] {2392} INFO -  at 49.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:04] {2219} INFO - iteration 392, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:04] {2392} INFO -  at 49.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:04] {2219} INFO - iteration 393, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:04] {2392} INFO -  at 50.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:04] {2219} INFO - iteration 394, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:05] {2392} INFO -  at 50.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:05] {2219} INFO - iteration 395, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:05] {2392} INFO -  at 50.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:05] {2219} INFO - iteration 396, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:05] {2392} INFO -  at 50.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:05] {2219} INFO - iteration 397, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:05] {2392} INFO -  at 50.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:05] {2219} INFO - iteration 398, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:05] {2392} INFO -  at 50.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:05] {2219} INFO - iteration 399, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:05] {2392} INFO -  at 50.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:05] {2219} INFO - iteration 400, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:05] {2392} INFO -  at 50.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:05] {2219} INFO - iteration 401, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:05] {2392} INFO -  at 50.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:05] {2219} INFO - iteration 402, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:05] {2392} INFO -  at 50.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:05] {2219} INFO - iteration 403, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:05] {2392} INFO -  at 50.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:05] {2219} INFO - iteration 404, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:05] {2392} INFO -  at 50.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:05] {2219} INFO - iteration 405, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:05] {2392} INFO -  at 50.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:05] {2219} INFO - iteration 406, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:05] {2392} INFO -  at 51.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:05] {2219} INFO - iteration 407, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:06] {2392} INFO -  at 51.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:06] {2219} INFO - iteration 408, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:06] {2392} INFO -  at 51.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:06] {2219} INFO - iteration 409, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:06] {2392} INFO -  at 51.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:06] {2219} INFO - iteration 410, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:06] {2392} INFO -  at 51.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:06] {2219} INFO - iteration 411, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:06] {2392} INFO -  at 51.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:06] {2219} INFO - iteration 412, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:06] {2392} INFO -  at 51.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:06] {2219} INFO - iteration 413, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:06] {2392} INFO -  at 51.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:06] {2219} INFO - iteration 414, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:06] {2392} INFO -  at 51.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:06] {2219} INFO - iteration 415, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:06] {2392} INFO -  at 51.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:06] {2219} INFO - iteration 416, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:06] {2392} INFO -  at 51.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:06] {2219} INFO - iteration 417, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:06] {2392} INFO -  at 51.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:06] {2219} INFO - iteration 418, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:06] {2392} INFO -  at 51.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:06] {2219} INFO - iteration 419, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:06] {2392} INFO -  at 52.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:06] {2219} INFO - iteration 420, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:06] {2392} INFO -  at 52.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:06] {2219} INFO - iteration 421, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:07] {2392} INFO -  at 52.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:07] {2219} INFO - iteration 422, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:07] {2392} INFO -  at 52.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:07] {2219} INFO - iteration 423, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:07] {2392} INFO -  at 52.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:07] {2219} INFO - iteration 424, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:07] {2392} INFO -  at 52.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:07] {2219} INFO - iteration 425, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:07] {2392} INFO -  at 52.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:07] {2219} INFO - iteration 426, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:07] {2392} INFO -  at 52.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:07] {2219} INFO - iteration 427, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:07] {2392} INFO -  at 52.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:07] {2219} INFO - iteration 428, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:07] {2392} INFO -  at 52.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:07] {2219} INFO - iteration 429, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:07] {2392} INFO -  at 52.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:07] {2219} INFO - iteration 430, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:07] {2392} INFO -  at 52.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:07] {2219} INFO - iteration 431, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:07] {2392} INFO -  at 52.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:07] {2219} INFO - iteration 432, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:07] {2392} INFO -  at 53.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:07] {2219} INFO - iteration 433, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:07] {2392} INFO -  at 53.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:07] {2219} INFO - iteration 434, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:08] {2392} INFO -  at 53.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:08] {2219} INFO - iteration 435, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:08] {2392} INFO -  at 53.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:08] {2219} INFO - iteration 436, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:08] {2392} INFO -  at 53.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:08] {2219} INFO - iteration 437, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:08] {2392} INFO -  at 53.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:08] {2219} INFO - iteration 438, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:08] {2392} INFO -  at 53.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:08] {2219} INFO - iteration 439, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:08] {2392} INFO -  at 53.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:08] {2219} INFO - iteration 440, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:08] {2392} INFO -  at 53.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:08] {2219} INFO - iteration 441, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:08] {2392} INFO -  at 53.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:08] {2219} INFO - iteration 442, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:08] {2392} INFO -  at 53.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:08] {2219} INFO - iteration 443, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:08] {2392} INFO -  at 53.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:08] {2219} INFO - iteration 444, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:08] {2392} INFO -  at 53.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:08] {2219} INFO - iteration 445, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:08] {2392} INFO -  at 54.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:08] {2219} INFO - iteration 446, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:08] {2392} INFO -  at 54.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:08] {2219} INFO - iteration 447, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:09] {2392} INFO -  at 54.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:09] {2219} INFO - iteration 448, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:09] {2392} INFO -  at 54.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:09] {2219} INFO - iteration 449, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:09] {2392} INFO -  at 54.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:09] {2219} INFO - iteration 450, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:09] {2392} INFO -  at 54.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:09] {2219} INFO - iteration 451, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:09] {2392} INFO -  at 54.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:09] {2219} INFO - iteration 452, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:09] {2392} INFO -  at 54.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:09] {2219} INFO - iteration 453, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:09] {2392} INFO -  at 54.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:09] {2219} INFO - iteration 454, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:09] {2392} INFO -  at 54.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:09] {2219} INFO - iteration 455, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:09] {2392} INFO -  at 54.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:09] {2219} INFO - iteration 456, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:09] {2392} INFO -  at 54.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:09] {2219} INFO - iteration 457, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:09] {2392} INFO -  at 54.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:09] {2219} INFO - iteration 458, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:09] {2392} INFO -  at 55.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:09] {2219} INFO - iteration 459, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:09] {2392} INFO -  at 55.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:09] {2219} INFO - iteration 460, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:10] {2392} INFO -  at 55.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:10] {2219} INFO - iteration 461, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:10] {2392} INFO -  at 55.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:10] {2219} INFO - iteration 462, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:10] {2392} INFO -  at 55.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:10] {2219} INFO - iteration 463, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:10] {2392} INFO -  at 55.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:10] {2219} INFO - iteration 464, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:10] {2392} INFO -  at 55.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:10] {2219} INFO - iteration 465, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:10] {2392} INFO -  at 55.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:10] {2219} INFO - iteration 466, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:10] {2392} INFO -  at 55.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:10] {2219} INFO - iteration 467, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:10] {2392} INFO -  at 55.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:10] {2219} INFO - iteration 468, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:10] {2392} INFO -  at 55.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:10] {2219} INFO - iteration 469, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:10] {2392} INFO -  at 55.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:10] {2219} INFO - iteration 470, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:10] {2392} INFO -  at 55.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:10] {2219} INFO - iteration 471, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:10] {2392} INFO -  at 56.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:10] {2219} INFO - iteration 472, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:11] {2392} INFO -  at 56.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:11] {2219} INFO - iteration 473, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:11] {2392} INFO -  at 56.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:11] {2219} INFO - iteration 474, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:11] {2392} INFO -  at 56.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:11] {2219} INFO - iteration 475, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:11] {2392} INFO -  at 56.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:11] {2219} INFO - iteration 476, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:11] {2392} INFO -  at 56.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:11] {2219} INFO - iteration 477, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:11] {2392} INFO -  at 56.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:11] {2219} INFO - iteration 478, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:11] {2392} INFO -  at 56.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:11] {2219} INFO - iteration 479, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:11] {2392} INFO -  at 56.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:11] {2219} INFO - iteration 480, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:11] {2392} INFO -  at 56.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:11] {2219} INFO - iteration 481, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:11] {2392} INFO -  at 56.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:11] {2219} INFO - iteration 482, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:11] {2392} INFO -  at 56.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:11] {2219} INFO - iteration 483, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:11] {2392} INFO -  at 56.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:11] {2219} INFO - iteration 484, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:11] {2392} INFO -  at 56.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:11] {2219} INFO - iteration 485, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:11] {2392} INFO -  at 57.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:11] {2219} INFO - iteration 486, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:12] {2392} INFO -  at 57.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:12] {2219} INFO - iteration 487, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:12] {2392} INFO -  at 57.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:12] {2219} INFO - iteration 488, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:12] {2392} INFO -  at 57.2s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:12] {2219} INFO - iteration 489, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:12] {2392} INFO -  at 57.3s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:12] {2219} INFO - iteration 490, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:12] {2392} INFO -  at 57.4s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:12] {2219} INFO - iteration 491, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:12] {2392} INFO -  at 57.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:12] {2219} INFO - iteration 492, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:12] {2392} INFO -  at 57.5s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:12] {2219} INFO - iteration 493, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:12] {2392} INFO -  at 57.6s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:12] {2219} INFO - iteration 494, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:12] {2392} INFO -  at 57.7s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:12] {2219} INFO - iteration 495, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:12] {2392} INFO -  at 57.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:12] {2219} INFO - iteration 496, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:12] {2392} INFO -  at 57.8s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:12] {2219} INFO - iteration 497, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:12] {2392} INFO -  at 57.9s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:12] {2219} INFO - iteration 498, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:12] {2392} INFO -  at 58.0s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:12] {2219} INFO - iteration 499, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:13] {2392} INFO -  at 58.1s,\testimator lgbm's best error=0.3415,\tbest estimator lgbm's best error=0.3415\n",
            "[flaml.automl.logger: 03-18 08:19:13] {2494} INFO - selected model: LGBMClassifier(colsample_bytree=0.6685857864644198, learning_rate=1.0,\n",
            "               max_bin=511, min_child_samples=4, n_estimators=1, n_jobs=-1,\n",
            "               num_leaves=7, reg_alpha=0.018234205536180596,\n",
            "               reg_lambda=0.05476667543347822, verbose=-1)\n",
            "[flaml.automl.logger: 03-18 08:19:13] {1931} INFO - fit succeeded\n",
            "[flaml.automl.logger: 03-18 08:19:13] {1932} INFO - Time taken to find the best model: 20.243148803710938\n"
          ]
        }
      ],
      "source": [
        "!pip -q install flaml\n",
        "from flaml import AutoML\n",
        "automl = AutoML()\n",
        "automl.fit(indicators, target, X_val=val_indicators,y_val=val_target,task=\"classification\", max_iter=500,metric='micro_f1',estimator_list=[\"lgbm\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gNyH2HM2g1k"
      },
      "source": [
        "no particular increase in f1 score , not a great improvement\n",
        "\n",
        "Remember, each of the iterations is being evaluated on the test set, if it were evaluated on the train set, (which i've tried) , it gives very less error (0.07 ), that means that there is severe overfitting going on here . One thing that we can do, is to use same indicator with multiple values, sma_5, sma_10, sma_15 etc and similar for other indicators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "ytxLqjo37Ti0",
        "outputId": "be2cb61e-979e-4e42-839a-aa8220ddc059"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "repr_error": "0",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-15e0a93d-7ae9-4a4d-baf0-ee79d5b89fc1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2492</th>\n",
              "      <td>2020-04-28T14:35:00</td>\n",
              "      <td>123.90</td>\n",
              "      <td>124.25</td>\n",
              "      <td>123.7</td>\n",
              "      <td>124.15</td>\n",
              "      <td>289726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2493</th>\n",
              "      <td>2020-04-28T14:45:00</td>\n",
              "      <td>124.15</td>\n",
              "      <td>125.80</td>\n",
              "      <td>124.1</td>\n",
              "      <td>125.80</td>\n",
              "      <td>1706683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2494</th>\n",
              "      <td>2020-04-28T14:55:00</td>\n",
              "      <td>125.80</td>\n",
              "      <td>125.80</td>\n",
              "      <td>125.8</td>\n",
              "      <td>125.80</td>\n",
              "      <td>145240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2495</th>\n",
              "      <td>2020-04-28T15:05:00</td>\n",
              "      <td>125.80</td>\n",
              "      <td>131.50</td>\n",
              "      <td>125.8</td>\n",
              "      <td>130.85</td>\n",
              "      <td>3162404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2496</th>\n",
              "      <td>2020-04-28T15:15:00</td>\n",
              "      <td>130.95</td>\n",
              "      <td>130.95</td>\n",
              "      <td>129.6</td>\n",
              "      <td>129.75</td>\n",
              "      <td>221556</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15e0a93d-7ae9-4a4d-baf0-ee79d5b89fc1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-15e0a93d-7ae9-4a4d-baf0-ee79d5b89fc1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-15e0a93d-7ae9-4a4d-baf0-ee79d5b89fc1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-75eb0f9b-20fe-4e5b-9762-f1759e3f38bd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-75eb0f9b-20fe-4e5b-9762-f1759e3f38bd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-75eb0f9b-20fe-4e5b-9762-f1759e3f38bd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                     Date    Open    High    Low   Close   Volume\n",
              "2492  2020-04-28T14:35:00  123.90  124.25  123.7  124.15   289726\n",
              "2493  2020-04-28T14:45:00  124.15  125.80  124.1  125.80  1706683\n",
              "2494  2020-04-28T14:55:00  125.80  125.80  125.8  125.80   145240\n",
              "2495  2020-04-28T15:05:00  125.80  131.50  125.8  130.85  3162404\n",
              "2496  2020-04-28T15:15:00  130.95  130.95  129.6  129.75   221556"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df=pd.read_csv(\"/content/Manappuram_10minute.csv\")\n",
        "df.tail(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4bUbF-E7Ti1"
      },
      "outputs": [],
      "source": [
        "# Converting Date column into datetime dftype\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df.set_index('Date', inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiXgeu8b6JuP"
      },
      "outputs": [],
      "source": [
        "def calculate_indicators(df):\n",
        "    base = 19\n",
        "    for i in range(5, 31, 5):  # This will loop over 5, 10, 15\n",
        "        n = base * i\n",
        "\n",
        "        # Calculate SMA\n",
        "        df[f'sma_{i}'] = df['Close'].rolling(window=n).mean()\n",
        "\n",
        "        # Calculate EMA\n",
        "        df[f'ema_{i}'] = df['Close'].ewm(span=n, adjust=False).mean()\n",
        "\n",
        "        # Calculate RSI\n",
        "        delta = df['Close'].diff()\n",
        "        up, down = delta.copy(), delta.copy()\n",
        "        up[up < 0] = 0\n",
        "        down[down > 0] = 0\n",
        "        avg_gain = up.rolling(window=n).mean()\n",
        "        avg_loss = abs(down.rolling(window=n).mean())\n",
        "        rs = avg_gain / avg_loss\n",
        "        df[f'rsi_{i}'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "    # Calculate long-short SMA and EMA deltas\n",
        "    for i in range(10, 16, 5):  # This will loop over 10, 15\n",
        "        df[f'sma_{i}_5_delta'] = df[f'sma_{i}'] - df['sma_5']\n",
        "        df[f'ema_{i}_5_delta'] = df[f'ema_{i}'] - df['ema_5']\n",
        "\n",
        "    return df\n",
        "\n",
        "def calculate_adx(df):\n",
        "    base = 19\n",
        "    for i in range(5, 31, 5):  # This will loop over 5, 10, 15\n",
        "        n = base * i\n",
        "\n",
        "        # Calculate the components of ADX\n",
        "        df['hl_diff'] = df['High'] - df['Low']\n",
        "        df['hc_diff'] = abs(df['High'] - df['Close'].shift(1))\n",
        "        df['lc_diff'] = abs(df['Low'] - df['Close'].shift(1))\n",
        "        df['tr'] = df[['hl_diff', 'hc_diff', 'lc_diff']].max(axis=1)\n",
        "        df['+dm'] = np.where((df['High'] > df['High'].shift(1)) & (df['High'] - df['High'].shift(1) > df['Low'].shift(1) - df['Low']), df['High'] - df['High'].shift(1), 0)\n",
        "        df['-dm'] = np.where((df['Low'] < df['Low'].shift(1)) & (df['High'].shift(1) - df['High'] < df['Low'].shift(1) - df['Low']), df['Low'].shift(1) - df['Low'], 0)\n",
        "        df['tr_ema'] = df['tr'].ewm(span=n, adjust=False).mean()\n",
        "        df['+dm_ema'] = df['+dm'].ewm(span=n, adjust=False).mean()\n",
        "        df['-dm_ema'] = df['-dm'].ewm(span=n, adjust=False).mean()\n",
        "        df['+di'] = (df['+dm_ema'] / df['tr_ema']) * 100\n",
        "        df['-di'] = (df['-dm_ema'] / df['tr_ema']) * 100\n",
        "        df['dx'] = (abs(df['+di'] - df['-di']) / (df['+di'] + df['-di'])) * 100\n",
        "\n",
        "        # Calculate ADX\n",
        "        df[f'adx_{i}'] = df['dx'].rolling(window=n).mean()\n",
        "\n",
        "    # Drop the intermediate columns\n",
        "    df = df.drop(columns=['hl_diff', 'hc_diff', 'lc_diff', 'tr', '+dm', '-dm', 'tr_ema', '+dm_ema', '-dm_ema', '+di', '-di', 'dx'])\n",
        "\n",
        "    return df\n",
        "\n",
        "def calculate_bollinger_bands(df):\n",
        "    base = 19\n",
        "    for i in range(5, 31, 5):  # This will loop over 5, 10, 15\n",
        "        n = base * i\n",
        "\n",
        "        # Calculate Simple Moving Average (SMA)\n",
        "        df[f'sma_{i}'] = df['Close'].rolling(window=n).mean()\n",
        "\n",
        "        # Calculate Standard Deviation\n",
        "        df[f'std_{i}'] = df['Close'].rolling(window=n).std()\n",
        "\n",
        "        # Calculate Upper Bollinger Band = SMA + 2*std\n",
        "        df[f'upper_bb_{i}'] = df[f'sma_{i}'] + 2*df[f'std_{i}']\n",
        "\n",
        "        # Calculate Lower Bollinger Band = SMA - 2*std\n",
        "        df[f'lower_bb_{i}'] = df[f'sma_{i}'] - 2*df[f'std_{i}']\n",
        "\n",
        "    return df\n",
        "\n",
        "# Candlestick indicators\n",
        "\n",
        "# 1) Body Size\n",
        "df['body_size'] = abs(df['Close'] - df['Open'])\n",
        "\n",
        "# 2) Upper Shadow\n",
        "df['upper_shadow'] = df['High'] - df[['Open', 'Close']].max(axis=1)\n",
        "\n",
        "# 3) Lower Shadow\n",
        "df['lower_shadow'] = df[['Open', 'Close']].min(axis=1) - df['Low']\n",
        "\n",
        "# 4) Candle Direction\n",
        "df['candle_direction'] = np.where(df['Close'] >= df['Open'], '1', '-1')\n",
        "\n",
        "# 5) Price Range\n",
        "df['price_range'] = df['High'] - df['Low']\n",
        "\n",
        "# 6) Relative Price / Normalized Price\n",
        "df['relative_price'] = (df['Close'] - df['Low']) / (df['High'] - df['Low'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-DnN7Ii0-xt"
      },
      "outputs": [],
      "source": [
        "df=calculate_bollinger_bands(df)\n",
        "df=calculate_adx(df)\n",
        "df=calculate_indicators(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sN-ji6S6UhYq"
      },
      "outputs": [],
      "source": [
        "# List of necessary indicators\n",
        "indicators = ['Open', 'High', 'Low', 'Volume', 'body_size', 'upper_shadow',\n",
        "              'lower_shadow', 'candle_direction', 'price_range', 'relative_price',\n",
        "              'sma_5', 'std_5', 'upper_bb_5', 'lower_bb_5', 'sma_10', 'std_10',\n",
        "              'upper_bb_10', 'lower_bb_10', 'sma_15', 'std_15', 'upper_bb_15',\n",
        "              'lower_bb_15', 'sma_20', 'std_20', 'upper_bb_20', 'lower_bb_20',\n",
        "              'sma_25', 'std_25', 'upper_bb_25', 'lower_bb_25', 'sma_30', 'std_30',\n",
        "              'upper_bb_30', 'lower_bb_30', 'adx_5', 'adx_10', 'adx_15', 'adx_20',\n",
        "              'adx_25', 'adx_30', 'ema_5', 'rsi_5', 'ema_10', 'rsi_10', 'ema_15',\n",
        "              'rsi_15', 'ema_20', 'rsi_20', 'ema_25', 'rsi_25', 'ema_30', 'rsi_30']\n",
        "\n",
        "# Calculate delta for each indicator\n",
        "for indicator in indicators:\n",
        "    try:\n",
        "        df[indicator + '_delta'] = df['Close'] - df[indicator]\n",
        "    except:\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "4yFGNxi3UsIV",
        "outputId": "39d7f08d-1bc6-4036-a703-a41616e3b20e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c5a9645d-05b1-42fd-b93f-236a6578e7d7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>body_size</th>\n",
              "      <th>upper_shadow</th>\n",
              "      <th>lower_shadow</th>\n",
              "      <th>candle_direction</th>\n",
              "      <th>price_range</th>\n",
              "      <th>...</th>\n",
              "      <th>ema_10_delta</th>\n",
              "      <th>rsi_10_delta</th>\n",
              "      <th>ema_15_delta</th>\n",
              "      <th>rsi_15_delta</th>\n",
              "      <th>ema_20_delta</th>\n",
              "      <th>rsi_20_delta</th>\n",
              "      <th>ema_25_delta</th>\n",
              "      <th>rsi_25_delta</th>\n",
              "      <th>ema_30_delta</th>\n",
              "      <th>rsi_30_delta</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-01-21 09:15:00</th>\n",
              "      <td>179.30</td>\n",
              "      <td>180.20</td>\n",
              "      <td>178.25</td>\n",
              "      <td>180.15</td>\n",
              "      <td>173897</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.05</td>\n",
              "      <td>1.05</td>\n",
              "      <td>1</td>\n",
              "      <td>1.95</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-21 09:25:00</th>\n",
              "      <td>180.00</td>\n",
              "      <td>181.30</td>\n",
              "      <td>180.00</td>\n",
              "      <td>180.50</td>\n",
              "      <td>175277</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1.30</td>\n",
              "      <td>...</td>\n",
              "      <td>0.346335</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.347552</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.348163</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.348529</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.348774</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-21 09:35:00</th>\n",
              "      <td>180.50</td>\n",
              "      <td>181.05</td>\n",
              "      <td>180.25</td>\n",
              "      <td>180.55</td>\n",
              "      <td>110920</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1</td>\n",
              "      <td>0.80</td>\n",
              "      <td>...</td>\n",
              "      <td>0.392185</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.394772</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.396073</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.396855</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.397377</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-21 09:45:00</th>\n",
              "      <td>180.55</td>\n",
              "      <td>181.50</td>\n",
              "      <td>180.05</td>\n",
              "      <td>181.35</td>\n",
              "      <td>80456</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1</td>\n",
              "      <td>1.45</td>\n",
              "      <td>...</td>\n",
              "      <td>1.179701</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.186417</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.189794</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.191826</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.193183</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-21 09:55:00</th>\n",
              "      <td>181.35</td>\n",
              "      <td>181.65</td>\n",
              "      <td>181.00</td>\n",
              "      <td>181.30</td>\n",
              "      <td>73996</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.30</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.65</td>\n",
              "      <td>...</td>\n",
              "      <td>1.117872</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.128470</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.133811</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.137029</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.139179</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 108 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5a9645d-05b1-42fd-b93f-236a6578e7d7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c5a9645d-05b1-42fd-b93f-236a6578e7d7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c5a9645d-05b1-42fd-b93f-236a6578e7d7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3dc0e201-c3a5-46a6-b041-7fe418e64e4f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3dc0e201-c3a5-46a6-b041-7fe418e64e4f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3dc0e201-c3a5-46a6-b041-7fe418e64e4f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                       Open    High     Low   Close  Volume  body_size  \\\n",
              "Date                                                                     \n",
              "2020-01-21 09:15:00  179.30  180.20  178.25  180.15  173897       0.85   \n",
              "2020-01-21 09:25:00  180.00  181.30  180.00  180.50  175277       0.50   \n",
              "2020-01-21 09:35:00  180.50  181.05  180.25  180.55  110920       0.05   \n",
              "2020-01-21 09:45:00  180.55  181.50  180.05  181.35   80456       0.80   \n",
              "2020-01-21 09:55:00  181.35  181.65  181.00  181.30   73996       0.05   \n",
              "\n",
              "                     upper_shadow  lower_shadow candle_direction  price_range  \\\n",
              "Date                                                                            \n",
              "2020-01-21 09:15:00          0.05          1.05                1         1.95   \n",
              "2020-01-21 09:25:00          0.80          0.00                1         1.30   \n",
              "2020-01-21 09:35:00          0.50          0.25                1         0.80   \n",
              "2020-01-21 09:45:00          0.15          0.50                1         1.45   \n",
              "2020-01-21 09:55:00          0.30          0.30               -1         0.65   \n",
              "\n",
              "                     ...  ema_10_delta  rsi_10_delta  ema_15_delta  \\\n",
              "Date                 ...                                             \n",
              "2020-01-21 09:15:00  ...      0.000000           NaN      0.000000   \n",
              "2020-01-21 09:25:00  ...      0.346335           NaN      0.347552   \n",
              "2020-01-21 09:35:00  ...      0.392185           NaN      0.394772   \n",
              "2020-01-21 09:45:00  ...      1.179701           NaN      1.186417   \n",
              "2020-01-21 09:55:00  ...      1.117872           NaN      1.128470   \n",
              "\n",
              "                     rsi_15_delta  ema_20_delta  rsi_20_delta  ema_25_delta  \\\n",
              "Date                                                                          \n",
              "2020-01-21 09:15:00           NaN      0.000000           NaN      0.000000   \n",
              "2020-01-21 09:25:00           NaN      0.348163           NaN      0.348529   \n",
              "2020-01-21 09:35:00           NaN      0.396073           NaN      0.396855   \n",
              "2020-01-21 09:45:00           NaN      1.189794           NaN      1.191826   \n",
              "2020-01-21 09:55:00           NaN      1.133811           NaN      1.137029   \n",
              "\n",
              "                     rsi_25_delta  ema_30_delta  rsi_30_delta  \n",
              "Date                                                           \n",
              "2020-01-21 09:15:00           NaN      0.000000           NaN  \n",
              "2020-01-21 09:25:00           NaN      0.348774           NaN  \n",
              "2020-01-21 09:35:00           NaN      0.397377           NaN  \n",
              "2020-01-21 09:45:00           NaN      1.193183           NaN  \n",
              "2020-01-21 09:55:00           NaN      1.139179           NaN  \n",
              "\n",
              "[5 rows x 108 columns]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT0V8V8d7eTU",
        "outputId": "aa247e34-61ec-451b-d7ac-4b4842a847a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'body_size', 'upper_shadow',\n",
              "       'lower_shadow', 'candle_direction', 'price_range',\n",
              "       ...\n",
              "       'ema_10_delta', 'rsi_10_delta', 'ema_15_delta', 'rsi_15_delta',\n",
              "       'ema_20_delta', 'rsi_20_delta', 'ema_25_delta', 'rsi_25_delta',\n",
              "       'ema_30_delta', 'rsi_30_delta'],\n",
              "      dtype='object', length=108)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEQ4VzvK8C7k"
      },
      "source": [
        "Calculating delta columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSJd67rc7f5A"
      },
      "outputs": [],
      "source": [
        "# Calculate the difference between short and long term moving averages\n",
        "df['sma_delta_10_5'] = df['sma_10'] - df['sma_5']\n",
        "df['sma_delta_15_5'] = df['sma_15'] - df['sma_5']\n",
        "df['sma_delta_15_10'] = df['sma_15'] - df['sma_10']\n",
        "\n",
        "df['ema_delta_10_5'] = df['ema_10'] - df['ema_5']\n",
        "df['ema_delta_15_5'] = df['ema_15'] - df['ema_5']\n",
        "df['ema_delta_15_10'] = df['ema_15'] - df['ema_10']\n",
        "\n",
        "# Calculate the difference between the close price and the Bollinger Bands\n",
        "df['bb_upper_delta_5'] = df['Close'] - df['upper_bb_5']\n",
        "df['bb_lower_delta_5'] = df['Close'] - df['lower_bb_5']\n",
        "df['bb_upper_delta_10'] = df['Close'] - df['upper_bb_10']\n",
        "df['bb_lower_delta_10'] = df['Close'] - df['lower_bb_10']\n",
        "df['bb_upper_delta_15'] = df['Close'] - df['upper_bb_15']\n",
        "df['bb_lower_delta_15'] = df['Close'] - df['lower_bb_15']\n",
        "\n",
        "# Calculate the difference between consecutive RSI values\n",
        "df['rsi_delta_5'] = df['rsi_5'].diff()\n",
        "df['rsi_delta_10'] = df['rsi_10'].diff()\n",
        "df['rsi_delta_15'] = df['rsi_15'].diff()\n",
        "\n",
        "df=find_extrema(df,16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMPYeimq9Eeh"
      },
      "outputs": [],
      "source": [
        " # Initialize the signal column with hold signals\n",
        "df['true_signal'] = 0\n",
        "\n",
        "# Generate buy signals at local minima\n",
        "df.loc[df['min'].notna(), 'true_signal'] = 1\n",
        "\n",
        "# Generate sell signals at local maxima\n",
        "df.loc[df['max'].notna(), 'true_signal'] = -1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrL9Ryx79Eej"
      },
      "outputs": [],
      "source": [
        "# As the buy/sell signals themselves are sparse,I'd predict positions instead of signals\n",
        "for day in np.unique(df.index.date):\n",
        "    indices = df[df.index.date == day].index\n",
        "    for i in range(len(indices) - 1):  # subtracting 1 because we're looking ahead by 1 row\n",
        "        if df.loc[indices[i], \"true_signal\"] == 1 and df.loc[indices[i + 1], \"true_signal\"] == 0:\n",
        "            df.loc[indices[i + 1], \"true_signal\"] = 1\n",
        "        elif df.loc[indices[i], \"true_signal\"] == -1 and df.loc[indices[i + 1], \"true_signal\"] == 0:\n",
        "            df.loc[indices[i + 1], \"true_signal\"] = -1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-7OVics9Eei",
        "outputId": "3188c9d7-bab9-41ce-887b-c04f1fd40e77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              " 0    971\n",
              "-1    811\n",
              " 1    715\n",
              "Name: true_signal, dtype: int64"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.true_signal.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7BcotaE9iTI"
      },
      "outputs": [],
      "source": [
        "df=df.drop([\"Close\",\"Open\",\"High\",\"Low\"],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrqQTWDU8z4j"
      },
      "outputs": [],
      "source": [
        "train=df[:38*55]\n",
        "test=df[38*56:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JMME0iD8z4k",
        "outputId": "51be8925-a337-4675-d967-57b451ac7810"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "369"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSLvZiNn8z4l"
      },
      "outputs": [],
      "source": [
        "target=train.true_signal\n",
        "indicators=train.drop([\"true_signal\"],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrJfgdTJ8z4m"
      },
      "outputs": [],
      "source": [
        "val_target=test.true_signal\n",
        "val_indicators=test.drop([\"true_signal\"],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogEPgfRG8z4m",
        "outputId": "caca166c-f9c6-4f5d-bd06-3ebee8099b63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              " 0    869\n",
              "-1    651\n",
              " 1    570\n",
              "Name: true_signal, dtype: int64"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        },
        "id": "v27tJzrDSL2b",
        "outputId": "c81cbf9b-cf3f-4817-8422-030727fca8a0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "indicators"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-9343c749-c2a8-4993-b371-a67265a6e4f8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Volume</th>\n",
              "      <th>body_size</th>\n",
              "      <th>upper_shadow</th>\n",
              "      <th>lower_shadow</th>\n",
              "      <th>candle_direction</th>\n",
              "      <th>price_range</th>\n",
              "      <th>relative_price</th>\n",
              "      <th>sma_5</th>\n",
              "      <th>std_5</th>\n",
              "      <th>upper_bb_5</th>\n",
              "      <th>...</th>\n",
              "      <th>bb_lower_delta_5</th>\n",
              "      <th>bb_upper_delta_10</th>\n",
              "      <th>bb_lower_delta_10</th>\n",
              "      <th>bb_upper_delta_15</th>\n",
              "      <th>bb_lower_delta_15</th>\n",
              "      <th>rsi_delta_5</th>\n",
              "      <th>rsi_delta_10</th>\n",
              "      <th>rsi_delta_15</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-01-21 09:15:00</th>\n",
              "      <td>173897</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.05</td>\n",
              "      <td>1.05</td>\n",
              "      <td>1</td>\n",
              "      <td>1.95</td>\n",
              "      <td>0.974359</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-21 09:25:00</th>\n",
              "      <td>175277</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1.30</td>\n",
              "      <td>0.384615</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-21 09:35:00</th>\n",
              "      <td>110920</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-21 09:45:00</th>\n",
              "      <td>80456</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1</td>\n",
              "      <td>1.45</td>\n",
              "      <td>0.896552</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>181.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-21 09:55:00</th>\n",
              "      <td>73996</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.30</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.461538</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-13 10:05:00</th>\n",
              "      <td>297543</td>\n",
              "      <td>0.15</td>\n",
              "      <td>1.20</td>\n",
              "      <td>0.15</td>\n",
              "      <td>1</td>\n",
              "      <td>1.50</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>107.907368</td>\n",
              "      <td>4.237020</td>\n",
              "      <td>116.381408</td>\n",
              "      <td>...</td>\n",
              "      <td>5.866672</td>\n",
              "      <td>-11.213542</td>\n",
              "      <td>19.979858</td>\n",
              "      <td>-8.564646</td>\n",
              "      <td>19.191663</td>\n",
              "      <td>0.304692</td>\n",
              "      <td>-0.188859</td>\n",
              "      <td>1.069314</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-13 10:15:00</th>\n",
              "      <td>129428</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.30</td>\n",
              "      <td>1</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>107.962105</td>\n",
              "      <td>4.168778</td>\n",
              "      <td>116.299661</td>\n",
              "      <td>...</td>\n",
              "      <td>5.725450</td>\n",
              "      <td>-11.208960</td>\n",
              "      <td>19.974223</td>\n",
              "      <td>-8.505183</td>\n",
              "      <td>19.239218</td>\n",
              "      <td>-0.199710</td>\n",
              "      <td>-0.382472</td>\n",
              "      <td>-0.213734</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-13 10:25:00</th>\n",
              "      <td>121791</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>108.006316</td>\n",
              "      <td>4.115010</td>\n",
              "      <td>116.236337</td>\n",
              "      <td>...</td>\n",
              "      <td>5.323705</td>\n",
              "      <td>-11.499984</td>\n",
              "      <td>19.662090</td>\n",
              "      <td>-8.720288</td>\n",
              "      <td>18.977832</td>\n",
              "      <td>-0.596168</td>\n",
              "      <td>0.090801</td>\n",
              "      <td>-0.678898</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-13 10:35:00</th>\n",
              "      <td>211887</td>\n",
              "      <td>1.15</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1.75</td>\n",
              "      <td>0.657143</td>\n",
              "      <td>108.055789</td>\n",
              "      <td>4.065121</td>\n",
              "      <td>116.186031</td>\n",
              "      <td>...</td>\n",
              "      <td>6.374452</td>\n",
              "      <td>-10.350502</td>\n",
              "      <td>20.785238</td>\n",
              "      <td>-7.501315</td>\n",
              "      <td>20.171140</td>\n",
              "      <td>0.290170</td>\n",
              "      <td>0.962118</td>\n",
              "      <td>0.462472</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-13 10:45:00</th>\n",
              "      <td>149106</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.55</td>\n",
              "      <td>1</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>108.099474</td>\n",
              "      <td>4.023610</td>\n",
              "      <td>116.146695</td>\n",
              "      <td>...</td>\n",
              "      <td>6.297747</td>\n",
              "      <td>-10.349931</td>\n",
              "      <td>20.755194</td>\n",
              "      <td>-7.428643</td>\n",
              "      <td>20.212854</td>\n",
              "      <td>-0.319384</td>\n",
              "      <td>0.088302</td>\n",
              "      <td>-0.086896</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2090 rows × 121 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9343c749-c2a8-4993-b371-a67265a6e4f8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9343c749-c2a8-4993-b371-a67265a6e4f8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9343c749-c2a8-4993-b371-a67265a6e4f8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f6a91599-85fe-4d53-8741-453841893919\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f6a91599-85fe-4d53-8741-453841893919')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f6a91599-85fe-4d53-8741-453841893919 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_3de5ee98-d87d-45a1-b0f9-b37b09c9521f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('indicators')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3de5ee98-d87d-45a1-b0f9-b37b09c9521f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('indicators');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                     Volume  body_size  upper_shadow  lower_shadow  \\\n",
              "Date                                                                 \n",
              "2020-01-21 09:15:00  173897       0.85          0.05          1.05   \n",
              "2020-01-21 09:25:00  175277       0.50          0.80          0.00   \n",
              "2020-01-21 09:35:00  110920       0.05          0.50          0.25   \n",
              "2020-01-21 09:45:00   80456       0.80          0.15          0.50   \n",
              "2020-01-21 09:55:00   73996       0.05          0.30          0.30   \n",
              "...                     ...        ...           ...           ...   \n",
              "2020-04-13 10:05:00  297543       0.15          1.20          0.15   \n",
              "2020-04-13 10:15:00  129428       0.05          0.45          0.30   \n",
              "2020-04-13 10:25:00  121791       0.25          0.20          0.25   \n",
              "2020-04-13 10:35:00  211887       1.15          0.60          0.00   \n",
              "2020-04-13 10:45:00  149106       0.10          0.15          0.55   \n",
              "\n",
              "                    candle_direction  price_range  relative_price       sma_5  \\\n",
              "Date                                                                            \n",
              "2020-01-21 09:15:00                1         1.95        0.974359         NaN   \n",
              "2020-01-21 09:25:00                1         1.30        0.384615         NaN   \n",
              "2020-01-21 09:35:00                1         0.80        0.375000         NaN   \n",
              "2020-01-21 09:45:00                1         1.45        0.896552         NaN   \n",
              "2020-01-21 09:55:00               -1         0.65        0.461538         NaN   \n",
              "...                              ...          ...             ...         ...   \n",
              "2020-04-13 10:05:00                1         1.50        0.200000  107.907368   \n",
              "2020-04-13 10:15:00                1         0.80        0.437500  107.962105   \n",
              "2020-04-13 10:25:00               -1         0.70        0.357143  108.006316   \n",
              "2020-04-13 10:35:00                1         1.75        0.657143  108.055789   \n",
              "2020-04-13 10:45:00                1         0.80        0.812500  108.099474   \n",
              "\n",
              "                        std_5  upper_bb_5  ...  bb_lower_delta_5  \\\n",
              "Date                                       ...                     \n",
              "2020-01-21 09:15:00       NaN         NaN  ...               NaN   \n",
              "2020-01-21 09:25:00       NaN         NaN  ...               NaN   \n",
              "2020-01-21 09:35:00       NaN         NaN  ...               NaN   \n",
              "2020-01-21 09:45:00       NaN         NaN  ...               NaN   \n",
              "2020-01-21 09:55:00       NaN         NaN  ...               NaN   \n",
              "...                       ...         ...  ...               ...   \n",
              "2020-04-13 10:05:00  4.237020  116.381408  ...          5.866672   \n",
              "2020-04-13 10:15:00  4.168778  116.299661  ...          5.725450   \n",
              "2020-04-13 10:25:00  4.115010  116.236337  ...          5.323705   \n",
              "2020-04-13 10:35:00  4.065121  116.186031  ...          6.374452   \n",
              "2020-04-13 10:45:00  4.023610  116.146695  ...          6.297747   \n",
              "\n",
              "                     bb_upper_delta_10  bb_lower_delta_10  bb_upper_delta_15  \\\n",
              "Date                                                                           \n",
              "2020-01-21 09:15:00                NaN                NaN                NaN   \n",
              "2020-01-21 09:25:00                NaN                NaN                NaN   \n",
              "2020-01-21 09:35:00                NaN                NaN                NaN   \n",
              "2020-01-21 09:45:00                NaN                NaN                NaN   \n",
              "2020-01-21 09:55:00                NaN                NaN                NaN   \n",
              "...                                ...                ...                ...   \n",
              "2020-04-13 10:05:00         -11.213542          19.979858          -8.564646   \n",
              "2020-04-13 10:15:00         -11.208960          19.974223          -8.505183   \n",
              "2020-04-13 10:25:00         -11.499984          19.662090          -8.720288   \n",
              "2020-04-13 10:35:00         -10.350502          20.785238          -7.501315   \n",
              "2020-04-13 10:45:00         -10.349931          20.755194          -7.428643   \n",
              "\n",
              "                     bb_lower_delta_15  rsi_delta_5  rsi_delta_10  \\\n",
              "Date                                                                \n",
              "2020-01-21 09:15:00                NaN          NaN           NaN   \n",
              "2020-01-21 09:25:00                NaN          NaN           NaN   \n",
              "2020-01-21 09:35:00                NaN          NaN           NaN   \n",
              "2020-01-21 09:45:00                NaN          NaN           NaN   \n",
              "2020-01-21 09:55:00                NaN          NaN           NaN   \n",
              "...                                ...          ...           ...   \n",
              "2020-04-13 10:05:00          19.191663     0.304692     -0.188859   \n",
              "2020-04-13 10:15:00          19.239218    -0.199710     -0.382472   \n",
              "2020-04-13 10:25:00          18.977832    -0.596168      0.090801   \n",
              "2020-04-13 10:35:00          20.171140     0.290170      0.962118   \n",
              "2020-04-13 10:45:00          20.212854    -0.319384      0.088302   \n",
              "\n",
              "                     rsi_delta_15  min     max  \n",
              "Date                                            \n",
              "2020-01-21 09:15:00           NaN  NaN     NaN  \n",
              "2020-01-21 09:25:00           NaN  NaN     NaN  \n",
              "2020-01-21 09:35:00           NaN  NaN     NaN  \n",
              "2020-01-21 09:45:00           NaN  NaN  181.35  \n",
              "2020-01-21 09:55:00           NaN  NaN     NaN  \n",
              "...                           ...  ...     ...  \n",
              "2020-04-13 10:05:00      1.069314  NaN     NaN  \n",
              "2020-04-13 10:15:00     -0.213734  NaN     NaN  \n",
              "2020-04-13 10:25:00     -0.678898  NaN     NaN  \n",
              "2020-04-13 10:35:00      0.462472  NaN     NaN  \n",
              "2020-04-13 10:45:00     -0.086896  NaN     NaN  \n",
              "\n",
              "[2090 rows x 121 columns]"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "indicators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "GUc0LWfVSMxx",
        "outputId": "cc0b5331-e405-4106-f482-cfad6c22b4e6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-37bca608-3263-4602-8391-6975a9014420\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Volume</th>\n",
              "      <th>body_size</th>\n",
              "      <th>upper_shadow</th>\n",
              "      <th>lower_shadow</th>\n",
              "      <th>price_range</th>\n",
              "      <th>relative_price</th>\n",
              "      <th>sma_5</th>\n",
              "      <th>std_5</th>\n",
              "      <th>upper_bb_5</th>\n",
              "      <th>lower_bb_5</th>\n",
              "      <th>...</th>\n",
              "      <th>bb_lower_delta_5</th>\n",
              "      <th>bb_upper_delta_10</th>\n",
              "      <th>bb_lower_delta_10</th>\n",
              "      <th>bb_upper_delta_15</th>\n",
              "      <th>bb_lower_delta_15</th>\n",
              "      <th>rsi_delta_5</th>\n",
              "      <th>rsi_delta_10</th>\n",
              "      <th>rsi_delta_15</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2.090000e+03</td>\n",
              "      <td>2090.000000</td>\n",
              "      <td>2090.000000</td>\n",
              "      <td>2090.000000</td>\n",
              "      <td>2090.000000</td>\n",
              "      <td>2089.000000</td>\n",
              "      <td>1996.000000</td>\n",
              "      <td>1996.000000</td>\n",
              "      <td>1996.000000</td>\n",
              "      <td>1996.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1996.000000</td>\n",
              "      <td>1901.000000</td>\n",
              "      <td>1901.000000</td>\n",
              "      <td>1806.000000</td>\n",
              "      <td>1806.000000</td>\n",
              "      <td>1994.000000</td>\n",
              "      <td>1899.000000</td>\n",
              "      <td>1804.000000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>42.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.366107e+05</td>\n",
              "      <td>0.604019</td>\n",
              "      <td>0.308804</td>\n",
              "      <td>0.304976</td>\n",
              "      <td>1.217799</td>\n",
              "      <td>0.488059</td>\n",
              "      <td>148.057497</td>\n",
              "      <td>3.733102</td>\n",
              "      <td>155.523701</td>\n",
              "      <td>140.591294</td>\n",
              "      <td>...</td>\n",
              "      <td>5.802619</td>\n",
              "      <td>-15.782745</td>\n",
              "      <td>7.829085</td>\n",
              "      <td>-22.462478</td>\n",
              "      <td>9.249027</td>\n",
              "      <td>-0.000967</td>\n",
              "      <td>0.000625</td>\n",
              "      <td>-0.002538</td>\n",
              "      <td>146.477174</td>\n",
              "      <td>153.477381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.646028e+05</td>\n",
              "      <td>0.735147</td>\n",
              "      <td>0.356938</td>\n",
              "      <td>0.393170</td>\n",
              "      <td>0.997896</td>\n",
              "      <td>0.299187</td>\n",
              "      <td>35.354572</td>\n",
              "      <td>2.423437</td>\n",
              "      <td>32.809489</td>\n",
              "      <td>38.345968</td>\n",
              "      <td>...</td>\n",
              "      <td>6.429551</td>\n",
              "      <td>14.916858</td>\n",
              "      <td>8.691123</td>\n",
              "      <td>19.404115</td>\n",
              "      <td>9.973438</td>\n",
              "      <td>1.184498</td>\n",
              "      <td>0.596721</td>\n",
              "      <td>0.391738</td>\n",
              "      <td>37.198318</td>\n",
              "      <td>34.322177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.013000e+03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>85.459474</td>\n",
              "      <td>0.906248</td>\n",
              "      <td>92.425246</td>\n",
              "      <td>72.818410</td>\n",
              "      <td>...</td>\n",
              "      <td>-10.804056</td>\n",
              "      <td>-71.600212</td>\n",
              "      <td>-12.152515</td>\n",
              "      <td>-84.704183</td>\n",
              "      <td>-15.476870</td>\n",
              "      <td>-7.545010</td>\n",
              "      <td>-4.493211</td>\n",
              "      <td>-3.322090</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>85.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.407100e+04</td>\n",
              "      <td>0.150000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>104.907500</td>\n",
              "      <td>1.895916</td>\n",
              "      <td>116.829920</td>\n",
              "      <td>93.503399</td>\n",
              "      <td>...</td>\n",
              "      <td>1.605020</td>\n",
              "      <td>-22.123631</td>\n",
              "      <td>1.595159</td>\n",
              "      <td>-29.508247</td>\n",
              "      <td>1.715990</td>\n",
              "      <td>-0.539917</td>\n",
              "      <td>-0.288483</td>\n",
              "      <td>-0.189216</td>\n",
              "      <td>105.612500</td>\n",
              "      <td>121.450000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.556850e+05</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.475000</td>\n",
              "      <td>164.634211</td>\n",
              "      <td>2.999542</td>\n",
              "      <td>168.858211</td>\n",
              "      <td>160.435665</td>\n",
              "      <td>...</td>\n",
              "      <td>3.907697</td>\n",
              "      <td>-13.655573</td>\n",
              "      <td>5.829042</td>\n",
              "      <td>-18.689312</td>\n",
              "      <td>6.885418</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.009924</td>\n",
              "      <td>163.375000</td>\n",
              "      <td>167.725000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.819530e+05</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>1.450000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>176.477895</td>\n",
              "      <td>5.102265</td>\n",
              "      <td>180.572294</td>\n",
              "      <td>170.171927</td>\n",
              "      <td>...</td>\n",
              "      <td>8.428868</td>\n",
              "      <td>-4.446294</td>\n",
              "      <td>12.116043</td>\n",
              "      <td>-7.063831</td>\n",
              "      <td>16.203196</td>\n",
              "      <td>0.603220</td>\n",
              "      <td>0.279681</td>\n",
              "      <td>0.190045</td>\n",
              "      <td>176.762500</td>\n",
              "      <td>179.512500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.239266e+07</td>\n",
              "      <td>9.500000</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>6.650000</td>\n",
              "      <td>13.450000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>189.210526</td>\n",
              "      <td>13.632513</td>\n",
              "      <td>193.441800</td>\n",
              "      <td>186.225425</td>\n",
              "      <td>...</td>\n",
              "      <td>36.231998</td>\n",
              "      <td>9.607164</td>\n",
              "      <td>41.602836</td>\n",
              "      <td>6.559190</td>\n",
              "      <td>42.916599</td>\n",
              "      <td>7.762635</td>\n",
              "      <td>4.793982</td>\n",
              "      <td>3.010510</td>\n",
              "      <td>187.300000</td>\n",
              "      <td>192.150000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 120 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37bca608-3263-4602-8391-6975a9014420')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-37bca608-3263-4602-8391-6975a9014420 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-37bca608-3263-4602-8391-6975a9014420');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d54a4554-6ba2-42dd-b9a7-393b4e5d7734\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d54a4554-6ba2-42dd-b9a7-393b4e5d7734')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d54a4554-6ba2-42dd-b9a7-393b4e5d7734 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "             Volume    body_size  upper_shadow  lower_shadow  price_range  \\\n",
              "count  2.090000e+03  2090.000000   2090.000000   2090.000000  2090.000000   \n",
              "mean   2.366107e+05     0.604019      0.308804      0.304976     1.217799   \n",
              "std    3.646028e+05     0.735147      0.356938      0.393170     0.997896   \n",
              "min    5.013000e+03     0.000000      0.000000      0.000000     0.000000   \n",
              "25%    8.407100e+04     0.150000      0.100000      0.100000     0.650000   \n",
              "50%    1.556850e+05     0.400000      0.200000      0.200000     0.950000   \n",
              "75%    2.819530e+05     0.750000      0.400000      0.400000     1.450000   \n",
              "max    1.239266e+07     9.500000      4.500000      6.650000    13.450000   \n",
              "\n",
              "       relative_price        sma_5        std_5   upper_bb_5   lower_bb_5  \\\n",
              "count     2089.000000  1996.000000  1996.000000  1996.000000  1996.000000   \n",
              "mean         0.488059   148.057497     3.733102   155.523701   140.591294   \n",
              "std          0.299187    35.354572     2.423437    32.809489    38.345968   \n",
              "min          0.000000    85.459474     0.906248    92.425246    72.818410   \n",
              "25%          0.230769   104.907500     1.895916   116.829920    93.503399   \n",
              "50%          0.475000   164.634211     2.999542   168.858211   160.435665   \n",
              "75%          0.750000   176.477895     5.102265   180.572294   170.171927   \n",
              "max          1.000000   189.210526    13.632513   193.441800   186.225425   \n",
              "\n",
              "       ...  bb_lower_delta_5  bb_upper_delta_10  bb_lower_delta_10  \\\n",
              "count  ...       1996.000000        1901.000000        1901.000000   \n",
              "mean   ...          5.802619         -15.782745           7.829085   \n",
              "std    ...          6.429551          14.916858           8.691123   \n",
              "min    ...        -10.804056         -71.600212         -12.152515   \n",
              "25%    ...          1.605020         -22.123631           1.595159   \n",
              "50%    ...          3.907697         -13.655573           5.829042   \n",
              "75%    ...          8.428868          -4.446294          12.116043   \n",
              "max    ...         36.231998           9.607164          41.602836   \n",
              "\n",
              "       bb_upper_delta_15  bb_lower_delta_15  rsi_delta_5  rsi_delta_10  \\\n",
              "count        1806.000000        1806.000000  1994.000000   1899.000000   \n",
              "mean          -22.462478           9.249027    -0.000967      0.000625   \n",
              "std            19.404115           9.973438     1.184498      0.596721   \n",
              "min           -84.704183         -15.476870    -7.545010     -4.493211   \n",
              "25%           -29.508247           1.715990    -0.539917     -0.288483   \n",
              "50%           -18.689312           6.885418     0.000000      0.000000   \n",
              "75%            -7.063831          16.203196     0.603220      0.279681   \n",
              "max             6.559190          42.916599     7.762635      4.793982   \n",
              "\n",
              "       rsi_delta_15         min         max  \n",
              "count   1804.000000   46.000000   42.000000  \n",
              "mean      -0.002538  146.477174  153.477381  \n",
              "std        0.391738   37.198318   34.322177  \n",
              "min       -3.322090   78.000000   85.500000  \n",
              "25%       -0.189216  105.612500  121.450000  \n",
              "50%       -0.009924  163.375000  167.725000  \n",
              "75%        0.190045  176.762500  179.512500  \n",
              "max        3.010510  187.300000  192.150000  \n",
              "\n",
              "[8 rows x 120 columns]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "indicators.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bL1lVqyqV2c8"
      },
      "outputs": [],
      "source": [
        "# try:\n",
        "#     indicators=np.log(indicators)\n",
        "#     val_indicators=np.log(val_indicators)\n",
        "# except:\n",
        "#     pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgsjjVt48z4n",
        "outputId": "35bf2009-fe50-4823-9935-873d73ffd0af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[flaml.automl.logger: 03-18 08:19:15] {1680} INFO - task = classification\n",
            "[flaml.automl.logger: 03-18 08:19:15] {1688} INFO - Data split method: stratified\n",
            "[flaml.automl.logger: 03-18 08:19:15] {1691} INFO - Evaluation method: holdout\n",
            "[flaml.automl.logger: 03-18 08:19:15] {1789} INFO - Minimizing error metric: 1-micro_f1\n",
            "[flaml.automl.logger: 03-18 08:19:15] {1901} INFO - List of ML learners in AutoML Run: ['lgbm']\n",
            "[flaml.automl.logger: 03-18 08:19:15] {2219} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:15] {2345} INFO - Estimated sufficient time budget=10000s. Estimated necessary time budget=10s.\n",
            "[flaml.automl.logger: 03-18 08:19:15] {2392} INFO -  at 0.9s,\testimator lgbm's best error=0.6287,\tbest estimator lgbm's best error=0.6287\n",
            "[flaml.automl.logger: 03-18 08:19:15] {2219} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:16] {2392} INFO -  at 1.0s,\testimator lgbm's best error=0.6287,\tbest estimator lgbm's best error=0.6287\n",
            "[flaml.automl.logger: 03-18 08:19:16] {2219} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:16] {2392} INFO -  at 1.1s,\testimator lgbm's best error=0.5881,\tbest estimator lgbm's best error=0.5881\n",
            "[flaml.automl.logger: 03-18 08:19:16] {2219} INFO - iteration 3, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:16] {2392} INFO -  at 1.3s,\testimator lgbm's best error=0.5285,\tbest estimator lgbm's best error=0.5285\n",
            "[flaml.automl.logger: 03-18 08:19:16] {2219} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:16] {2392} INFO -  at 1.6s,\testimator lgbm's best error=0.5285,\tbest estimator lgbm's best error=0.5285\n",
            "[flaml.automl.logger: 03-18 08:19:16] {2219} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:16] {2392} INFO -  at 1.7s,\testimator lgbm's best error=0.5285,\tbest estimator lgbm's best error=0.5285\n",
            "[flaml.automl.logger: 03-18 08:19:16] {2219} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:16] {2392} INFO -  at 1.9s,\testimator lgbm's best error=0.4986,\tbest estimator lgbm's best error=0.4986\n",
            "[flaml.automl.logger: 03-18 08:19:16] {2219} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:17] {2392} INFO -  at 2.0s,\testimator lgbm's best error=0.4986,\tbest estimator lgbm's best error=0.4986\n",
            "[flaml.automl.logger: 03-18 08:19:17] {2219} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:17] {2392} INFO -  at 2.4s,\testimator lgbm's best error=0.4986,\tbest estimator lgbm's best error=0.4986\n",
            "[flaml.automl.logger: 03-18 08:19:17] {2219} INFO - iteration 9, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:17] {2392} INFO -  at 2.5s,\testimator lgbm's best error=0.4986,\tbest estimator lgbm's best error=0.4986\n",
            "[flaml.automl.logger: 03-18 08:19:17] {2219} INFO - iteration 10, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:18] {2392} INFO -  at 3.3s,\testimator lgbm's best error=0.4986,\tbest estimator lgbm's best error=0.4986\n",
            "[flaml.automl.logger: 03-18 08:19:18] {2219} INFO - iteration 11, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:18] {2392} INFO -  at 3.5s,\testimator lgbm's best error=0.4986,\tbest estimator lgbm's best error=0.4986\n",
            "[flaml.automl.logger: 03-18 08:19:18] {2219} INFO - iteration 12, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:18] {2392} INFO -  at 3.6s,\testimator lgbm's best error=0.4986,\tbest estimator lgbm's best error=0.4986\n",
            "[flaml.automl.logger: 03-18 08:19:18] {2219} INFO - iteration 13, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:18] {2392} INFO -  at 3.8s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:18] {2219} INFO - iteration 14, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:19] {2392} INFO -  at 4.4s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:19] {2219} INFO - iteration 15, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:19] {2392} INFO -  at 4.8s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:19] {2219} INFO - iteration 16, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:20] {2392} INFO -  at 5.0s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:20] {2219} INFO - iteration 17, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:20] {2392} INFO -  at 5.4s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:20] {2219} INFO - iteration 18, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:20] {2392} INFO -  at 5.5s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:20] {2219} INFO - iteration 19, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:20] {2392} INFO -  at 5.7s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:20] {2219} INFO - iteration 20, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:21] {2392} INFO -  at 6.0s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:21] {2219} INFO - iteration 21, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:21] {2392} INFO -  at 6.4s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:21] {2219} INFO - iteration 22, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:21] {2392} INFO -  at 6.6s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:21] {2219} INFO - iteration 23, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:21] {2392} INFO -  at 6.8s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:21] {2219} INFO - iteration 24, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:22] {2392} INFO -  at 7.1s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:22] {2219} INFO - iteration 25, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:24] {2392} INFO -  at 9.1s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:24] {2219} INFO - iteration 26, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:27] {2392} INFO -  at 12.0s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:27] {2219} INFO - iteration 27, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:30] {2392} INFO -  at 15.4s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:30] {2219} INFO - iteration 28, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:31] {2392} INFO -  at 16.7s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:31] {2219} INFO - iteration 29, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:33] {2392} INFO -  at 18.5s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:33] {2219} INFO - iteration 30, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:41] {2392} INFO -  at 26.4s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:41] {2219} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:43] {2392} INFO -  at 28.0s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:43] {2219} INFO - iteration 32, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:45] {2392} INFO -  at 30.3s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:45] {2219} INFO - iteration 33, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:47] {2392} INFO -  at 32.0s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:47] {2219} INFO - iteration 34, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:49] {2392} INFO -  at 34.8s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:49] {2219} INFO - iteration 35, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:50] {2392} INFO -  at 35.3s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:50] {2219} INFO - iteration 36, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:50] {2392} INFO -  at 35.5s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:50] {2219} INFO - iteration 37, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:50] {2392} INFO -  at 35.7s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:50] {2219} INFO - iteration 38, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:50] {2392} INFO -  at 35.9s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:50] {2219} INFO - iteration 39, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:53] {2392} INFO -  at 38.2s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:53] {2219} INFO - iteration 40, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:53] {2392} INFO -  at 38.6s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:53] {2219} INFO - iteration 41, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:53] {2392} INFO -  at 38.7s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:53] {2219} INFO - iteration 42, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:54] {2392} INFO -  at 39.3s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:54] {2219} INFO - iteration 43, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:54] {2392} INFO -  at 39.7s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:54] {2219} INFO - iteration 44, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:54] {2392} INFO -  at 39.8s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:54] {2219} INFO - iteration 45, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:55] {2392} INFO -  at 40.0s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:55] {2219} INFO - iteration 46, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:55] {2392} INFO -  at 40.7s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:55] {2219} INFO - iteration 47, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:55] {2392} INFO -  at 40.8s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:55] {2219} INFO - iteration 48, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:56] {2392} INFO -  at 41.6s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:56] {2219} INFO - iteration 49, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:56] {2392} INFO -  at 41.7s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:56] {2219} INFO - iteration 50, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:57] {2392} INFO -  at 42.8s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:57] {2219} INFO - iteration 51, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:58] {2392} INFO -  at 43.4s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:58] {2219} INFO - iteration 52, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:58] {2392} INFO -  at 43.6s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:58] {2219} INFO - iteration 53, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:59] {2392} INFO -  at 44.2s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:59] {2219} INFO - iteration 54, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:59] {2392} INFO -  at 44.3s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:59] {2219} INFO - iteration 55, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:19:59] {2392} INFO -  at 44.7s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:19:59] {2219} INFO - iteration 56, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:00] {2392} INFO -  at 45.0s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:00] {2219} INFO - iteration 57, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:00] {2392} INFO -  at 45.2s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:00] {2219} INFO - iteration 58, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:00] {2392} INFO -  at 45.4s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:00] {2219} INFO - iteration 59, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:00] {2392} INFO -  at 45.6s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:00] {2219} INFO - iteration 60, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:01] {2392} INFO -  at 46.1s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:01] {2219} INFO - iteration 61, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:01] {2392} INFO -  at 46.7s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:01] {2219} INFO - iteration 62, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:01] {2392} INFO -  at 46.9s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:01] {2219} INFO - iteration 63, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:02] {2392} INFO -  at 47.3s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:02] {2219} INFO - iteration 64, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:02] {2392} INFO -  at 47.5s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:02] {2219} INFO - iteration 65, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:02] {2392} INFO -  at 47.6s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:02] {2219} INFO - iteration 66, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:03] {2392} INFO -  at 47.9s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:03] {2219} INFO - iteration 67, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:03] {2392} INFO -  at 48.1s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:03] {2219} INFO - iteration 68, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:03] {2392} INFO -  at 48.5s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:03] {2219} INFO - iteration 69, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:05] {2392} INFO -  at 50.7s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:05] {2219} INFO - iteration 70, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:05] {2392} INFO -  at 50.9s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:05] {2219} INFO - iteration 71, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:06] {2392} INFO -  at 51.6s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:06] {2219} INFO - iteration 72, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:08] {2392} INFO -  at 53.6s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:08] {2219} INFO - iteration 73, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:11] {2392} INFO -  at 56.1s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:11] {2219} INFO - iteration 74, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:13] {2392} INFO -  at 58.3s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:13] {2219} INFO - iteration 75, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:13] {2392} INFO -  at 58.6s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:13] {2219} INFO - iteration 76, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:13] {2392} INFO -  at 58.8s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:13] {2219} INFO - iteration 77, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:13] {2392} INFO -  at 58.9s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:13] {2219} INFO - iteration 78, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:14] {2392} INFO -  at 59.5s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:14] {2219} INFO - iteration 79, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:14] {2392} INFO -  at 59.8s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:14] {2219} INFO - iteration 80, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:15] {2392} INFO -  at 60.0s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:15] {2219} INFO - iteration 81, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:17] {2392} INFO -  at 62.1s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:17] {2219} INFO - iteration 82, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:17] {2392} INFO -  at 62.4s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:17] {2219} INFO - iteration 83, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:17] {2392} INFO -  at 62.6s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:17] {2219} INFO - iteration 84, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:17] {2392} INFO -  at 62.9s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:17] {2219} INFO - iteration 85, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:18] {2392} INFO -  at 63.0s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:18] {2219} INFO - iteration 86, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:18] {2392} INFO -  at 63.5s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:18] {2219} INFO - iteration 87, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:18] {2392} INFO -  at 63.8s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:18] {2219} INFO - iteration 88, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:19] {2392} INFO -  at 64.0s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:19] {2219} INFO - iteration 89, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:19] {2392} INFO -  at 64.1s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:19] {2219} INFO - iteration 90, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:19] {2392} INFO -  at 64.4s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:19] {2219} INFO - iteration 91, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:19] {2392} INFO -  at 64.6s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:19] {2219} INFO - iteration 92, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:20] {2392} INFO -  at 65.0s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:20] {2219} INFO - iteration 93, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:20] {2392} INFO -  at 65.1s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:20] {2219} INFO - iteration 94, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:20] {2392} INFO -  at 65.5s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:20] {2219} INFO - iteration 95, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:20] {2392} INFO -  at 65.9s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:20] {2219} INFO - iteration 96, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:21] {2392} INFO -  at 66.1s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:21] {2219} INFO - iteration 97, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:21] {2392} INFO -  at 66.3s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:21] {2219} INFO - iteration 98, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:21] {2392} INFO -  at 66.6s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:21] {2219} INFO - iteration 99, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:21] {2392} INFO -  at 66.8s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:21] {2219} INFO - iteration 100, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:22] {2392} INFO -  at 67.0s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:22] {2219} INFO - iteration 101, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:22] {2392} INFO -  at 67.2s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:22] {2219} INFO - iteration 102, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:22] {2392} INFO -  at 67.4s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:22] {2219} INFO - iteration 103, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:22] {2392} INFO -  at 67.6s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:22] {2219} INFO - iteration 104, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:22] {2392} INFO -  at 67.7s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:22] {2219} INFO - iteration 105, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:23] {2392} INFO -  at 68.2s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:23] {2219} INFO - iteration 106, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:23] {2392} INFO -  at 68.3s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:23] {2219} INFO - iteration 107, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:23] {2392} INFO -  at 68.5s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:23] {2219} INFO - iteration 108, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:24] {2392} INFO -  at 69.0s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:24] {2219} INFO - iteration 109, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:24] {2392} INFO -  at 69.2s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:24] {2219} INFO - iteration 110, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:24] {2392} INFO -  at 69.5s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:24] {2219} INFO - iteration 111, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:25] {2392} INFO -  at 70.2s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:25] {2219} INFO - iteration 112, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:25] {2392} INFO -  at 70.4s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:25] {2219} INFO - iteration 113, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:25] {2392} INFO -  at 70.6s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:25] {2219} INFO - iteration 114, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:25] {2392} INFO -  at 70.9s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:25] {2219} INFO - iteration 115, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:26] {2392} INFO -  at 71.0s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:26] {2219} INFO - iteration 116, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:26] {2392} INFO -  at 71.5s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:26] {2219} INFO - iteration 117, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:27] {2392} INFO -  at 72.3s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:27] {2219} INFO - iteration 118, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:27] {2392} INFO -  at 72.6s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:27] {2219} INFO - iteration 119, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:29] {2392} INFO -  at 74.4s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:29] {2219} INFO - iteration 120, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:29] {2392} INFO -  at 74.6s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:29] {2219} INFO - iteration 121, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:29] {2392} INFO -  at 74.9s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:29] {2219} INFO - iteration 122, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:30] {2392} INFO -  at 75.1s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:30] {2219} INFO - iteration 123, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:30] {2392} INFO -  at 75.4s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:30] {2219} INFO - iteration 124, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:30] {2392} INFO -  at 75.7s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:30] {2219} INFO - iteration 125, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:30] {2392} INFO -  at 75.9s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:30] {2219} INFO - iteration 126, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:31] {2392} INFO -  at 76.3s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:31] {2219} INFO - iteration 127, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:31] {2392} INFO -  at 76.9s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:31] {2219} INFO - iteration 128, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:32] {2392} INFO -  at 77.0s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:32] {2219} INFO - iteration 129, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:32] {2392} INFO -  at 77.2s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:32] {2219} INFO - iteration 130, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:32] {2392} INFO -  at 77.4s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:32] {2219} INFO - iteration 131, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:32] {2392} INFO -  at 77.5s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:32] {2219} INFO - iteration 132, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:32] {2392} INFO -  at 77.8s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:32] {2219} INFO - iteration 133, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:33] {2392} INFO -  at 78.4s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:33] {2219} INFO - iteration 134, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:33] {2392} INFO -  at 78.5s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:33] {2219} INFO - iteration 135, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:33] {2392} INFO -  at 78.6s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:33] {2219} INFO - iteration 136, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:33] {2392} INFO -  at 78.9s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:33] {2219} INFO - iteration 137, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:34] {2392} INFO -  at 79.3s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:34] {2219} INFO - iteration 138, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:34] {2392} INFO -  at 79.4s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:34] {2219} INFO - iteration 139, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:34] {2392} INFO -  at 79.6s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:34] {2219} INFO - iteration 140, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:35] {2392} INFO -  at 80.3s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:35] {2219} INFO - iteration 141, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:35] {2392} INFO -  at 80.4s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:35] {2219} INFO - iteration 142, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:35] {2392} INFO -  at 80.9s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:35] {2219} INFO - iteration 143, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:36] {2392} INFO -  at 81.0s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:36] {2219} INFO - iteration 144, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:36] {2392} INFO -  at 81.6s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:36] {2219} INFO - iteration 145, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:36] {2392} INFO -  at 81.7s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:36] {2219} INFO - iteration 146, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:37] {2392} INFO -  at 82.4s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:37] {2219} INFO - iteration 147, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:37] {2392} INFO -  at 82.6s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:37] {2219} INFO - iteration 148, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:37] {2392} INFO -  at 82.8s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:37] {2219} INFO - iteration 149, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:38] {2392} INFO -  at 83.0s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:38] {2219} INFO - iteration 150, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:38] {2392} INFO -  at 83.4s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:38] {2219} INFO - iteration 151, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:38] {2392} INFO -  at 83.8s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:38] {2219} INFO - iteration 152, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:39] {2392} INFO -  at 84.0s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:39] {2219} INFO - iteration 153, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:39] {2392} INFO -  at 84.1s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:39] {2219} INFO - iteration 154, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:40] {2392} INFO -  at 85.9s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:40] {2219} INFO - iteration 155, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:41] {2392} INFO -  at 86.7s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:41] {2219} INFO - iteration 156, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:41] {2392} INFO -  at 86.8s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:41] {2219} INFO - iteration 157, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:41] {2392} INFO -  at 86.9s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:41] {2219} INFO - iteration 158, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:42] {2392} INFO -  at 87.5s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:42] {2219} INFO - iteration 159, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:42] {2392} INFO -  at 87.7s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:42] {2219} INFO - iteration 160, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:42] {2392} INFO -  at 87.9s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:43] {2219} INFO - iteration 161, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:43] {2392} INFO -  at 88.2s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:43] {2219} INFO - iteration 162, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:43] {2392} INFO -  at 88.5s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:43] {2219} INFO - iteration 163, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:43] {2392} INFO -  at 88.7s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:43] {2219} INFO - iteration 164, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:43] {2392} INFO -  at 88.9s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:43] {2219} INFO - iteration 165, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:44] {2392} INFO -  at 89.2s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:44] {2219} INFO - iteration 166, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:44] {2392} INFO -  at 89.3s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:44] {2219} INFO - iteration 167, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:44] {2392} INFO -  at 89.5s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:44] {2219} INFO - iteration 168, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:45] {2392} INFO -  at 90.7s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:45] {2219} INFO - iteration 169, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:45] {2392} INFO -  at 90.8s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:45] {2219} INFO - iteration 170, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:46] {2392} INFO -  at 91.4s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:46] {2219} INFO - iteration 171, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:46] {2392} INFO -  at 91.6s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:46] {2219} INFO - iteration 172, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:46] {2392} INFO -  at 91.7s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:46] {2219} INFO - iteration 173, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:47] {2392} INFO -  at 92.2s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:47] {2219} INFO - iteration 174, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:47] {2392} INFO -  at 92.4s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:47] {2219} INFO - iteration 175, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:47] {2392} INFO -  at 92.6s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:47] {2219} INFO - iteration 176, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:47] {2392} INFO -  at 92.9s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:47] {2219} INFO - iteration 177, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:48] {2392} INFO -  at 93.2s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:48] {2219} INFO - iteration 178, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:48] {2392} INFO -  at 93.4s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:48] {2219} INFO - iteration 179, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:48] {2392} INFO -  at 93.7s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:48] {2219} INFO - iteration 180, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:49] {2392} INFO -  at 94.0s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:49] {2219} INFO - iteration 181, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:49] {2392} INFO -  at 94.1s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:49] {2219} INFO - iteration 182, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:49] {2392} INFO -  at 94.3s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:49] {2219} INFO - iteration 183, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:49] {2392} INFO -  at 94.7s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:49] {2219} INFO - iteration 184, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:49] {2392} INFO -  at 94.9s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:49] {2219} INFO - iteration 185, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:50] {2392} INFO -  at 95.3s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:50] {2219} INFO - iteration 186, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:50] {2392} INFO -  at 95.4s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:50] {2219} INFO - iteration 187, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:50] {2392} INFO -  at 95.8s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:50] {2219} INFO - iteration 188, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:51] {2392} INFO -  at 96.0s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:51] {2219} INFO - iteration 189, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:51] {2392} INFO -  at 96.2s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:51] {2219} INFO - iteration 190, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:53] {2392} INFO -  at 98.3s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:53] {2219} INFO - iteration 191, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:53] {2392} INFO -  at 98.8s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:53] {2219} INFO - iteration 192, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:53] {2392} INFO -  at 98.9s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:53] {2219} INFO - iteration 193, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:54] {2392} INFO -  at 99.2s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:54] {2219} INFO - iteration 194, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:54] {2392} INFO -  at 99.5s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:54] {2219} INFO - iteration 195, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:54] {2392} INFO -  at 99.6s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:54] {2219} INFO - iteration 196, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:54] {2392} INFO -  at 99.9s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:54] {2219} INFO - iteration 197, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:55] {2392} INFO -  at 100.2s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:55] {2219} INFO - iteration 198, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:55] {2392} INFO -  at 100.4s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:55] {2219} INFO - iteration 199, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:55] {2392} INFO -  at 100.8s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:55] {2219} INFO - iteration 200, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:56] {2392} INFO -  at 101.0s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:56] {2219} INFO - iteration 201, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:56] {2392} INFO -  at 101.2s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:56] {2219} INFO - iteration 202, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:56] {2392} INFO -  at 101.4s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:56] {2219} INFO - iteration 203, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:56] {2392} INFO -  at 101.6s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:56] {2219} INFO - iteration 204, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:56] {2392} INFO -  at 101.8s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:56] {2219} INFO - iteration 205, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:57] {2392} INFO -  at 102.0s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:57] {2219} INFO - iteration 206, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:57] {2392} INFO -  at 102.3s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:57] {2219} INFO - iteration 207, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:57] {2392} INFO -  at 102.5s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:57] {2219} INFO - iteration 208, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:57] {2392} INFO -  at 102.8s,\testimator lgbm's best error=0.4255,\tbest estimator lgbm's best error=0.4255\n",
            "[flaml.automl.logger: 03-18 08:20:57] {2219} INFO - iteration 209, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:58] {2392} INFO -  at 103.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:20:58] {2219} INFO - iteration 210, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:58] {2392} INFO -  at 103.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:20:58] {2219} INFO - iteration 211, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:58] {2392} INFO -  at 103.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:20:58] {2219} INFO - iteration 212, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:59] {2392} INFO -  at 103.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:20:59] {2219} INFO - iteration 213, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:59] {2392} INFO -  at 104.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:20:59] {2219} INFO - iteration 214, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:20:59] {2392} INFO -  at 104.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:20:59] {2219} INFO - iteration 215, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:00] {2392} INFO -  at 105.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:00] {2219} INFO - iteration 216, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:00] {2392} INFO -  at 105.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:00] {2219} INFO - iteration 217, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:01] {2392} INFO -  at 106.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:01] {2219} INFO - iteration 218, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:01] {2392} INFO -  at 106.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:01] {2219} INFO - iteration 219, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:01] {2392} INFO -  at 106.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:01] {2219} INFO - iteration 220, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:01] {2392} INFO -  at 106.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:01] {2219} INFO - iteration 221, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:02] {2392} INFO -  at 107.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:02] {2219} INFO - iteration 222, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:02] {2392} INFO -  at 107.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:02] {2219} INFO - iteration 223, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:02] {2392} INFO -  at 107.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:02] {2219} INFO - iteration 224, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:03] {2392} INFO -  at 107.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:03] {2219} INFO - iteration 225, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:04] {2392} INFO -  at 109.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:04] {2219} INFO - iteration 226, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:04] {2392} INFO -  at 109.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:04] {2219} INFO - iteration 227, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:05] {2392} INFO -  at 110.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:05] {2219} INFO - iteration 228, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:05] {2392} INFO -  at 110.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:05] {2219} INFO - iteration 229, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:06] {2392} INFO -  at 111.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:06] {2219} INFO - iteration 230, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:06] {2392} INFO -  at 111.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:06] {2219} INFO - iteration 231, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:06] {2392} INFO -  at 111.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:06] {2219} INFO - iteration 232, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:07] {2392} INFO -  at 112.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:07] {2219} INFO - iteration 233, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:07] {2392} INFO -  at 112.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:07] {2219} INFO - iteration 234, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:07] {2392} INFO -  at 112.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:07] {2219} INFO - iteration 235, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:07] {2392} INFO -  at 112.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:07] {2219} INFO - iteration 236, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:08] {2392} INFO -  at 113.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:08] {2219} INFO - iteration 237, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:08] {2392} INFO -  at 113.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:08] {2219} INFO - iteration 238, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:08] {2392} INFO -  at 113.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:08] {2219} INFO - iteration 239, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:08] {2392} INFO -  at 113.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:08] {2219} INFO - iteration 240, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:09] {2392} INFO -  at 114.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:09] {2219} INFO - iteration 241, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:09] {2392} INFO -  at 114.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:09] {2219} INFO - iteration 242, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:10] {2392} INFO -  at 115.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:10] {2219} INFO - iteration 243, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:10] {2392} INFO -  at 115.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:10] {2219} INFO - iteration 244, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:10] {2392} INFO -  at 115.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:10] {2219} INFO - iteration 245, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:11] {2392} INFO -  at 116.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:11] {2219} INFO - iteration 246, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:11] {2392} INFO -  at 116.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:11] {2219} INFO - iteration 247, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:11] {2392} INFO -  at 116.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:11] {2219} INFO - iteration 248, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:11] {2392} INFO -  at 116.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:11] {2219} INFO - iteration 249, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:11] {2392} INFO -  at 116.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:11] {2219} INFO - iteration 250, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:12] {2392} INFO -  at 117.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:12] {2219} INFO - iteration 251, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:12] {2392} INFO -  at 117.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:12] {2219} INFO - iteration 252, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:12] {2392} INFO -  at 117.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:12] {2219} INFO - iteration 253, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:13] {2392} INFO -  at 118.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:13] {2219} INFO - iteration 254, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:13] {2392} INFO -  at 118.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:13] {2219} INFO - iteration 255, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:13] {2392} INFO -  at 118.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:13] {2219} INFO - iteration 256, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:14] {2392} INFO -  at 119.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:14] {2219} INFO - iteration 257, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:14] {2392} INFO -  at 119.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:14] {2219} INFO - iteration 258, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:16] {2392} INFO -  at 121.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:16] {2219} INFO - iteration 259, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:17] {2392} INFO -  at 122.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:17] {2219} INFO - iteration 260, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:17] {2392} INFO -  at 122.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:17] {2219} INFO - iteration 261, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:18] {2392} INFO -  at 123.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:18] {2219} INFO - iteration 262, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:18] {2392} INFO -  at 123.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:18] {2219} INFO - iteration 263, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:19] {2392} INFO -  at 124.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:19] {2219} INFO - iteration 264, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:19] {2392} INFO -  at 124.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:19] {2219} INFO - iteration 265, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:19] {2392} INFO -  at 124.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:19] {2219} INFO - iteration 266, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:19] {2392} INFO -  at 124.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:19] {2219} INFO - iteration 267, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:20] {2392} INFO -  at 125.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:20] {2219} INFO - iteration 268, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:20] {2392} INFO -  at 125.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:20] {2219} INFO - iteration 269, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:20] {2392} INFO -  at 125.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:20] {2219} INFO - iteration 270, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:21] {2392} INFO -  at 126.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:21] {2219} INFO - iteration 271, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:21] {2392} INFO -  at 126.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:21] {2219} INFO - iteration 272, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:22] {2392} INFO -  at 127.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:22] {2219} INFO - iteration 273, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:22] {2392} INFO -  at 127.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:22] {2219} INFO - iteration 274, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:22] {2392} INFO -  at 127.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:22] {2219} INFO - iteration 275, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:23] {2392} INFO -  at 128.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:23] {2219} INFO - iteration 276, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:23] {2392} INFO -  at 128.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:23] {2219} INFO - iteration 277, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:23] {2392} INFO -  at 128.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:23] {2219} INFO - iteration 278, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:24] {2392} INFO -  at 128.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:24] {2219} INFO - iteration 279, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:24] {2392} INFO -  at 129.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:24] {2219} INFO - iteration 280, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:24] {2392} INFO -  at 129.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:24] {2219} INFO - iteration 281, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:24] {2392} INFO -  at 129.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:24] {2219} INFO - iteration 282, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:25] {2392} INFO -  at 130.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:25] {2219} INFO - iteration 283, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:25] {2392} INFO -  at 130.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:25] {2219} INFO - iteration 284, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:25] {2392} INFO -  at 130.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:25] {2219} INFO - iteration 285, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:26] {2392} INFO -  at 131.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:26] {2219} INFO - iteration 286, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:26] {2392} INFO -  at 131.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:26] {2219} INFO - iteration 287, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:29] {2392} INFO -  at 134.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:29] {2219} INFO - iteration 288, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:29] {2392} INFO -  at 134.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:29] {2219} INFO - iteration 289, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:29] {2392} INFO -  at 134.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:29] {2219} INFO - iteration 290, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:30] {2392} INFO -  at 135.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:30] {2219} INFO - iteration 291, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:30] {2392} INFO -  at 135.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:30] {2219} INFO - iteration 292, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:30] {2392} INFO -  at 135.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:30] {2219} INFO - iteration 293, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:31] {2392} INFO -  at 136.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:31] {2219} INFO - iteration 294, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:31] {2392} INFO -  at 136.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:31] {2219} INFO - iteration 295, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:31] {2392} INFO -  at 136.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:31] {2219} INFO - iteration 296, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:31] {2392} INFO -  at 136.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:31] {2219} INFO - iteration 297, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:32] {2392} INFO -  at 137.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:32] {2219} INFO - iteration 298, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:32] {2392} INFO -  at 137.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:32] {2219} INFO - iteration 299, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:32] {2392} INFO -  at 137.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:32] {2219} INFO - iteration 300, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:33] {2392} INFO -  at 138.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:33] {2219} INFO - iteration 301, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:33] {2392} INFO -  at 138.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:33] {2219} INFO - iteration 302, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:33] {2392} INFO -  at 138.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:33] {2219} INFO - iteration 303, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:34] {2392} INFO -  at 139.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:34] {2219} INFO - iteration 304, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:34] {2392} INFO -  at 139.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:34] {2219} INFO - iteration 305, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:35] {2392} INFO -  at 140.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:35] {2219} INFO - iteration 306, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:35] {2392} INFO -  at 140.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:35] {2219} INFO - iteration 307, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:35] {2392} INFO -  at 140.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:35] {2219} INFO - iteration 308, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:35] {2392} INFO -  at 140.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:35] {2219} INFO - iteration 309, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:36] {2392} INFO -  at 141.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:36] {2219} INFO - iteration 310, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:36] {2392} INFO -  at 141.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:36] {2219} INFO - iteration 311, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:36] {2392} INFO -  at 141.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:36] {2219} INFO - iteration 312, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:36] {2392} INFO -  at 141.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:36] {2219} INFO - iteration 313, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:37] {2392} INFO -  at 142.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:37] {2219} INFO - iteration 314, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:37] {2392} INFO -  at 142.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:37] {2219} INFO - iteration 315, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:38] {2392} INFO -  at 143.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:38] {2219} INFO - iteration 316, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:38] {2392} INFO -  at 143.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:38] {2219} INFO - iteration 317, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:38] {2392} INFO -  at 143.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:38] {2219} INFO - iteration 318, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:39] {2392} INFO -  at 144.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:39] {2219} INFO - iteration 319, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:40] {2392} INFO -  at 145.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:40] {2219} INFO - iteration 320, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:41] {2392} INFO -  at 146.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:41] {2219} INFO - iteration 321, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:41] {2392} INFO -  at 146.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:41] {2219} INFO - iteration 322, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:41] {2392} INFO -  at 146.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:41] {2219} INFO - iteration 323, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:42] {2392} INFO -  at 147.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:42] {2219} INFO - iteration 324, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:42] {2392} INFO -  at 147.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:42] {2219} INFO - iteration 325, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:42] {2392} INFO -  at 147.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:42] {2219} INFO - iteration 326, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:43] {2392} INFO -  at 148.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:43] {2219} INFO - iteration 327, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:43] {2392} INFO -  at 148.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:43] {2219} INFO - iteration 328, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:43] {2392} INFO -  at 148.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:43] {2219} INFO - iteration 329, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:44] {2392} INFO -  at 149.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:44] {2219} INFO - iteration 330, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:45] {2392} INFO -  at 150.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:45] {2219} INFO - iteration 331, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:45] {2392} INFO -  at 150.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:45] {2219} INFO - iteration 332, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:45] {2392} INFO -  at 150.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:45] {2219} INFO - iteration 333, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:45] {2392} INFO -  at 150.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:45] {2219} INFO - iteration 334, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:46] {2392} INFO -  at 151.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:46] {2219} INFO - iteration 335, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:46] {2392} INFO -  at 151.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:46] {2219} INFO - iteration 336, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:46] {2392} INFO -  at 151.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:46] {2219} INFO - iteration 337, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:47] {2392} INFO -  at 152.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:47] {2219} INFO - iteration 338, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:47] {2392} INFO -  at 152.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:47] {2219} INFO - iteration 339, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:47] {2392} INFO -  at 152.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:47] {2219} INFO - iteration 340, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:48] {2392} INFO -  at 153.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:48] {2219} INFO - iteration 341, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:48] {2392} INFO -  at 153.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:48] {2219} INFO - iteration 342, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:48] {2392} INFO -  at 153.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:48] {2219} INFO - iteration 343, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:48] {2392} INFO -  at 153.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:48] {2219} INFO - iteration 344, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:49] {2392} INFO -  at 154.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:49] {2219} INFO - iteration 345, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:49] {2392} INFO -  at 154.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:49] {2219} INFO - iteration 346, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:49] {2392} INFO -  at 154.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:49] {2219} INFO - iteration 347, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:50] {2392} INFO -  at 155.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:50] {2219} INFO - iteration 348, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:51] {2392} INFO -  at 156.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:51] {2219} INFO - iteration 349, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:51] {2392} INFO -  at 156.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:51] {2219} INFO - iteration 350, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:53] {2392} INFO -  at 158.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:53] {2219} INFO - iteration 351, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:53] {2392} INFO -  at 158.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:53] {2219} INFO - iteration 352, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:53] {2392} INFO -  at 158.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:53] {2219} INFO - iteration 353, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:54] {2392} INFO -  at 159.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:54] {2219} INFO - iteration 354, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:54] {2392} INFO -  at 159.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:54] {2219} INFO - iteration 355, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:54] {2392} INFO -  at 159.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:54] {2219} INFO - iteration 356, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:55] {2392} INFO -  at 160.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:55] {2219} INFO - iteration 357, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:55] {2392} INFO -  at 160.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:55] {2219} INFO - iteration 358, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:55] {2392} INFO -  at 160.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:55] {2219} INFO - iteration 359, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:56] {2392} INFO -  at 161.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:56] {2219} INFO - iteration 360, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:56] {2392} INFO -  at 161.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:56] {2219} INFO - iteration 361, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:56] {2392} INFO -  at 161.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:56] {2219} INFO - iteration 362, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:56] {2392} INFO -  at 161.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:56] {2219} INFO - iteration 363, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:57] {2392} INFO -  at 162.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:57] {2219} INFO - iteration 364, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:57] {2392} INFO -  at 162.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:57] {2219} INFO - iteration 365, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:57] {2392} INFO -  at 162.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:57] {2219} INFO - iteration 366, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:58] {2392} INFO -  at 163.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:58] {2219} INFO - iteration 367, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:58] {2392} INFO -  at 163.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:58] {2219} INFO - iteration 368, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:58] {2392} INFO -  at 163.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:58] {2219} INFO - iteration 369, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:59] {2392} INFO -  at 164.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:59] {2219} INFO - iteration 370, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:59] {2392} INFO -  at 164.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:59] {2219} INFO - iteration 371, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:21:59] {2392} INFO -  at 164.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:21:59] {2219} INFO - iteration 372, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:00] {2392} INFO -  at 165.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:00] {2219} INFO - iteration 373, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:00] {2392} INFO -  at 165.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:00] {2219} INFO - iteration 374, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:00] {2392} INFO -  at 165.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:00] {2219} INFO - iteration 375, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:00] {2392} INFO -  at 165.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:00] {2219} INFO - iteration 376, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:01] {2392} INFO -  at 166.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:01] {2219} INFO - iteration 377, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:02] {2392} INFO -  at 167.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:02] {2219} INFO - iteration 378, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:02] {2392} INFO -  at 167.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:02] {2219} INFO - iteration 379, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:03] {2392} INFO -  at 168.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:03] {2219} INFO - iteration 380, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:03] {2392} INFO -  at 168.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:03] {2219} INFO - iteration 381, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:04] {2392} INFO -  at 169.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:04] {2219} INFO - iteration 382, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:06] {2392} INFO -  at 171.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:06] {2219} INFO - iteration 383, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:06] {2392} INFO -  at 171.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:06] {2219} INFO - iteration 384, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:06] {2392} INFO -  at 171.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:06] {2219} INFO - iteration 385, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:07] {2392} INFO -  at 172.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:07] {2219} INFO - iteration 386, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:07] {2392} INFO -  at 172.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:07] {2219} INFO - iteration 387, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:07] {2392} INFO -  at 172.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:07] {2219} INFO - iteration 388, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:07] {2392} INFO -  at 172.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:07] {2219} INFO - iteration 389, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:08] {2392} INFO -  at 173.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:08] {2219} INFO - iteration 390, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:08] {2392} INFO -  at 173.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:08] {2219} INFO - iteration 391, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:08] {2392} INFO -  at 173.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:08] {2219} INFO - iteration 392, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:09] {2392} INFO -  at 174.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:09] {2219} INFO - iteration 393, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:09] {2392} INFO -  at 174.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:09] {2219} INFO - iteration 394, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:10] {2392} INFO -  at 175.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:10] {2219} INFO - iteration 395, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:10] {2392} INFO -  at 175.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:10] {2219} INFO - iteration 396, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:10] {2392} INFO -  at 175.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:10] {2219} INFO - iteration 397, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:10] {2392} INFO -  at 175.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:10] {2219} INFO - iteration 398, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:11] {2392} INFO -  at 176.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:11] {2219} INFO - iteration 399, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:11] {2392} INFO -  at 176.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:11] {2219} INFO - iteration 400, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:11] {2392} INFO -  at 176.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:11] {2219} INFO - iteration 401, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:11] {2392} INFO -  at 176.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:11] {2219} INFO - iteration 402, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:12] {2392} INFO -  at 177.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:12] {2219} INFO - iteration 403, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:12] {2392} INFO -  at 177.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:12] {2219} INFO - iteration 404, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:12] {2392} INFO -  at 177.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:12] {2219} INFO - iteration 405, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:12] {2392} INFO -  at 177.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:12] {2219} INFO - iteration 406, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:13] {2392} INFO -  at 178.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:13] {2219} INFO - iteration 407, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:13] {2392} INFO -  at 178.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:13] {2219} INFO - iteration 408, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:13] {2392} INFO -  at 178.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:13] {2219} INFO - iteration 409, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:13] {2392} INFO -  at 178.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:13] {2219} INFO - iteration 410, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:14] {2392} INFO -  at 179.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:14] {2219} INFO - iteration 411, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:16] {2392} INFO -  at 181.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:16] {2219} INFO - iteration 412, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:17] {2392} INFO -  at 182.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:17] {2219} INFO - iteration 413, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:17] {2392} INFO -  at 182.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:17] {2219} INFO - iteration 414, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:17] {2392} INFO -  at 182.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:17] {2219} INFO - iteration 415, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:18] {2392} INFO -  at 183.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:18] {2219} INFO - iteration 416, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:18] {2392} INFO -  at 183.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:18] {2219} INFO - iteration 417, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:18] {2392} INFO -  at 183.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:18] {2219} INFO - iteration 418, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:18] {2392} INFO -  at 183.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:18] {2219} INFO - iteration 419, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:19] {2392} INFO -  at 184.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:19] {2219} INFO - iteration 420, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:19] {2392} INFO -  at 184.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:19] {2219} INFO - iteration 421, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:20] {2392} INFO -  at 184.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:20] {2219} INFO - iteration 422, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:20] {2392} INFO -  at 185.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:20] {2219} INFO - iteration 423, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:20] {2392} INFO -  at 185.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:20] {2219} INFO - iteration 424, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:20] {2392} INFO -  at 185.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:20] {2219} INFO - iteration 425, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:21] {2392} INFO -  at 186.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:21] {2219} INFO - iteration 426, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:21] {2392} INFO -  at 186.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:21] {2219} INFO - iteration 427, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:21] {2392} INFO -  at 186.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:21] {2219} INFO - iteration 428, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:21] {2392} INFO -  at 186.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:21] {2219} INFO - iteration 429, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:22] {2392} INFO -  at 186.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:22] {2219} INFO - iteration 430, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:22] {2392} INFO -  at 187.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:22] {2219} INFO - iteration 431, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:22] {2392} INFO -  at 187.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:22] {2219} INFO - iteration 432, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:22] {2392} INFO -  at 187.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:22] {2219} INFO - iteration 433, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:23] {2392} INFO -  at 188.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:23] {2219} INFO - iteration 434, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:23] {2392} INFO -  at 188.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:23] {2219} INFO - iteration 435, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:23] {2392} INFO -  at 188.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:23] {2219} INFO - iteration 436, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:24] {2392} INFO -  at 189.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:24] {2219} INFO - iteration 437, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:24] {2392} INFO -  at 189.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:24] {2219} INFO - iteration 438, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:24] {2392} INFO -  at 189.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:24] {2219} INFO - iteration 439, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:24] {2392} INFO -  at 189.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:24] {2219} INFO - iteration 440, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:26] {2392} INFO -  at 191.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:26] {2219} INFO - iteration 441, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:26] {2392} INFO -  at 191.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:26] {2219} INFO - iteration 442, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:27] {2392} INFO -  at 192.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:27] {2219} INFO - iteration 443, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:27] {2392} INFO -  at 192.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:27] {2219} INFO - iteration 444, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:29] {2392} INFO -  at 194.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:29] {2219} INFO - iteration 445, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:29] {2392} INFO -  at 194.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:29] {2219} INFO - iteration 446, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:30] {2392} INFO -  at 195.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:30] {2219} INFO - iteration 447, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:30] {2392} INFO -  at 195.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:30] {2219} INFO - iteration 448, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:30] {2392} INFO -  at 195.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:30] {2219} INFO - iteration 449, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:30] {2392} INFO -  at 195.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:30] {2219} INFO - iteration 450, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:31] {2392} INFO -  at 196.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:31] {2219} INFO - iteration 451, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:31] {2392} INFO -  at 196.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:31] {2219} INFO - iteration 452, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:31] {2392} INFO -  at 196.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:31] {2219} INFO - iteration 453, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:32] {2392} INFO -  at 197.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:32] {2219} INFO - iteration 454, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:32] {2392} INFO -  at 197.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:32] {2219} INFO - iteration 455, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:32] {2392} INFO -  at 197.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:32] {2219} INFO - iteration 456, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:32] {2392} INFO -  at 197.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:32] {2219} INFO - iteration 457, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:32] {2392} INFO -  at 197.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:32] {2219} INFO - iteration 458, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:33] {2392} INFO -  at 198.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:33] {2219} INFO - iteration 459, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:34] {2392} INFO -  at 199.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:34] {2219} INFO - iteration 460, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:34] {2392} INFO -  at 199.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:34] {2219} INFO - iteration 461, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:35] {2392} INFO -  at 200.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:35] {2219} INFO - iteration 462, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:35] {2392} INFO -  at 200.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:35] {2219} INFO - iteration 463, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:36] {2392} INFO -  at 201.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:36] {2219} INFO - iteration 464, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:36] {2392} INFO -  at 201.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:36] {2219} INFO - iteration 465, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:36] {2392} INFO -  at 201.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:36] {2219} INFO - iteration 466, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:37] {2392} INFO -  at 202.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:37] {2219} INFO - iteration 467, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:37] {2392} INFO -  at 202.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:37] {2219} INFO - iteration 468, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:38] {2392} INFO -  at 203.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:38] {2219} INFO - iteration 469, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:38] {2392} INFO -  at 203.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:38] {2219} INFO - iteration 470, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:38] {2392} INFO -  at 203.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:38] {2219} INFO - iteration 471, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:38] {2392} INFO -  at 203.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:38] {2219} INFO - iteration 472, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:39] {2392} INFO -  at 204.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:39] {2219} INFO - iteration 473, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:41] {2392} INFO -  at 206.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:41] {2219} INFO - iteration 474, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:41] {2392} INFO -  at 206.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:41] {2219} INFO - iteration 475, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:41] {2392} INFO -  at 206.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:41] {2219} INFO - iteration 476, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:41] {2392} INFO -  at 206.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:41] {2219} INFO - iteration 477, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:42] {2392} INFO -  at 207.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:42] {2219} INFO - iteration 478, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:42] {2392} INFO -  at 207.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:42] {2219} INFO - iteration 479, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:42] {2392} INFO -  at 207.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:42] {2219} INFO - iteration 480, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:42] {2392} INFO -  at 207.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:42] {2219} INFO - iteration 481, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:43] {2392} INFO -  at 208.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:43] {2219} INFO - iteration 482, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:43] {2392} INFO -  at 208.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:43] {2219} INFO - iteration 483, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:43] {2392} INFO -  at 208.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:43] {2219} INFO - iteration 484, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:43] {2392} INFO -  at 208.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:43] {2219} INFO - iteration 485, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:44] {2392} INFO -  at 208.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:44] {2219} INFO - iteration 486, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:44] {2392} INFO -  at 209.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:44] {2219} INFO - iteration 487, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:44] {2392} INFO -  at 209.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:44] {2219} INFO - iteration 488, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:44] {2392} INFO -  at 209.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:44] {2219} INFO - iteration 489, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:45] {2392} INFO -  at 210.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:45] {2219} INFO - iteration 490, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:45] {2392} INFO -  at 210.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:45] {2219} INFO - iteration 491, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:45] {2392} INFO -  at 210.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:45] {2219} INFO - iteration 492, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:45] {2392} INFO -  at 210.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:45] {2219} INFO - iteration 493, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:46] {2392} INFO -  at 211.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:46] {2219} INFO - iteration 494, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:46] {2392} INFO -  at 211.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:46] {2219} INFO - iteration 495, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:47] {2392} INFO -  at 212.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:47] {2219} INFO - iteration 496, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:47] {2392} INFO -  at 212.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:47] {2219} INFO - iteration 497, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:47] {2392} INFO -  at 212.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:47] {2219} INFO - iteration 498, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:47] {2392} INFO -  at 212.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:47] {2219} INFO - iteration 499, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:48] {2392} INFO -  at 213.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:48] {2219} INFO - iteration 500, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:48] {2392} INFO -  at 213.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:48] {2219} INFO - iteration 501, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:48] {2392} INFO -  at 213.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:48] {2219} INFO - iteration 502, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:49] {2392} INFO -  at 214.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:49] {2219} INFO - iteration 503, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:49] {2392} INFO -  at 214.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:49] {2219} INFO - iteration 504, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:49] {2392} INFO -  at 214.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:49] {2219} INFO - iteration 505, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:49] {2392} INFO -  at 214.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:49] {2219} INFO - iteration 506, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:50] {2392} INFO -  at 215.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:50] {2219} INFO - iteration 507, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:50] {2392} INFO -  at 215.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:50] {2219} INFO - iteration 508, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:50] {2392} INFO -  at 215.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:50] {2219} INFO - iteration 509, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:50] {2392} INFO -  at 215.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:50] {2219} INFO - iteration 510, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:51] {2392} INFO -  at 216.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:51] {2219} INFO - iteration 511, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:53] {2392} INFO -  at 218.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:53] {2219} INFO - iteration 512, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:53] {2392} INFO -  at 218.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:53] {2219} INFO - iteration 513, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:53] {2392} INFO -  at 218.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:53] {2219} INFO - iteration 514, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:53] {2392} INFO -  at 218.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:53] {2219} INFO - iteration 515, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:54] {2392} INFO -  at 219.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:54] {2219} INFO - iteration 516, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:54] {2392} INFO -  at 219.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:54] {2219} INFO - iteration 517, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:54] {2392} INFO -  at 219.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:54] {2219} INFO - iteration 518, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:55] {2392} INFO -  at 220.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:55] {2219} INFO - iteration 519, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:55] {2392} INFO -  at 220.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:55] {2219} INFO - iteration 520, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:55] {2392} INFO -  at 220.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:55] {2219} INFO - iteration 521, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:55] {2392} INFO -  at 220.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:55] {2219} INFO - iteration 522, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:56] {2392} INFO -  at 221.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:56] {2219} INFO - iteration 523, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:56] {2392} INFO -  at 221.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:56] {2219} INFO - iteration 524, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:56] {2392} INFO -  at 221.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:56] {2219} INFO - iteration 525, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:57] {2392} INFO -  at 222.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:57] {2219} INFO - iteration 526, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:57] {2392} INFO -  at 222.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:57] {2219} INFO - iteration 527, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:57] {2392} INFO -  at 222.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:57] {2219} INFO - iteration 528, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:57] {2392} INFO -  at 222.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:57] {2219} INFO - iteration 529, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:58] {2392} INFO -  at 223.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:58] {2219} INFO - iteration 530, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:58] {2392} INFO -  at 223.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:58] {2219} INFO - iteration 531, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:58] {2392} INFO -  at 223.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:58] {2219} INFO - iteration 532, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:59] {2392} INFO -  at 224.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:59] {2219} INFO - iteration 533, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:59] {2392} INFO -  at 224.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:59] {2219} INFO - iteration 534, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:22:59] {2392} INFO -  at 224.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:22:59] {2219} INFO - iteration 535, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:00] {2392} INFO -  at 225.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:00] {2219} INFO - iteration 536, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:00] {2392} INFO -  at 225.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:00] {2219} INFO - iteration 537, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:00] {2392} INFO -  at 225.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:00] {2219} INFO - iteration 538, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:00] {2392} INFO -  at 225.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:00] {2219} INFO - iteration 539, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:00] {2392} INFO -  at 225.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:00] {2219} INFO - iteration 540, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:01] {2392} INFO -  at 226.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:01] {2219} INFO - iteration 541, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:02] {2392} INFO -  at 227.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:02] {2219} INFO - iteration 542, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:02] {2392} INFO -  at 227.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:02] {2219} INFO - iteration 543, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:02] {2392} INFO -  at 227.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:02] {2219} INFO - iteration 544, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:02] {2392} INFO -  at 227.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:02] {2219} INFO - iteration 545, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:03] {2392} INFO -  at 227.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:03] {2219} INFO - iteration 546, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:04] {2392} INFO -  at 229.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:04] {2219} INFO - iteration 547, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:05] {2392} INFO -  at 230.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:05] {2219} INFO - iteration 548, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:05] {2392} INFO -  at 230.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:05] {2219} INFO - iteration 549, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:05] {2392} INFO -  at 230.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:05] {2219} INFO - iteration 550, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:05] {2392} INFO -  at 230.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:05] {2219} INFO - iteration 551, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:06] {2392} INFO -  at 231.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:06] {2219} INFO - iteration 552, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:06] {2392} INFO -  at 231.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:06] {2219} INFO - iteration 553, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:06] {2392} INFO -  at 231.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:06] {2219} INFO - iteration 554, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:07] {2392} INFO -  at 232.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:07] {2219} INFO - iteration 555, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:07] {2392} INFO -  at 232.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:07] {2219} INFO - iteration 556, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:07] {2392} INFO -  at 232.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:07] {2219} INFO - iteration 557, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:07] {2392} INFO -  at 232.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:07] {2219} INFO - iteration 558, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:08] {2392} INFO -  at 233.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:08] {2219} INFO - iteration 559, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:08] {2392} INFO -  at 233.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:08] {2219} INFO - iteration 560, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:09] {2392} INFO -  at 234.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:09] {2219} INFO - iteration 561, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:09] {2392} INFO -  at 234.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:09] {2219} INFO - iteration 562, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:09] {2392} INFO -  at 234.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:09] {2219} INFO - iteration 563, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:09] {2392} INFO -  at 234.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:09] {2219} INFO - iteration 564, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:10] {2392} INFO -  at 235.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:10] {2219} INFO - iteration 565, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:10] {2392} INFO -  at 235.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:10] {2219} INFO - iteration 566, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:11] {2392} INFO -  at 236.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:11] {2219} INFO - iteration 567, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:11] {2392} INFO -  at 236.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:11] {2219} INFO - iteration 568, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:11] {2392} INFO -  at 236.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:11] {2219} INFO - iteration 569, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:11] {2392} INFO -  at 236.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:11] {2219} INFO - iteration 570, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:12] {2392} INFO -  at 237.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:12] {2219} INFO - iteration 571, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:12] {2392} INFO -  at 237.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:12] {2219} INFO - iteration 572, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:12] {2392} INFO -  at 237.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:12] {2219} INFO - iteration 573, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:12] {2392} INFO -  at 237.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:12] {2219} INFO - iteration 574, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:13] {2392} INFO -  at 238.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:13] {2219} INFO - iteration 575, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:13] {2392} INFO -  at 238.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:13] {2219} INFO - iteration 576, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:13] {2392} INFO -  at 238.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:13] {2219} INFO - iteration 577, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:14] {2392} INFO -  at 239.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:14] {2219} INFO - iteration 578, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:15] {2392} INFO -  at 240.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:15] {2219} INFO - iteration 579, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:17] {2392} INFO -  at 242.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:17] {2219} INFO - iteration 580, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:17] {2392} INFO -  at 242.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:17] {2219} INFO - iteration 581, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:17] {2392} INFO -  at 242.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:17] {2219} INFO - iteration 582, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:17] {2392} INFO -  at 242.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:17] {2219} INFO - iteration 583, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:18] {2392} INFO -  at 243.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:18] {2219} INFO - iteration 584, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:18] {2392} INFO -  at 243.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:18] {2219} INFO - iteration 585, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:18] {2392} INFO -  at 243.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:18] {2219} INFO - iteration 586, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:19] {2392} INFO -  at 244.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:19] {2219} INFO - iteration 587, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:19] {2392} INFO -  at 244.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:19] {2219} INFO - iteration 588, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:19] {2392} INFO -  at 244.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:19] {2219} INFO - iteration 589, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:20] {2392} INFO -  at 245.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:20] {2219} INFO - iteration 590, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:20] {2392} INFO -  at 245.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:20] {2219} INFO - iteration 591, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:20] {2392} INFO -  at 245.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:20] {2219} INFO - iteration 592, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:21] {2392} INFO -  at 246.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:21] {2219} INFO - iteration 593, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:21] {2392} INFO -  at 246.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:21] {2219} INFO - iteration 594, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:21] {2392} INFO -  at 246.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:21] {2219} INFO - iteration 595, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:21] {2392} INFO -  at 246.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:21] {2219} INFO - iteration 596, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:22] {2392} INFO -  at 247.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:22] {2219} INFO - iteration 597, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:22] {2392} INFO -  at 247.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:22] {2219} INFO - iteration 598, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:22] {2392} INFO -  at 247.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:22] {2219} INFO - iteration 599, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:22] {2392} INFO -  at 247.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:22] {2219} INFO - iteration 600, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:23] {2392} INFO -  at 248.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:23] {2219} INFO - iteration 601, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:23] {2392} INFO -  at 248.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:23] {2219} INFO - iteration 602, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:23] {2392} INFO -  at 248.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:23] {2219} INFO - iteration 603, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:24] {2392} INFO -  at 249.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:24] {2219} INFO - iteration 604, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:24] {2392} INFO -  at 249.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:24] {2219} INFO - iteration 605, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:24] {2392} INFO -  at 249.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:24] {2219} INFO - iteration 606, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:24] {2392} INFO -  at 249.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:24] {2219} INFO - iteration 607, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:25] {2392} INFO -  at 250.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:25] {2219} INFO - iteration 608, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:25] {2392} INFO -  at 250.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:25] {2219} INFO - iteration 609, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:25] {2392} INFO -  at 250.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:25] {2219} INFO - iteration 610, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:25] {2392} INFO -  at 250.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:25] {2219} INFO - iteration 611, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:26] {2392} INFO -  at 251.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:26] {2219} INFO - iteration 612, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:26] {2392} INFO -  at 251.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:26] {2219} INFO - iteration 613, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:26] {2392} INFO -  at 251.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:26] {2219} INFO - iteration 614, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:27] {2392} INFO -  at 252.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:27] {2219} INFO - iteration 615, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:28] {2392} INFO -  at 253.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:28] {2219} INFO - iteration 616, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:29] {2392} INFO -  at 254.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:29] {2219} INFO - iteration 617, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:29] {2392} INFO -  at 254.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:29] {2219} INFO - iteration 618, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:29] {2392} INFO -  at 254.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:29] {2219} INFO - iteration 619, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:30] {2392} INFO -  at 255.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:30] {2219} INFO - iteration 620, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:30] {2392} INFO -  at 255.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:30] {2219} INFO - iteration 621, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:30] {2392} INFO -  at 255.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:30] {2219} INFO - iteration 622, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:31] {2392} INFO -  at 256.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:31] {2219} INFO - iteration 623, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:31] {2392} INFO -  at 256.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:31] {2219} INFO - iteration 624, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:31] {2392} INFO -  at 256.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:31] {2219} INFO - iteration 625, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:32] {2392} INFO -  at 257.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:32] {2219} INFO - iteration 626, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:32] {2392} INFO -  at 257.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:32] {2219} INFO - iteration 627, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:32] {2392} INFO -  at 257.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:32] {2219} INFO - iteration 628, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:33] {2392} INFO -  at 258.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:33] {2219} INFO - iteration 629, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:33] {2392} INFO -  at 258.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:33] {2219} INFO - iteration 630, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:33] {2392} INFO -  at 258.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:33] {2219} INFO - iteration 631, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:33] {2392} INFO -  at 258.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:33] {2219} INFO - iteration 632, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:34] {2392} INFO -  at 259.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:34] {2219} INFO - iteration 633, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:34] {2392} INFO -  at 259.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:34] {2219} INFO - iteration 634, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:34] {2392} INFO -  at 259.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:34] {2219} INFO - iteration 635, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:34] {2392} INFO -  at 259.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:34] {2219} INFO - iteration 636, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:35] {2392} INFO -  at 260.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:35] {2219} INFO - iteration 637, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:35] {2392} INFO -  at 260.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:35] {2219} INFO - iteration 638, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:35] {2392} INFO -  at 260.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:35] {2219} INFO - iteration 639, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:35] {2392} INFO -  at 260.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:35] {2219} INFO - iteration 640, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:36] {2392} INFO -  at 261.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:36] {2219} INFO - iteration 641, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:36] {2392} INFO -  at 261.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:36] {2219} INFO - iteration 642, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:36] {2392} INFO -  at 261.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:36] {2219} INFO - iteration 643, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:36] {2392} INFO -  at 261.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:36] {2219} INFO - iteration 644, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:37] {2392} INFO -  at 262.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:37] {2219} INFO - iteration 645, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:37] {2392} INFO -  at 262.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:37] {2219} INFO - iteration 646, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:37] {2392} INFO -  at 262.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:37] {2219} INFO - iteration 647, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:38] {2392} INFO -  at 263.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:38] {2219} INFO - iteration 648, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:38] {2392} INFO -  at 263.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:38] {2219} INFO - iteration 649, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:38] {2392} INFO -  at 263.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:38] {2219} INFO - iteration 650, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:38] {2392} INFO -  at 263.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:38] {2219} INFO - iteration 651, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:38] {2392} INFO -  at 263.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:38] {2219} INFO - iteration 652, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:40] {2392} INFO -  at 265.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:40] {2219} INFO - iteration 653, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:41] {2392} INFO -  at 266.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:41] {2219} INFO - iteration 654, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:41] {2392} INFO -  at 266.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:41] {2219} INFO - iteration 655, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:41] {2392} INFO -  at 266.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:41] {2219} INFO - iteration 656, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:42] {2392} INFO -  at 267.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:42] {2219} INFO - iteration 657, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:42] {2392} INFO -  at 267.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:42] {2219} INFO - iteration 658, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:42] {2392} INFO -  at 267.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:42] {2219} INFO - iteration 659, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:42] {2392} INFO -  at 267.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:42] {2219} INFO - iteration 660, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:43] {2392} INFO -  at 268.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:43] {2219} INFO - iteration 661, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:43] {2392} INFO -  at 268.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:43] {2219} INFO - iteration 662, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:43] {2392} INFO -  at 268.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:43] {2219} INFO - iteration 663, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:44] {2392} INFO -  at 269.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:44] {2219} INFO - iteration 664, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:44] {2392} INFO -  at 269.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:44] {2219} INFO - iteration 665, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:44] {2392} INFO -  at 269.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:44] {2219} INFO - iteration 666, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:44] {2392} INFO -  at 269.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:44] {2219} INFO - iteration 667, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:45] {2392} INFO -  at 270.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:45] {2219} INFO - iteration 668, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:45] {2392} INFO -  at 270.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:45] {2219} INFO - iteration 669, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:45] {2392} INFO -  at 270.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:45] {2219} INFO - iteration 670, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:46] {2392} INFO -  at 270.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:46] {2219} INFO - iteration 671, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:46] {2392} INFO -  at 271.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:46] {2219} INFO - iteration 672, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:46] {2392} INFO -  at 271.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:46] {2219} INFO - iteration 673, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:46] {2392} INFO -  at 271.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:46] {2219} INFO - iteration 674, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:47] {2392} INFO -  at 272.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:47] {2219} INFO - iteration 675, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:47] {2392} INFO -  at 272.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:47] {2219} INFO - iteration 676, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:47] {2392} INFO -  at 272.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:47] {2219} INFO - iteration 677, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:48] {2392} INFO -  at 273.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:48] {2219} INFO - iteration 678, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:48] {2392} INFO -  at 273.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:48] {2219} INFO - iteration 679, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:48] {2392} INFO -  at 273.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:48] {2219} INFO - iteration 680, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:48] {2392} INFO -  at 273.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:48] {2219} INFO - iteration 681, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:49] {2392} INFO -  at 274.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:49] {2219} INFO - iteration 682, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:49] {2392} INFO -  at 274.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:49] {2219} INFO - iteration 683, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:49] {2392} INFO -  at 274.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:49] {2219} INFO - iteration 684, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:50] {2392} INFO -  at 275.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:50] {2219} INFO - iteration 685, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:50] {2392} INFO -  at 275.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:50] {2219} INFO - iteration 686, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:50] {2392} INFO -  at 275.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:50] {2219} INFO - iteration 687, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:51] {2392} INFO -  at 276.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:51] {2219} INFO - iteration 688, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:53] {2392} INFO -  at 278.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:53] {2219} INFO - iteration 689, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:53] {2392} INFO -  at 278.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:53] {2219} INFO - iteration 690, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:53] {2392} INFO -  at 278.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:53] {2219} INFO - iteration 691, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:53] {2392} INFO -  at 278.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:53] {2219} INFO - iteration 692, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:54] {2392} INFO -  at 279.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:54] {2219} INFO - iteration 693, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:54] {2392} INFO -  at 279.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:54] {2219} INFO - iteration 694, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:54] {2392} INFO -  at 279.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:54] {2219} INFO - iteration 695, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:55] {2392} INFO -  at 279.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:55] {2219} INFO - iteration 696, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:55] {2392} INFO -  at 280.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:55] {2219} INFO - iteration 697, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:55] {2392} INFO -  at 280.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:55] {2219} INFO - iteration 698, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:55] {2392} INFO -  at 280.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:55] {2219} INFO - iteration 699, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:56] {2392} INFO -  at 281.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:56] {2219} INFO - iteration 700, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:56] {2392} INFO -  at 281.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:56] {2219} INFO - iteration 701, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:57] {2392} INFO -  at 282.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:57] {2219} INFO - iteration 702, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:57] {2392} INFO -  at 282.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:57] {2219} INFO - iteration 703, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:57] {2392} INFO -  at 282.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:57] {2219} INFO - iteration 704, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:57] {2392} INFO -  at 282.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:57] {2219} INFO - iteration 705, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:58] {2392} INFO -  at 283.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:58] {2219} INFO - iteration 706, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:58] {2392} INFO -  at 283.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:58] {2219} INFO - iteration 707, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:58] {2392} INFO -  at 283.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:58] {2219} INFO - iteration 708, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:58] {2392} INFO -  at 283.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:58] {2219} INFO - iteration 709, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:59] {2392} INFO -  at 284.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:59] {2219} INFO - iteration 710, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:59] {2392} INFO -  at 284.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:59] {2219} INFO - iteration 711, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:59] {2392} INFO -  at 284.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:59] {2219} INFO - iteration 712, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:23:59] {2392} INFO -  at 284.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:23:59] {2219} INFO - iteration 713, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:00] {2392} INFO -  at 285.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:00] {2219} INFO - iteration 714, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:00] {2392} INFO -  at 285.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:00] {2219} INFO - iteration 715, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:00] {2392} INFO -  at 285.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:00] {2219} INFO - iteration 716, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:00] {2392} INFO -  at 285.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:00] {2219} INFO - iteration 717, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:01] {2392} INFO -  at 286.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:01] {2219} INFO - iteration 718, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:01] {2392} INFO -  at 286.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:01] {2219} INFO - iteration 719, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:01] {2392} INFO -  at 286.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:01] {2219} INFO - iteration 720, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:02] {2392} INFO -  at 287.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:02] {2219} INFO - iteration 721, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:02] {2392} INFO -  at 287.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:02] {2219} INFO - iteration 722, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:02] {2392} INFO -  at 287.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:02] {2219} INFO - iteration 723, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:03] {2392} INFO -  at 288.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:03] {2219} INFO - iteration 724, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:03] {2392} INFO -  at 288.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:03] {2219} INFO - iteration 725, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:05] {2392} INFO -  at 290.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:05] {2219} INFO - iteration 726, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:05] {2392} INFO -  at 290.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:05] {2219} INFO - iteration 727, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:05] {2392} INFO -  at 290.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:05] {2219} INFO - iteration 728, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:05] {2392} INFO -  at 290.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:05] {2219} INFO - iteration 729, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:06] {2392} INFO -  at 291.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:06] {2219} INFO - iteration 730, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:06] {2392} INFO -  at 291.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:06] {2219} INFO - iteration 731, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:06] {2392} INFO -  at 291.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:06] {2219} INFO - iteration 732, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:06] {2392} INFO -  at 291.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:06] {2219} INFO - iteration 733, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:07] {2392} INFO -  at 292.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:07] {2219} INFO - iteration 734, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:07] {2392} INFO -  at 292.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:07] {2219} INFO - iteration 735, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:07] {2392} INFO -  at 292.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:07] {2219} INFO - iteration 736, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:07] {2392} INFO -  at 292.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:07] {2219} INFO - iteration 737, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:08] {2392} INFO -  at 293.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:08] {2219} INFO - iteration 738, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:08] {2392} INFO -  at 293.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:08] {2219} INFO - iteration 739, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:08] {2392} INFO -  at 293.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:08] {2219} INFO - iteration 740, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:08] {2392} INFO -  at 293.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:08] {2219} INFO - iteration 741, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:09] {2392} INFO -  at 294.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:09] {2219} INFO - iteration 742, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:09] {2392} INFO -  at 294.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:09] {2219} INFO - iteration 743, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:09] {2392} INFO -  at 294.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:09] {2219} INFO - iteration 744, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:09] {2392} INFO -  at 294.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:09] {2219} INFO - iteration 745, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:10] {2392} INFO -  at 295.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:10] {2219} INFO - iteration 746, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:10] {2392} INFO -  at 295.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:10] {2219} INFO - iteration 747, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:10] {2392} INFO -  at 295.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:10] {2219} INFO - iteration 748, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:10] {2392} INFO -  at 295.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:10] {2219} INFO - iteration 749, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:11] {2392} INFO -  at 296.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:11] {2219} INFO - iteration 750, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:11] {2392} INFO -  at 296.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:11] {2219} INFO - iteration 751, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:11] {2392} INFO -  at 296.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:11] {2219} INFO - iteration 752, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:12] {2392} INFO -  at 296.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:12] {2219} INFO - iteration 753, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:12] {2392} INFO -  at 297.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:12] {2219} INFO - iteration 754, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:12] {2392} INFO -  at 297.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:12] {2219} INFO - iteration 755, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:12] {2392} INFO -  at 297.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:12] {2219} INFO - iteration 756, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:13] {2392} INFO -  at 298.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:13] {2219} INFO - iteration 757, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:13] {2392} INFO -  at 298.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:13] {2219} INFO - iteration 758, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:13] {2392} INFO -  at 298.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:13] {2219} INFO - iteration 759, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:13] {2392} INFO -  at 298.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:13] {2219} INFO - iteration 760, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:13] {2392} INFO -  at 298.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:13] {2219} INFO - iteration 761, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:14] {2392} INFO -  at 299.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:14] {2219} INFO - iteration 762, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:14] {2392} INFO -  at 299.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:14] {2219} INFO - iteration 763, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:14] {2392} INFO -  at 299.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:14] {2219} INFO - iteration 764, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:14] {2392} INFO -  at 299.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:14] {2219} INFO - iteration 765, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:15] {2392} INFO -  at 300.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:15] {2219} INFO - iteration 766, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:16] {2392} INFO -  at 301.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:16] {2219} INFO - iteration 767, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:16] {2392} INFO -  at 301.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:16] {2219} INFO - iteration 768, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:17] {2392} INFO -  at 302.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:17] {2219} INFO - iteration 769, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:17] {2392} INFO -  at 302.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:17] {2219} INFO - iteration 770, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:18] {2392} INFO -  at 303.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:18] {2219} INFO - iteration 771, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:18] {2392} INFO -  at 303.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:18] {2219} INFO - iteration 772, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:18] {2392} INFO -  at 303.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:18] {2219} INFO - iteration 773, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:18] {2392} INFO -  at 303.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:18] {2219} INFO - iteration 774, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:19] {2392} INFO -  at 304.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:19] {2219} INFO - iteration 775, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:19] {2392} INFO -  at 304.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:19] {2219} INFO - iteration 776, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:19] {2392} INFO -  at 304.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:19] {2219} INFO - iteration 777, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:19] {2392} INFO -  at 304.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:19] {2219} INFO - iteration 778, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:20] {2392} INFO -  at 305.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:20] {2219} INFO - iteration 779, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:20] {2392} INFO -  at 305.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:20] {2219} INFO - iteration 780, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:20] {2392} INFO -  at 305.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:20] {2219} INFO - iteration 781, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:21] {2392} INFO -  at 306.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:21] {2219} INFO - iteration 782, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:21] {2392} INFO -  at 306.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:21] {2219} INFO - iteration 783, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:21] {2392} INFO -  at 306.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:21] {2219} INFO - iteration 784, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:21] {2392} INFO -  at 306.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:21] {2219} INFO - iteration 785, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:22] {2392} INFO -  at 307.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:22] {2219} INFO - iteration 786, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:22] {2392} INFO -  at 307.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:22] {2219} INFO - iteration 787, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:22] {2392} INFO -  at 307.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:22] {2219} INFO - iteration 788, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:23] {2392} INFO -  at 308.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:23] {2219} INFO - iteration 789, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:23] {2392} INFO -  at 308.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:23] {2219} INFO - iteration 790, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:23] {2392} INFO -  at 308.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:23] {2219} INFO - iteration 791, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:23] {2392} INFO -  at 308.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:23] {2219} INFO - iteration 792, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:24] {2392} INFO -  at 309.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:24] {2219} INFO - iteration 793, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:24] {2392} INFO -  at 309.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:24] {2219} INFO - iteration 794, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:24] {2392} INFO -  at 309.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:24] {2219} INFO - iteration 795, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:25] {2392} INFO -  at 309.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:25] {2219} INFO - iteration 796, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:25] {2392} INFO -  at 310.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:25] {2219} INFO - iteration 797, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:25] {2392} INFO -  at 310.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:25] {2219} INFO - iteration 798, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:25] {2392} INFO -  at 310.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:25] {2219} INFO - iteration 799, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:25] {2392} INFO -  at 310.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:25] {2219} INFO - iteration 800, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:26] {2392} INFO -  at 311.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:26] {2219} INFO - iteration 801, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:26] {2392} INFO -  at 311.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:26] {2219} INFO - iteration 802, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:26] {2392} INFO -  at 311.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:26] {2219} INFO - iteration 803, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:27] {2392} INFO -  at 312.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:27] {2219} INFO - iteration 804, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:27] {2392} INFO -  at 312.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:27] {2219} INFO - iteration 805, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:29] {2392} INFO -  at 314.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:29] {2219} INFO - iteration 806, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:29] {2392} INFO -  at 314.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:29] {2219} INFO - iteration 807, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:30] {2392} INFO -  at 315.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:30] {2219} INFO - iteration 808, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:30] {2392} INFO -  at 315.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:30] {2219} INFO - iteration 809, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:30] {2392} INFO -  at 315.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:30] {2219} INFO - iteration 810, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:30] {2392} INFO -  at 315.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:30] {2219} INFO - iteration 811, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:30] {2392} INFO -  at 315.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:30] {2219} INFO - iteration 812, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:31] {2392} INFO -  at 316.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:31] {2219} INFO - iteration 813, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:31] {2392} INFO -  at 316.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:31] {2219} INFO - iteration 814, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:31] {2392} INFO -  at 316.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:31] {2219} INFO - iteration 815, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:31] {2392} INFO -  at 316.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:31] {2219} INFO - iteration 816, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:32] {2392} INFO -  at 317.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:32] {2219} INFO - iteration 817, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:32] {2392} INFO -  at 317.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:32] {2219} INFO - iteration 818, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:32] {2392} INFO -  at 317.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:32] {2219} INFO - iteration 819, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:32] {2392} INFO -  at 317.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:32] {2219} INFO - iteration 820, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:33] {2392} INFO -  at 318.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:33] {2219} INFO - iteration 821, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:33] {2392} INFO -  at 318.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:33] {2219} INFO - iteration 822, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:33] {2392} INFO -  at 318.7s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:33] {2219} INFO - iteration 823, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:34] {2392} INFO -  at 319.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:34] {2219} INFO - iteration 824, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:34] {2392} INFO -  at 319.2s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:34] {2219} INFO - iteration 825, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:34] {2392} INFO -  at 319.5s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:34] {2219} INFO - iteration 826, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:34] {2392} INFO -  at 319.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:34] {2219} INFO - iteration 827, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:34] {2392} INFO -  at 319.9s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:34] {2219} INFO - iteration 828, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:35] {2392} INFO -  at 320.1s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:35] {2219} INFO - iteration 829, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:35] {2392} INFO -  at 320.4s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:35] {2219} INFO - iteration 830, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:35] {2392} INFO -  at 320.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:35] {2219} INFO - iteration 831, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:36] {2392} INFO -  at 321.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:36] {2219} INFO - iteration 832, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:36] {2392} INFO -  at 321.3s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:36] {2219} INFO - iteration 833, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:36] {2392} INFO -  at 321.6s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:36] {2219} INFO - iteration 834, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:36] {2392} INFO -  at 321.8s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:36] {2219} INFO - iteration 835, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:37] {2392} INFO -  at 322.0s,\testimator lgbm's best error=0.4092,\tbest estimator lgbm's best error=0.4092\n",
            "[flaml.automl.logger: 03-18 08:24:37] {2219} INFO - iteration 836, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:37] {2392} INFO -  at 322.4s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:37] {2219} INFO - iteration 837, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:37] {2392} INFO -  at 322.6s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:37] {2219} INFO - iteration 838, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:38] {2392} INFO -  at 323.3s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:38] {2219} INFO - iteration 839, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:38] {2392} INFO -  at 323.6s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:38] {2219} INFO - iteration 840, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:39] {2392} INFO -  at 324.2s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:39] {2219} INFO - iteration 841, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:40] {2392} INFO -  at 325.2s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:40] {2219} INFO - iteration 842, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:41] {2392} INFO -  at 326.5s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:41] {2219} INFO - iteration 843, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:41] {2392} INFO -  at 326.8s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:41] {2219} INFO - iteration 844, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:42] {2392} INFO -  at 327.3s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:42] {2219} INFO - iteration 845, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:42] {2392} INFO -  at 327.5s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:42] {2219} INFO - iteration 846, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:42] {2392} INFO -  at 327.9s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:42] {2219} INFO - iteration 847, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:43] {2392} INFO -  at 328.2s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:43] {2219} INFO - iteration 848, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:43] {2392} INFO -  at 328.7s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:43] {2219} INFO - iteration 849, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:44] {2392} INFO -  at 329.1s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:44] {2219} INFO - iteration 850, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:44] {2392} INFO -  at 329.4s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:44] {2219} INFO - iteration 851, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:44] {2392} INFO -  at 329.7s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:44] {2219} INFO - iteration 852, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:45] {2392} INFO -  at 330.2s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:45] {2219} INFO - iteration 853, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:45] {2392} INFO -  at 330.7s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:45] {2219} INFO - iteration 854, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:45] {2392} INFO -  at 330.9s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:45] {2219} INFO - iteration 855, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:46] {2392} INFO -  at 331.4s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:46] {2219} INFO - iteration 856, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:46] {2392} INFO -  at 331.7s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:46] {2219} INFO - iteration 857, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:47] {2392} INFO -  at 332.2s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:47] {2219} INFO - iteration 858, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:47] {2392} INFO -  at 332.5s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:47] {2219} INFO - iteration 859, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:47] {2392} INFO -  at 332.8s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:47] {2219} INFO - iteration 860, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:48] {2392} INFO -  at 333.3s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:48] {2219} INFO - iteration 861, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:48] {2392} INFO -  at 333.7s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:48] {2219} INFO - iteration 862, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:48] {2392} INFO -  at 333.9s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:48] {2219} INFO - iteration 863, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:49] {2392} INFO -  at 334.2s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:49] {2219} INFO - iteration 864, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:49] {2392} INFO -  at 334.7s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:49] {2219} INFO - iteration 865, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:50] {2392} INFO -  at 335.0s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:50] {2219} INFO - iteration 866, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:50] {2392} INFO -  at 335.3s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:50] {2219} INFO - iteration 867, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:50] {2392} INFO -  at 335.7s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:50] {2219} INFO - iteration 868, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:51] {2392} INFO -  at 336.1s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:51] {2219} INFO - iteration 869, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:51] {2392} INFO -  at 336.3s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:51] {2219} INFO - iteration 870, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:53] {2392} INFO -  at 338.7s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:53] {2219} INFO - iteration 871, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:54] {2392} INFO -  at 339.0s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:54] {2219} INFO - iteration 872, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:54] {2392} INFO -  at 339.5s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:54] {2219} INFO - iteration 873, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:55] {2392} INFO -  at 340.0s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:55] {2219} INFO - iteration 874, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:55] {2392} INFO -  at 340.3s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:55] {2219} INFO - iteration 875, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:55] {2392} INFO -  at 340.8s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:55] {2219} INFO - iteration 876, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:56] {2392} INFO -  at 341.1s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:56] {2219} INFO - iteration 877, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:56] {2392} INFO -  at 341.3s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:56] {2219} INFO - iteration 878, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:57] {2392} INFO -  at 342.0s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:57] {2219} INFO - iteration 879, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:57] {2392} INFO -  at 342.4s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:57] {2219} INFO - iteration 880, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:57] {2392} INFO -  at 342.8s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:57] {2219} INFO - iteration 881, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:58] {2392} INFO -  at 343.1s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:58] {2219} INFO - iteration 882, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:58] {2392} INFO -  at 343.6s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:58] {2219} INFO - iteration 883, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:59] {2392} INFO -  at 344.0s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:59] {2219} INFO - iteration 884, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:24:59] {2392} INFO -  at 344.4s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:24:59] {2219} INFO - iteration 885, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:00] {2392} INFO -  at 345.1s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:00] {2219} INFO - iteration 886, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:00] {2392} INFO -  at 345.2s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:00] {2219} INFO - iteration 887, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:00] {2392} INFO -  at 345.5s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:00] {2219} INFO - iteration 888, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:01] {2392} INFO -  at 346.4s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:01] {2219} INFO - iteration 889, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:01] {2392} INFO -  at 346.8s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:01] {2219} INFO - iteration 890, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:02] {2392} INFO -  at 347.1s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:02] {2219} INFO - iteration 891, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:02] {2392} INFO -  at 347.3s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:02] {2219} INFO - iteration 892, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:02] {2392} INFO -  at 347.8s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:02] {2219} INFO - iteration 893, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:03] {2392} INFO -  at 348.0s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:03] {2219} INFO - iteration 894, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:05] {2392} INFO -  at 350.2s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:05] {2219} INFO - iteration 895, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:05] {2392} INFO -  at 350.8s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:05] {2219} INFO - iteration 896, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:06] {2392} INFO -  at 351.0s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:06] {2219} INFO - iteration 897, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:06] {2392} INFO -  at 351.3s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:06] {2219} INFO - iteration 898, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:06] {2392} INFO -  at 351.7s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:06] {2219} INFO - iteration 899, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:07] {2392} INFO -  at 352.4s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:07] {2219} INFO - iteration 900, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:07] {2392} INFO -  at 352.6s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:07] {2219} INFO - iteration 901, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:08] {2392} INFO -  at 353.7s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:08] {2219} INFO - iteration 902, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:08] {2392} INFO -  at 353.9s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:08] {2219} INFO - iteration 903, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:09] {2392} INFO -  at 354.4s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:09] {2219} INFO - iteration 904, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:09] {2392} INFO -  at 354.6s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:09] {2219} INFO - iteration 905, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:09] {2392} INFO -  at 354.8s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:09] {2219} INFO - iteration 906, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:10] {2392} INFO -  at 355.4s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:10] {2219} INFO - iteration 907, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:10] {2392} INFO -  at 355.8s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:10] {2219} INFO - iteration 908, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:11] {2392} INFO -  at 356.0s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:11] {2219} INFO - iteration 909, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:11] {2392} INFO -  at 356.5s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:11] {2219} INFO - iteration 910, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:11] {2392} INFO -  at 356.8s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:11] {2219} INFO - iteration 911, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:12] {2392} INFO -  at 357.2s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:12] {2219} INFO - iteration 912, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:12] {2392} INFO -  at 357.5s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:12] {2219} INFO - iteration 913, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:13] {2392} INFO -  at 358.0s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:13] {2219} INFO - iteration 914, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:13] {2392} INFO -  at 358.2s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:13] {2219} INFO - iteration 915, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:13] {2392} INFO -  at 358.7s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:13] {2219} INFO - iteration 916, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:14] {2392} INFO -  at 359.0s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:14] {2219} INFO - iteration 917, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:14] {2392} INFO -  at 359.3s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:14] {2219} INFO - iteration 918, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:14] {2392} INFO -  at 359.6s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:14] {2219} INFO - iteration 919, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:15] {2392} INFO -  at 359.9s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:15] {2219} INFO - iteration 920, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:17] {2392} INFO -  at 362.1s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:17] {2219} INFO - iteration 921, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:17] {2392} INFO -  at 362.4s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:17] {2219} INFO - iteration 922, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:17] {2392} INFO -  at 362.7s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:17] {2219} INFO - iteration 923, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:18] {2392} INFO -  at 363.3s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:18] {2219} INFO - iteration 924, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:18] {2392} INFO -  at 363.5s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:18] {2219} INFO - iteration 925, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:19] {2392} INFO -  at 364.0s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:19] {2219} INFO - iteration 926, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:19] {2392} INFO -  at 364.2s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:19] {2219} INFO - iteration 927, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:19] {2392} INFO -  at 364.7s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:19] {2219} INFO - iteration 928, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:20] {2392} INFO -  at 364.9s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:20] {2219} INFO - iteration 929, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:20] {2392} INFO -  at 365.2s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:20] {2219} INFO - iteration 930, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:20] {2392} INFO -  at 365.9s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:20] {2219} INFO - iteration 931, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:21] {2392} INFO -  at 366.3s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:21] {2219} INFO - iteration 932, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:21] {2392} INFO -  at 366.7s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:21] {2219} INFO - iteration 933, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:22] {2392} INFO -  at 367.0s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:22] {2219} INFO - iteration 934, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:22] {2392} INFO -  at 367.4s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:22] {2219} INFO - iteration 935, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:22] {2392} INFO -  at 367.8s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:22] {2219} INFO - iteration 936, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:23] {2392} INFO -  at 368.1s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:23] {2219} INFO - iteration 937, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:23] {2392} INFO -  at 368.5s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:23] {2219} INFO - iteration 938, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:23] {2392} INFO -  at 368.9s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:24] {2219} INFO - iteration 939, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:24] {2392} INFO -  at 369.1s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:24] {2219} INFO - iteration 940, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:24] {2392} INFO -  at 369.7s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:24] {2219} INFO - iteration 941, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:25] {2392} INFO -  at 370.1s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:25] {2219} INFO - iteration 942, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:25] {2392} INFO -  at 370.4s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:25] {2219} INFO - iteration 943, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:25] {2392} INFO -  at 370.7s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:25] {2219} INFO - iteration 944, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:26] {2392} INFO -  at 371.1s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:26] {2219} INFO - iteration 945, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:26] {2392} INFO -  at 371.6s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:26] {2219} INFO - iteration 946, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:26] {2392} INFO -  at 371.8s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:26] {2219} INFO - iteration 947, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:28] {2392} INFO -  at 373.0s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:28] {2219} INFO - iteration 948, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:29] {2392} INFO -  at 374.2s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:29] {2219} INFO - iteration 949, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:29] {2392} INFO -  at 374.7s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:29] {2219} INFO - iteration 950, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:30] {2392} INFO -  at 375.0s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:30] {2219} INFO - iteration 951, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:30] {2392} INFO -  at 375.5s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:30] {2219} INFO - iteration 952, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:30] {2392} INFO -  at 375.8s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:30] {2219} INFO - iteration 953, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:31] {2392} INFO -  at 376.1s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:31] {2219} INFO - iteration 954, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:31] {2392} INFO -  at 376.4s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:31] {2219} INFO - iteration 955, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:31] {2392} INFO -  at 376.7s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:31] {2219} INFO - iteration 956, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:32] {2392} INFO -  at 377.4s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:32] {2219} INFO - iteration 957, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:32] {2392} INFO -  at 377.8s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:32] {2219} INFO - iteration 958, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:33] {2392} INFO -  at 378.1s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:33] {2219} INFO - iteration 959, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:33] {2392} INFO -  at 378.3s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:33] {2219} INFO - iteration 960, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:33] {2392} INFO -  at 378.8s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:33] {2219} INFO - iteration 961, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:34] {2392} INFO -  at 379.1s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:34] {2219} INFO - iteration 962, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:34] {2392} INFO -  at 379.8s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:34] {2219} INFO - iteration 963, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:35] {2392} INFO -  at 380.2s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:35] {2219} INFO - iteration 964, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:35] {2392} INFO -  at 380.5s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:35] {2219} INFO - iteration 965, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:35] {2392} INFO -  at 380.9s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:35] {2219} INFO - iteration 966, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:36] {2392} INFO -  at 381.2s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:36] {2219} INFO - iteration 967, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:36] {2392} INFO -  at 381.9s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:36] {2219} INFO - iteration 968, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:37] {2392} INFO -  at 382.1s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:37] {2219} INFO - iteration 969, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:37] {2392} INFO -  at 382.4s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:37] {2219} INFO - iteration 970, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:37] {2392} INFO -  at 382.8s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:37] {2219} INFO - iteration 971, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:38] {2392} INFO -  at 383.1s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:38] {2219} INFO - iteration 972, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:38] {2392} INFO -  at 383.6s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:38] {2219} INFO - iteration 973, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:38] {2392} INFO -  at 383.9s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:38] {2219} INFO - iteration 974, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:41] {2392} INFO -  at 386.0s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:41] {2219} INFO - iteration 975, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:41] {2392} INFO -  at 386.2s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:41] {2219} INFO - iteration 976, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:41] {2392} INFO -  at 386.6s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:41] {2219} INFO - iteration 977, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:42] {2392} INFO -  at 387.2s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:42] {2219} INFO - iteration 978, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:42] {2392} INFO -  at 387.4s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:42] {2219} INFO - iteration 979, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:42] {2392} INFO -  at 387.8s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:42] {2219} INFO - iteration 980, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:43] {2392} INFO -  at 388.1s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:43] {2219} INFO - iteration 981, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:43] {2392} INFO -  at 388.5s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:43] {2219} INFO - iteration 982, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:43] {2392} INFO -  at 388.8s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:43] {2219} INFO - iteration 983, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:44] {2392} INFO -  at 389.2s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:44] {2219} INFO - iteration 984, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:44] {2392} INFO -  at 389.5s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:44] {2219} INFO - iteration 985, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:44] {2392} INFO -  at 389.7s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:44] {2219} INFO - iteration 986, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:45] {2392} INFO -  at 390.2s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:45] {2219} INFO - iteration 987, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:45] {2392} INFO -  at 390.4s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:45] {2219} INFO - iteration 988, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:45] {2392} INFO -  at 390.9s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:45] {2219} INFO - iteration 989, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:46] {2392} INFO -  at 391.3s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:46] {2219} INFO - iteration 990, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:46] {2392} INFO -  at 391.6s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:46] {2219} INFO - iteration 991, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:47] {2392} INFO -  at 392.0s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:47] {2219} INFO - iteration 992, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:47] {2392} INFO -  at 392.3s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:47] {2219} INFO - iteration 993, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:47] {2392} INFO -  at 392.5s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:47] {2219} INFO - iteration 994, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:48] {2392} INFO -  at 393.1s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:48] {2219} INFO - iteration 995, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:48] {2392} INFO -  at 393.7s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:48] {2219} INFO - iteration 996, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:48] {2392} INFO -  at 393.9s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:48] {2219} INFO - iteration 997, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:49] {2392} INFO -  at 394.5s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:49] {2219} INFO - iteration 998, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:49] {2392} INFO -  at 394.7s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:49] {2219} INFO - iteration 999, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:25:50] {2392} INFO -  at 395.1s,\testimator lgbm's best error=0.3659,\tbest estimator lgbm's best error=0.3659\n",
            "[flaml.automl.logger: 03-18 08:25:50] {2494} INFO - selected model: LGBMClassifier(colsample_bytree=0.9654557339580644,\n",
            "               learning_rate=0.39792311661009516, max_bin=1023,\n",
            "               min_child_samples=13, n_estimators=1, n_jobs=-1, num_leaves=5,\n",
            "               reg_alpha=0.0009765625, reg_lambda=1.844318507435322,\n",
            "               verbose=-1)\n",
            "[flaml.automl.logger: 03-18 08:25:50] {1931} INFO - fit succeeded\n",
            "[flaml.automl.logger: 03-18 08:25:50] {1932} INFO - Time taken to find the best model: 322.3725600242615\n"
          ]
        }
      ],
      "source": [
        "# !pip -q install flaml\n",
        "from flaml import AutoML\n",
        "automl = AutoML()\n",
        "automl.fit(indicators, target, X_val=val_indicators,y_val=val_target, max_iter=1000,metric='micro_f1',estimator_list=[\"lgbm\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8gpIwfrTzib"
      },
      "source": [
        "This didn't work any better obviously. Same results. the next method would be to decompose the closing price into 4 signals using wavelet transform, and use each of those 4 signals to generate indicators using window sizes from our analysis.\n",
        "\n",
        "Moreover, I will also be using these features for each of the closing prices, which will tell us about the moving naturee of each of the 4 resultant closing prices.\n",
        "\n",
        "**Mean**: The average value of the closing prices in the window.\n",
        "\n",
        "**Harmonic Mean**: The reciprocal of the arithmetic mean of the reciprocals of the closing prices in the window.\n",
        "\n",
        "**Standard Deviation**: Measures the amount of variation or dispersion of the closing prices in the window.\n",
        "\n",
        "**Variance**: The square of the standard deviation.\n",
        "Kurtosis: Describes the shape of the probability distribution of the closing prices in the window.\n",
        "\n",
        "\n",
        "**Root Mean Square (RMS)**: The square root of the mean square (the arithmetic mean of the squares of the closing prices).\n",
        "\n",
        "**Shape Factor:** The ratio of the RMS to the mean.\n",
        "\n",
        "**Peak Value:** The maximum closing price in the window.\n",
        "\n",
        "**Peak-to-Peak Value:** The difference between the maximum and minimum closing prices in the window.\n",
        "\n",
        "**Interquartile Range**: The range between the first quartile (25th percentile) and the third quartile (75th percentile) of the closing prices in the window.\n",
        "\n",
        "**Shannon Entropy:** A measure of the uncertainty or randomness of the closing prices in the window.\n",
        "Summation: The total sum of the closing prices in the window.\n",
        "\n",
        "**Max Frequency, Peak Frequency, Bandwidth:** These are frequency-domain features that can be calculated from the Fast Fourier Transform (FFT) of the closing prices.\n",
        "\n",
        "**Signal-to-Noise Ratio (SNR):** The ratio of the power of a signal (meaningful information) and the power of background noise (unwanted signal).\n",
        "\n",
        "**Spectral Entropy:** Entropy of the power spectral density (PSD) of the closing prices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tonxakyi9Jgs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import signal\n",
        "from scipy.stats import skew, kurtosis\n",
        "import pywt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7WKVP1VZ6uO"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"/content/Manappuram_10minute.csv\")\n",
        "df.tail(5)\n",
        "# Converting Date column into datetime dftype\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df.set_index('Date', inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tak-941ubbM5",
        "outputId": "af11a01c-6def-4ef5-d875-09b2337d6e8f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Open', 'High', 'Low', 'Close', 'Volume'], dtype='object')"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b-alSp6Z6uP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import scipy.signal as signal\n",
        "from scipy.fft import fft\n",
        "\n",
        "# Define the window size\n",
        "window_size = 38*3\n",
        "\n",
        "# Calculate the mean\n",
        "df['Mean'] = df['Close'].rolling(window=window_size).mean()\n",
        "\n",
        "# Calculate the harmonic mean\n",
        "df['Harmonic_Mean'] = df['Close'].rolling(window=window_size).apply(lambda x: stats.hmean(x))\n",
        "\n",
        "# Calculate the standard deviation\n",
        "df['Standard_Deviation'] = df['Close'].rolling(window=window_size).std()\n",
        "\n",
        "# Calculate the variance\n",
        "df['Variance'] = df['Close'].rolling(window=window_size).var()\n",
        "\n",
        "\n",
        "df['Slope'] = df['Close'].rolling(window=window_size).apply(lambda x: (x.max() - x.min()) / window_size)\n",
        "df['Slope_Start_End'] = df['Close'].rolling(window=window_size).apply(lambda x: (x[-1] - x[0]) / (window_size - 1))\n",
        "\n",
        "\n",
        "\n",
        "# Calculate the kurtosis\n",
        "df['Kurtosis'] = df['Close'].rolling(window=window_size).apply(lambda x: stats.kurtosis(x))\n",
        "\n",
        "# Calculate the root mean square (RMS)\n",
        "df['RMS'] = df['Close'].rolling(window=window_size).apply(lambda x: np.sqrt(np.mean(np.square(x))))\n",
        "\n",
        "# Calculate the shape factor\n",
        "df['Shape_Factor'] = df['RMS'] / df['Mean']\n",
        "\n",
        "# Calculate the peak value\n",
        "df['Peak_Value'] = df['Close'].rolling(window=window_size).max()\n",
        "\n",
        "# Calculate the peak-to-peak value\n",
        "df['Peak_to_Peak_Value'] = df['Close'].rolling(window=window_size).apply(lambda x: np.ptp(x))\n",
        "\n",
        "# Calculate the interquartile range\n",
        "df['Interquartile_Range'] = df['Close'].rolling(window=window_size).apply(lambda x: np.subtract(*np.percentile(x, [75, 25])))\n",
        "\n",
        "# Calculate the Shannon entropy\n",
        "df['Shannon_Entropy'] = df['Close'].rolling(window=window_size).apply(lambda x: stats.entropy(x))\n",
        "\n",
        "# Calculate the summation\n",
        "df['Summation'] = df['Close'].rolling(window=window_size).sum()\n",
        "\n",
        "# Calculate the signal-to-noise ratio (SNR)\n",
        "df['SNR'] = df['Close'].rolling(window=window_size).apply(lambda x: np.mean(x) / np.std(x))\n",
        "\n",
        "# Calculate the spectral entropy\n",
        "# df['Spectral_Entropy'] = df['Close'].rolling(window=window_size).apply(lambda x: stats.entropy(np.abs(fft(x))))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aogNtFCXzYV0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import scipy.signal as signal\n",
        "from scipy.fft import fft\n",
        "\n",
        "# Define the window size\n",
        "window_size = 38*3\n",
        "\n",
        "# Calculate the mean\n",
        "df['Volume_Mean'] = df['Volume'].rolling(window=window_size).mean()\n",
        "\n",
        "# Calculate the harmonic mean\n",
        "df['Volume_Harmonic_Mean'] = df['Volume'].rolling(window=window_size).apply(lambda x: stats.hmean(x))\n",
        "\n",
        "# Calculate the standard deviation\n",
        "df['Volume_Standard_Deviation'] = df['Volume'].rolling(window=window_size).std()\n",
        "\n",
        "# Calculate the variance\n",
        "df['Volume_Variance'] = df['Volume'].rolling(window=window_size).var()\n",
        "\n",
        "\n",
        "df['Volume_Slope'] = df['Volume'].rolling(window=window_size).apply(lambda x: (x.max() - x.min()) / window_size)\n",
        "df['Volume_Slope_Start_End'] = df['Volume'].rolling(window=window_size).apply(lambda x: (x[-1] - x[0]) / (window_size - 1))\n",
        "\n",
        "\n",
        "\n",
        "# Calculate the kurtosis\n",
        "df['Volume_Kurtosis'] = df['Volume'].rolling(window=window_size).apply(lambda x: stats.kurtosis(x))\n",
        "\n",
        "# Calculate the root mean square (RMS)\n",
        "df['Volume_RMS'] = df['Volume'].rolling(window=window_size).apply(lambda x: np.sqrt(np.mean(np.square(x))))\n",
        "\n",
        "# Calculate the shape factor\n",
        "df['Volume_Shape_Factor'] = df['RMS'] / df['Mean']\n",
        "\n",
        "# Calculate the peak value\n",
        "df['Volume_Peak_Value'] = df['Volume'].rolling(window=window_size).max()\n",
        "\n",
        "# Calculate the peak-to-peak value\n",
        "df['Volume_Peak_to_Peak_Value'] = df['Volume'].rolling(window=window_size).apply(lambda x: np.ptp(x))\n",
        "\n",
        "# Calculate the interquartile range\n",
        "df['Volume_Interquartile_Range'] = df['Volume'].rolling(window=window_size).apply(lambda x: np.subtract(*np.percentile(x, [75, 25])))\n",
        "\n",
        "# Calculate the Shannon entropy\n",
        "df['Volume_Shannon_Entropy'] = df['Volume'].rolling(window=window_size).apply(lambda x: stats.entropy(x))\n",
        "\n",
        "# Calculate the summation\n",
        "df['Volume_Summation'] = df['Volume'].rolling(window=window_size).sum()\n",
        "\n",
        "# Calculate the signal-to-noise ratio (SNR)\n",
        "df['Volume_SNR'] = df['Volume'].rolling(window=window_size).apply(lambda x: np.mean(x) / np.std(x))\n",
        "\n",
        "# Calculate the spectral entropy\n",
        "# df['Spectral_Entropy'] = df['Volume'].rolling(window=window_size).apply(lambda x: stats.entropy(np.abs(fft(x))))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQPIsP2MZz46",
        "outputId": "54a458ee-3aa9-471d-9566-2c907e235d78"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Mean', 'Harmonic_Mean',\n",
              "       'Standard_Deviation', 'Variance', 'Slope', 'Slope_Start_End',\n",
              "       'Kurtosis', 'RMS', 'Shape_Factor', 'Peak_Value', 'Peak_to_Peak_Value',\n",
              "       'Interquartile_Range', 'Shannon_Entropy', 'Summation', 'SNR',\n",
              "       'Volume_Mean', 'Volume_Harmonic_Mean', 'Volume_Standard_Deviation',\n",
              "       'Volume_Variance', 'Volume_Slope', 'Volume_Slope_Start_End',\n",
              "       'Volume_Kurtosis', 'Volume_RMS', 'Volume_Shape_Factor',\n",
              "       'Volume_Peak_Value', 'Volume_Peak_to_Peak_Value',\n",
              "       'Volume_Interquartile_Range', 'Volume_Shannon_Entropy',\n",
              "       'Volume_Summation', 'Volume_SNR'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHve8nvBemyk"
      },
      "outputs": [],
      "source": [
        "# calculates SMA using \"n\" as the rolling window size\n",
        "def ma_calc(df, n):\n",
        "  df[\"sma\"] = df.Close.rolling(window=n).mean()\n",
        "  return df\n",
        "\n",
        "# calculates SMA using \"m\" and \"n\" as the rolling window size\n",
        "def longshort_ma_calc(df, m, n):\n",
        "  df[\"sma_short\"] = df.Close.rolling(window=min(m,n)).mean()\n",
        "  df[\"sma_long\"] = df.Close.rolling(window=max(m,n)).mean()\n",
        "  return df\n",
        "\n",
        "# calculates EMA using \"n\" as the rolling window size\n",
        "def ema_calc(df, n):\n",
        "  df[\"ema\"] = df.Close.ewm(span=n, adjust=False).mean()\n",
        "  return df\n",
        "\n",
        "\n",
        "def longshort_ema_calc(df, m, n):\n",
        "  df[\"ema_short\"] = df.Close.ewm(span=min(m,n), adjust=False).mean()\n",
        "  df[\"ema_long\"] = df.Close.ewm(span=max(m,n), adjust=False).mean()\n",
        "  return df\n",
        "\n",
        "# calculates RSI using \"n\" as the lookback period\n",
        "def rsi_calc(df, n):\n",
        "  df['rsi'] = 100 - (100 / (1 + df['Close'].diff().apply(lambda x: x if x > 0 else 0).rolling(window=n).mean() / df['Close'].diff().apply(lambda x: -x if x < 0 else 0).rolling(window=n).mean()))\n",
        "  return df\n",
        "\n",
        "# calculates OBV\n",
        "def obv_calc(df):\n",
        "  df['obv'] = (np.sign(df['Close'].diff()) * df['Volume']).fillna(0).cumsum()\n",
        "  return df\n",
        "\n",
        "def bb_calc(df, n):\n",
        "  df[\"sma\"] = df.Close.rolling(window=n).mean()\n",
        "  df[\"std\"] = df.Close.rolling(window=n).std()\n",
        "  df[\"upper_bb\"] = df[\"sma\"] + (2 * df[\"std\"])\n",
        "  df[\"lower_bb\"] = df[\"sma\"] - (2 * df[\"std\"])\n",
        "  return df\n",
        "\n",
        "# Volume weighted average price\n",
        "def vwap_calc(df):\n",
        "    df['vwap'] = (df['Volume'] * df['Close']).cumsum() / df['Volume'].cumsum()\n",
        "    return df\n",
        "\n",
        "# Supertrend Indicator\n",
        "def supertrend_calc(df, period, multiplier):\n",
        "    # Calculate basic upper and lower bands\n",
        "    df['hl_avg'] = (df['High'] + df['Low']) / 2\n",
        "    df['range'] = df['High'] - df['Low']\n",
        "    df['upper_band'] = df['hl_avg'] + multiplier * df['range']\n",
        "    df['lower_band'] = df['hl_avg'] - multiplier * df['range']\n",
        "\n",
        "    # Calculate final upper and lower bands\n",
        "    df['upper_band_final'] = np.where((df['upper_band'] < df['upper_band'].shift(1)) | (df['Close'] > df['upper_band'].shift(1)), df['upper_band'], df['upper_band'].shift(1))\n",
        "    df['lower_band_final'] = np.where((df['lower_band'] > df['lower_band'].shift(1)) | (df['Close'] < df['lower_band'].shift(1)), df['lower_band'], df['lower_band'].shift(1))\n",
        "\n",
        "    # Calculate Supertrend\n",
        "    df['supertrend'] = np.where(df['Close'] <= df['upper_band_final'], df['upper_band_final'], df['lower_band_final'])\n",
        "    df['supertrend'] = np.where(df['Close'] >= df['lower_band_final'], df['lower_band_final'], df['supertrend'])\n",
        "\n",
        "    return df\n",
        "\n",
        "# calculates Average Directional Index (ADX)\n",
        "def adx_calc(df, n):\n",
        "    df['hl_diff'] = df['High'] - df['Low']\n",
        "    df['hc_diff'] = abs(df['High'] - df['Close'].shift(1))\n",
        "    df['lc_diff'] = abs(df['Low'] - df['Close'].shift(1))\n",
        "    df['tr'] = df[['hl_diff', 'hc_diff', 'lc_diff']].max(axis=1)\n",
        "    df['+dm'] = np.where((df['High'] > df['High'].shift(1)) & (df['High'] - df['High'].shift(1) > df['Low'].shift(1) - df['Low']), df['High'] - df['High'].shift(1), 0)\n",
        "    df['-dm'] = np.where((df['Low'] < df['Low'].shift(1)) & (df['High'].shift(1) - df['High'] < df['Low'].shift(1) - df['Low']), df['Low'].shift(1) - df['Low'], 0)\n",
        "    df['tr_ema'] = df['tr'].ewm(span=n, adjust=False).mean()\n",
        "    df['+dm_ema'] = df['+dm'].ewm(span=n, adjust=False).mean()\n",
        "    df['-dm_ema'] = df['-dm'].ewm(span=n, adjust=False).mean()\n",
        "    df['+di'] = (df['+dm_ema'] / df['tr_ema']) * 100\n",
        "    df['-di'] = (df['-dm_ema'] / df['tr_ema']) * 100\n",
        "    df['dx'] = (abs(df['+di'] - df['-di']) / (df['+di'] + df['-di'])) * 100\n",
        "    df['adx'] = df['dx'].rolling(window=n).mean()\n",
        "\n",
        "    return df\n",
        "\n",
        "# calculates MACD\n",
        "def macd_calc(df, short_n, long_n, signal_n):\n",
        "    df['ema_short'] = df['Close'].ewm(span=short_n, adjust=False).mean()\n",
        "    df['ema_long'] = df['Close'].ewm(span=long_n, adjust=False).mean()\n",
        "    df['macd_line'] = df['ema_short'] - df['ema_long']\n",
        "    df['signal_line'] = df['macd_line'].ewm(span=signal_n, adjust=False).mean()\n",
        "    df['macd_histogram'] = df['macd_line'] - df['signal_line']\n",
        "\n",
        "    return df\n",
        "\n",
        "def find_extrema(df, n):\n",
        "    df['min'] = df.iloc[argrelextrema(df['Close'].values, np.less_equal, order=n)[0]]['Close']\n",
        "    df['max'] = df.iloc[argrelextrema(df['Close'].values, np.greater_equal, order=n)[0]]['Close']\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zz1SlwWemyw"
      },
      "outputs": [],
      "source": [
        "df=find_extrema(df,16)\n",
        "df=ma_calc(df,524)\n",
        "df=longshort_ma_calc(df,564,4)\n",
        "df=ema_calc(df,63)\n",
        "df=longshort_ema_calc(df,374,5)\n",
        "df=rsi_calc(df,118)\n",
        "df=adx_calc(df,32)\n",
        "\n",
        "# columns_to_drop = ['hl_diff', 'hc_diff', 'lc_diff', 'tr', '+dm', '-dm', 'tr_ema', '+dm_ema', '-dm_ema', '+di', '-di', 'dx']\n",
        "\n",
        "# # Drop the columns\n",
        "# df = df.drop(columns=columns_to_drop)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SVdxmxbemyx"
      },
      "outputs": [],
      "source": [
        " # Initialize the signal column with hold signals\n",
        "df['true_signal'] = 0\n",
        "\n",
        "# Generate buy signals at local minima\n",
        "df.loc[df['min'].notna(), 'true_signal'] = 1\n",
        "\n",
        "# Generate sell signals at local maxima\n",
        "df.loc[df['max'].notna(), 'true_signal'] = -1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCRGylUsemyy",
        "outputId": "b8b0b029-9b7c-4615-b102-417da7922a33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              " 0    2390\n",
              " 1      55\n",
              "-1      52\n",
              "Name: true_signal, dtype: int64"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.true_signal.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Df46XTflemyz"
      },
      "outputs": [],
      "source": [
        "# As the buy/sell signals themselves are sparse,I'd predict positions instead of signals\n",
        "for day in np.unique(df.index.date):\n",
        "    indices = df[df.index.date == day].index\n",
        "    for i in range(len(indices) - 1):  # subtracting 1 because we're looking ahead by 1 row\n",
        "        if df.loc[indices[i], \"true_signal\"] == 1 and df.loc[indices[i + 1], \"true_signal\"] == 0:\n",
        "            df.loc[indices[i + 1], \"true_signal\"] = 1\n",
        "        elif df.loc[indices[i], \"true_signal\"] == -1 and df.loc[indices[i + 1], \"true_signal\"] == 0:\n",
        "            df.loc[indices[i + 1], \"true_signal\"] = -1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqLSNV1vemyz",
        "outputId": "6809c7d3-e962-495e-fd0e-c21abf051dd0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              " 0    971\n",
              "-1    811\n",
              " 1    715\n",
              "Name: true_signal, dtype: int64"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.true_signal.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJZ64QnTemy0"
      },
      "outputs": [],
      "source": [
        "df[\"longshort_sma_delta\"]=df[\"sma_long\"]-df[\"sma_short\"]\n",
        "df[\"longshort_ema_delta\"]=df[\"ema_long\"]-df[\"ema_short\"]\n",
        "df[\"Close_sma_delta\"]=df[\"Close\"]-df[\"sma_short\"]\n",
        "df[\"Close_ema_delta\"]=df[\"Close\"]-df[\"ema_short\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtydmCJge9t1"
      },
      "outputs": [],
      "source": [
        "# 1) Body Size\n",
        "df['body_size'] = abs(df['Close'] - df['Open'])\n",
        "\n",
        "# 2) Upper Shadow\n",
        "df['upper_shadow'] = df['High'] - df[['Open', 'Close']].max(axis=1)\n",
        "\n",
        "# 3) Lower Shadow\n",
        "df['lower_shadow'] = df[['Open', 'Close']].min(axis=1) - df['Low']\n",
        "\n",
        "# 4) Candle Direction\n",
        "df['candle_direction'] = np.where(df['Close'] >= df['Open'], 1, -1)\n",
        "\n",
        "# 5) Price Range\n",
        "df['price_range'] = df['High'] - df['Low']\n",
        "\n",
        "# 6) Relative Price / Normalized Price\n",
        "df['relative_price'] = (df['Close'] - df['Low']) / (df['High'] - df['Low'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qa-vwSHPyOu8"
      },
      "outputs": [],
      "source": [
        "df['VWAP'] = (df['Volume'] * (df['High'] + df['Low'] + df['Close']) / 3).cumsum() / df['Volume'].cumsum()\n",
        "df['OBV'] = (df['Volume'] * (~df['Close'].diff().le(0) * 2 - 1)).cumsum()\n",
        "df['PVT'] = (df['Volume'] * (df['Close'].pct_change())).cumsum()\n",
        "typical_price = (df['High'] + df['Low'] + df['Close']) / 3\n",
        "money_flow = typical_price * df['Volume']\n",
        "df['MFI'] = money_flow.rolling(window=window_size).sum() / df['Volume'].rolling(window=window_size).sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2ryewGle9uF"
      },
      "outputs": [],
      "source": [
        "df=df.drop([\"Close\",\"High\",\"Low\"],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ra7O3jfstUyU"
      },
      "outputs": [],
      "source": [
        "# df=df.fillna(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwqnMAEje9uG"
      },
      "outputs": [],
      "source": [
        "train=df[:38*55]\n",
        "test=df[38*56:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcwBhjW7e9uG",
        "outputId": "ff38a5d7-40a2-4c54-d842-fa62afdfdd51"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "369"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXUQSnKXe9uI"
      },
      "outputs": [],
      "source": [
        "target=train.true_signal\n",
        "indicators=train.drop([\"true_signal\"],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9F7S1cZe9uI"
      },
      "outputs": [],
      "source": [
        "val_target=test.true_signal\n",
        "val_indicators=test.drop([\"true_signal\"],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpbtQtzoe9uJ",
        "outputId": "98562a27-7301-4236-b385-19ce0b482f5d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              " 0    869\n",
              "-1    651\n",
              " 1    570\n",
              "Name: true_signal, dtype: int64"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76fz_nhDe9uJ",
        "outputId": "fff5a9e7-ead7-4c23-a27e-273c6fcdd0d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[flaml.automl.logger: 03-18 08:26:03] {1680} INFO - task = classification\n",
            "[flaml.automl.logger: 03-18 08:26:03] {1688} INFO - Data split method: stratified\n",
            "[flaml.automl.logger: 03-18 08:26:03] {1691} INFO - Evaluation method: holdout\n",
            "[flaml.automl.logger: 03-18 08:26:03] {1789} INFO - Minimizing error metric: 1-micro_f1\n",
            "[flaml.automl.logger: 03-18 08:26:03] {1901} INFO - List of ML learners in AutoML Run: ['lgbm']\n",
            "[flaml.automl.logger: 03-18 08:26:03] {2219} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:04] {2345} INFO - Estimated sufficient time budget=10000s. Estimated necessary time budget=10s.\n",
            "[flaml.automl.logger: 03-18 08:26:04] {2392} INFO -  at 0.8s,\testimator lgbm's best error=0.6152,\tbest estimator lgbm's best error=0.6152\n",
            "[flaml.automl.logger: 03-18 08:26:04] {2219} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:04] {2392} INFO -  at 1.0s,\testimator lgbm's best error=0.6152,\tbest estimator lgbm's best error=0.6152\n",
            "[flaml.automl.logger: 03-18 08:26:04] {2219} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:04] {2392} INFO -  at 1.0s,\testimator lgbm's best error=0.5366,\tbest estimator lgbm's best error=0.5366\n",
            "[flaml.automl.logger: 03-18 08:26:04] {2219} INFO - iteration 3, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:05] {2392} INFO -  at 1.7s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:26:05] {2219} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:05] {2392} INFO -  at 1.7s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:26:05] {2219} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:05] {2392} INFO -  at 1.8s,\testimator lgbm's best error=0.4146,\tbest estimator lgbm's best error=0.4146\n",
            "[flaml.automl.logger: 03-18 08:26:05] {2219} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:05] {2392} INFO -  at 1.9s,\testimator lgbm's best error=0.3713,\tbest estimator lgbm's best error=0.3713\n",
            "[flaml.automl.logger: 03-18 08:26:05] {2219} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:05] {2392} INFO -  at 2.0s,\testimator lgbm's best error=0.3713,\tbest estimator lgbm's best error=0.3713\n",
            "[flaml.automl.logger: 03-18 08:26:05] {2219} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:05] {2392} INFO -  at 2.2s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:05] {2219} INFO - iteration 9, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:05] {2392} INFO -  at 2.2s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:05] {2219} INFO - iteration 10, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:06] {2392} INFO -  at 3.1s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:06] {2219} INFO - iteration 11, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:07] {2392} INFO -  at 3.3s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:07] {2219} INFO - iteration 12, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:07] {2392} INFO -  at 3.4s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:07] {2219} INFO - iteration 13, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:07] {2392} INFO -  at 3.7s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:07] {2219} INFO - iteration 14, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:07] {2392} INFO -  at 3.9s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:07] {2219} INFO - iteration 15, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:07] {2392} INFO -  at 4.3s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:07] {2219} INFO - iteration 16, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:08] {2392} INFO -  at 4.4s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:08] {2219} INFO - iteration 17, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:08] {2392} INFO -  at 4.7s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:08] {2219} INFO - iteration 18, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:08] {2392} INFO -  at 4.8s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:08] {2219} INFO - iteration 19, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:08] {2392} INFO -  at 4.9s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:08] {2219} INFO - iteration 20, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:08] {2392} INFO -  at 5.2s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:08] {2219} INFO - iteration 21, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:09] {2392} INFO -  at 5.4s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:09] {2219} INFO - iteration 22, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:09] {2392} INFO -  at 5.6s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:09] {2219} INFO - iteration 23, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:09] {2392} INFO -  at 5.8s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:09] {2219} INFO - iteration 24, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:09] {2392} INFO -  at 6.0s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:09] {2219} INFO - iteration 25, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:10] {2392} INFO -  at 6.3s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:10] {2219} INFO - iteration 26, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:10] {2392} INFO -  at 6.5s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:10] {2219} INFO - iteration 27, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:10] {2392} INFO -  at 6.7s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:10] {2219} INFO - iteration 28, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:10] {2392} INFO -  at 6.8s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:10] {2219} INFO - iteration 29, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:10] {2392} INFO -  at 6.9s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:10] {2219} INFO - iteration 30, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:11] {2392} INFO -  at 7.4s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:11] {2219} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:11] {2392} INFO -  at 7.5s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:11] {2219} INFO - iteration 32, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:11] {2392} INFO -  at 7.8s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:11] {2219} INFO - iteration 33, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:11] {2392} INFO -  at 7.9s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:11] {2219} INFO - iteration 34, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:11] {2392} INFO -  at 8.1s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:11] {2219} INFO - iteration 35, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:12] {2392} INFO -  at 8.5s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:12] {2219} INFO - iteration 36, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:12] {2392} INFO -  at 8.6s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:12] {2219} INFO - iteration 37, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:12] {2392} INFO -  at 8.8s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:12] {2219} INFO - iteration 38, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:12] {2392} INFO -  at 8.9s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:12] {2219} INFO - iteration 39, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:13] {2392} INFO -  at 9.7s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:13] {2219} INFO - iteration 40, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:13] {2392} INFO -  at 9.8s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:13] {2219} INFO - iteration 41, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:13] {2392} INFO -  at 9.8s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:13] {2219} INFO - iteration 42, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:14] {2392} INFO -  at 10.3s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:14] {2219} INFO - iteration 43, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:14] {2392} INFO -  at 10.6s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:14] {2219} INFO - iteration 44, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:14] {2392} INFO -  at 10.7s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:14] {2219} INFO - iteration 45, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:14] {2392} INFO -  at 10.8s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:14] {2219} INFO - iteration 46, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:15] {2392} INFO -  at 11.4s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:15] {2219} INFO - iteration 47, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:15] {2392} INFO -  at 11.5s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:15] {2219} INFO - iteration 48, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:17] {2392} INFO -  at 13.8s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:17] {2219} INFO - iteration 49, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:17] {2392} INFO -  at 13.8s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:17] {2219} INFO - iteration 50, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:18] {2392} INFO -  at 14.7s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:18] {2219} INFO - iteration 51, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:18] {2392} INFO -  at 15.2s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:18] {2219} INFO - iteration 52, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:18] {2392} INFO -  at 15.3s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:19] {2219} INFO - iteration 53, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:19] {2392} INFO -  at 15.8s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:19] {2219} INFO - iteration 54, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:19] {2392} INFO -  at 15.8s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:19] {2219} INFO - iteration 55, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:19] {2392} INFO -  at 16.1s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:19] {2219} INFO - iteration 56, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:20] {2392} INFO -  at 16.4s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:20] {2219} INFO - iteration 57, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:20] {2392} INFO -  at 16.5s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:20] {2219} INFO - iteration 58, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:20] {2392} INFO -  at 16.8s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:20] {2219} INFO - iteration 59, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:20] {2392} INFO -  at 16.9s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:20] {2219} INFO - iteration 60, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:21] {2392} INFO -  at 17.3s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:21] {2219} INFO - iteration 61, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:21] {2392} INFO -  at 17.8s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:21] {2219} INFO - iteration 62, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:21] {2392} INFO -  at 17.9s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:21] {2219} INFO - iteration 63, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:21] {2392} INFO -  at 18.2s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:21] {2219} INFO - iteration 64, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:22] {2392} INFO -  at 18.4s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:22] {2219} INFO - iteration 65, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:22] {2392} INFO -  at 18.5s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:22] {2219} INFO - iteration 66, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:22] {2392} INFO -  at 18.8s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:22] {2219} INFO - iteration 67, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:22] {2392} INFO -  at 18.9s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:22] {2219} INFO - iteration 68, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:22] {2392} INFO -  at 19.2s,\testimator lgbm's best error=0.3144,\tbest estimator lgbm's best error=0.3144\n",
            "[flaml.automl.logger: 03-18 08:26:22] {2219} INFO - iteration 69, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:23] {2392} INFO -  at 19.7s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:23] {2219} INFO - iteration 70, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:23] {2392} INFO -  at 19.8s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:23] {2219} INFO - iteration 71, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:24] {2392} INFO -  at 20.4s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:24] {2219} INFO - iteration 72, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:24] {2392} INFO -  at 20.9s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:24] {2219} INFO - iteration 73, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:24] {2392} INFO -  at 21.1s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:24] {2219} INFO - iteration 74, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:27] {2392} INFO -  at 23.3s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:27] {2219} INFO - iteration 75, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:29] {2392} INFO -  at 25.8s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:29] {2219} INFO - iteration 76, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:29] {2392} INFO -  at 26.1s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:29] {2219} INFO - iteration 77, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:29] {2392} INFO -  at 26.2s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:29] {2219} INFO - iteration 78, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:31] {2392} INFO -  at 27.9s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:31] {2219} INFO - iteration 79, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:32] {2392} INFO -  at 28.9s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:32] {2219} INFO - iteration 80, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:32] {2392} INFO -  at 29.1s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:32] {2219} INFO - iteration 81, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:34] {2392} INFO -  at 31.0s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:34] {2219} INFO - iteration 82, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:34] {2392} INFO -  at 31.2s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:34] {2219} INFO - iteration 83, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:35] {2392} INFO -  at 31.9s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:35] {2219} INFO - iteration 84, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:36] {2392} INFO -  at 32.5s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:36] {2219} INFO - iteration 85, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:36] {2392} INFO -  at 32.8s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:36] {2219} INFO - iteration 86, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:37] {2392} INFO -  at 34.2s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:37] {2219} INFO - iteration 87, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:38] {2392} INFO -  at 35.1s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:38] {2219} INFO - iteration 88, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:40] {2392} INFO -  at 36.8s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:40] {2219} INFO - iteration 89, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:41] {2392} INFO -  at 37.6s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:41] {2219} INFO - iteration 90, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:42] {2392} INFO -  at 38.3s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:42] {2219} INFO - iteration 91, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:42] {2392} INFO -  at 38.8s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:42] {2219} INFO - iteration 92, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:43] {2392} INFO -  at 39.7s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:43] {2219} INFO - iteration 93, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:43] {2392} INFO -  at 39.9s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:43] {2219} INFO - iteration 94, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:44] {2392} INFO -  at 41.1s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:44] {2219} INFO - iteration 95, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:45] {2392} INFO -  at 42.0s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:45] {2219} INFO - iteration 96, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:46] {2392} INFO -  at 42.4s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:46] {2219} INFO - iteration 97, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:46] {2392} INFO -  at 42.9s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:46] {2219} INFO - iteration 98, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:47] {2392} INFO -  at 43.6s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:47] {2219} INFO - iteration 99, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:47] {2392} INFO -  at 44.0s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:47] {2219} INFO - iteration 100, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:48] {2392} INFO -  at 44.5s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:48] {2219} INFO - iteration 101, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:48] {2392} INFO -  at 45.1s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:48] {2219} INFO - iteration 102, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:49] {2392} INFO -  at 45.4s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:49] {2219} INFO - iteration 103, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:49] {2392} INFO -  at 46.1s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:49] {2219} INFO - iteration 104, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:50] {2392} INFO -  at 46.3s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:50] {2219} INFO - iteration 105, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:53] {2392} INFO -  at 49.7s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:53] {2219} INFO - iteration 106, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:53] {2392} INFO -  at 50.0s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:53] {2219} INFO - iteration 107, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:53] {2392} INFO -  at 50.1s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:53] {2219} INFO - iteration 108, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:55] {2392} INFO -  at 51.7s,\testimator lgbm's best error=0.2900,\tbest estimator lgbm's best error=0.2900\n",
            "[flaml.automl.logger: 03-18 08:26:55] {2219} INFO - iteration 109, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:55] {2392} INFO -  at 52.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:26:55] {2219} INFO - iteration 110, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:56] {2392} INFO -  at 52.7s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:26:56] {2219} INFO - iteration 111, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:58] {2392} INFO -  at 54.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:26:58] {2219} INFO - iteration 112, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:58] {2392} INFO -  at 54.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:26:58] {2219} INFO - iteration 113, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:58] {2392} INFO -  at 54.8s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:26:58] {2219} INFO - iteration 114, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:59] {2392} INFO -  at 55.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:26:59] {2219} INFO - iteration 115, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:26:59] {2392} INFO -  at 55.5s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:26:59] {2219} INFO - iteration 116, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:00] {2392} INFO -  at 56.6s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:00] {2219} INFO - iteration 117, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:02] {2392} INFO -  at 58.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:02] {2219} INFO - iteration 118, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:02] {2392} INFO -  at 58.5s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:02] {2219} INFO - iteration 119, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:02] {2392} INFO -  at 59.0s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:02] {2219} INFO - iteration 120, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:03] {2392} INFO -  at 59.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:03] {2219} INFO - iteration 121, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:05] {2392} INFO -  at 61.7s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:05] {2219} INFO - iteration 122, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:05] {2392} INFO -  at 62.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:05] {2219} INFO - iteration 123, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:06] {2392} INFO -  at 62.6s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:06] {2219} INFO - iteration 124, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:06] {2392} INFO -  at 63.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:06] {2219} INFO - iteration 125, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:07] {2392} INFO -  at 63.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:07] {2219} INFO - iteration 126, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:07] {2392} INFO -  at 64.2s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:07] {2219} INFO - iteration 127, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:09] {2392} INFO -  at 65.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:09] {2219} INFO - iteration 128, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:09] {2392} INFO -  at 65.5s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:09] {2219} INFO - iteration 129, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:09] {2392} INFO -  at 65.8s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:09] {2219} INFO - iteration 130, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:09] {2392} INFO -  at 66.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:09] {2219} INFO - iteration 131, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:10] {2392} INFO -  at 66.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:10] {2219} INFO - iteration 132, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:10] {2392} INFO -  at 66.9s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:10] {2219} INFO - iteration 133, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:11] {2392} INFO -  at 68.0s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:11] {2219} INFO - iteration 134, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:11] {2392} INFO -  at 68.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:11] {2219} INFO - iteration 135, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:12] {2392} INFO -  at 68.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:12] {2219} INFO - iteration 136, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:12] {2392} INFO -  at 68.8s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:12] {2219} INFO - iteration 137, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:13] {2392} INFO -  at 69.5s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:13] {2219} INFO - iteration 138, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:13] {2392} INFO -  at 69.7s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:13] {2219} INFO - iteration 139, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:13] {2392} INFO -  at 69.9s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:13] {2219} INFO - iteration 140, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:16] {2392} INFO -  at 73.0s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:16] {2219} INFO - iteration 141, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:17] {2392} INFO -  at 73.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:17] {2219} INFO - iteration 142, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:17] {2392} INFO -  at 74.2s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:17] {2219} INFO - iteration 143, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:18] {2392} INFO -  at 74.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:18] {2219} INFO - iteration 144, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:19] {2392} INFO -  at 75.6s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:19] {2219} INFO - iteration 145, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:19] {2392} INFO -  at 75.7s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:19] {2219} INFO - iteration 146, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:20] {2392} INFO -  at 77.2s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:20] {2219} INFO - iteration 147, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:21] {2392} INFO -  at 77.6s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:21] {2219} INFO - iteration 148, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:21] {2392} INFO -  at 77.9s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:21] {2219} INFO - iteration 149, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:21] {2392} INFO -  at 78.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:21] {2219} INFO - iteration 150, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:22] {2392} INFO -  at 79.0s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:22] {2219} INFO - iteration 151, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:23] {2392} INFO -  at 79.6s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:23] {2219} INFO - iteration 152, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:23] {2392} INFO -  at 79.9s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:23] {2219} INFO - iteration 153, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:23] {2392} INFO -  at 80.0s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:23] {2219} INFO - iteration 154, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:24] {2392} INFO -  at 81.0s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:24] {2219} INFO - iteration 155, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:25] {2392} INFO -  at 82.0s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:25] {2219} INFO - iteration 156, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:25] {2392} INFO -  at 82.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:25] {2219} INFO - iteration 157, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:26] {2392} INFO -  at 82.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:26] {2219} INFO - iteration 158, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:29] {2392} INFO -  at 85.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:29] {2219} INFO - iteration 159, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:29] {2392} INFO -  at 85.6s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:29] {2219} INFO - iteration 160, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:29] {2392} INFO -  at 86.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:29] {2219} INFO - iteration 161, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:30] {2392} INFO -  at 86.6s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:30] {2219} INFO - iteration 162, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:30] {2392} INFO -  at 87.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:30] {2219} INFO - iteration 163, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:31] {2392} INFO -  at 87.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:31] {2219} INFO - iteration 164, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:31] {2392} INFO -  at 87.8s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:31] {2219} INFO - iteration 165, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:31] {2392} INFO -  at 88.2s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:31] {2219} INFO - iteration 166, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:32] {2392} INFO -  at 88.5s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:32] {2219} INFO - iteration 167, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:32] {2392} INFO -  at 88.7s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:32] {2219} INFO - iteration 168, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:35] {2392} INFO -  at 91.5s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:35] {2219} INFO - iteration 169, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:35] {2392} INFO -  at 91.7s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:35] {2219} INFO - iteration 170, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:36] {2392} INFO -  at 93.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:36] {2219} INFO - iteration 171, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:37] {2392} INFO -  at 93.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:37] {2219} INFO - iteration 172, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:37] {2392} INFO -  at 93.6s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:37] {2219} INFO - iteration 173, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:38] {2392} INFO -  at 94.5s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:38] {2219} INFO - iteration 174, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:38] {2392} INFO -  at 94.8s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:38] {2219} INFO - iteration 175, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:40] {2392} INFO -  at 96.8s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:40] {2219} INFO - iteration 176, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:41] {2392} INFO -  at 97.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:41] {2219} INFO - iteration 177, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:41] {2392} INFO -  at 98.0s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:41] {2219} INFO - iteration 178, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:42] {2392} INFO -  at 98.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:42] {2219} INFO - iteration 179, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:42] {2392} INFO -  at 98.8s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:42] {2219} INFO - iteration 180, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:42] {2392} INFO -  at 99.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:42] {2219} INFO - iteration 181, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:43] {2392} INFO -  at 99.5s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:43] {2219} INFO - iteration 182, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:43] {2392} INFO -  at 99.8s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:43] {2219} INFO - iteration 183, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:44] {2392} INFO -  at 100.8s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:44] {2219} INFO - iteration 184, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:44] {2392} INFO -  at 101.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:44] {2219} INFO - iteration 185, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:45] {2392} INFO -  at 101.9s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:45] {2219} INFO - iteration 186, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:45] {2392} INFO -  at 102.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:45] {2219} INFO - iteration 187, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:46] {2392} INFO -  at 102.9s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:46] {2219} INFO - iteration 188, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:46] {2392} INFO -  at 103.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:46] {2219} INFO - iteration 189, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:47] {2392} INFO -  at 103.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:47] {2219} INFO - iteration 190, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:48] {2392} INFO -  at 104.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:48] {2219} INFO - iteration 191, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:48] {2392} INFO -  at 105.2s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:48] {2219} INFO - iteration 192, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:49] {2392} INFO -  at 105.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:49] {2219} INFO - iteration 193, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:49] {2392} INFO -  at 106.0s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:49] {2219} INFO - iteration 194, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:50] {2392} INFO -  at 106.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:50] {2219} INFO - iteration 195, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:50] {2392} INFO -  at 106.5s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:50] {2219} INFO - iteration 196, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:50] {2392} INFO -  at 107.0s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:50] {2219} INFO - iteration 197, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:53] {2392} INFO -  at 109.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:53] {2219} INFO - iteration 198, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:53] {2392} INFO -  at 109.6s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:53] {2219} INFO - iteration 199, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:54] {2392} INFO -  at 110.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:54] {2219} INFO - iteration 200, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:54] {2392} INFO -  at 110.8s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:54] {2219} INFO - iteration 201, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:54] {2392} INFO -  at 111.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:54] {2219} INFO - iteration 202, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:55] {2392} INFO -  at 111.5s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:55] {2219} INFO - iteration 203, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:55] {2392} INFO -  at 111.7s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:55] {2219} INFO - iteration 204, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:55] {2392} INFO -  at 112.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:55] {2219} INFO - iteration 205, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:56] {2392} INFO -  at 112.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:56] {2219} INFO - iteration 206, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:56] {2392} INFO -  at 113.0s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:56] {2219} INFO - iteration 207, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:56] {2392} INFO -  at 113.2s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:56] {2219} INFO - iteration 208, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:57] {2392} INFO -  at 113.7s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:57] {2219} INFO - iteration 209, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:57] {2392} INFO -  at 114.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:57] {2219} INFO - iteration 210, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:58] {2392} INFO -  at 114.7s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:58] {2219} INFO - iteration 211, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:59] {2392} INFO -  at 115.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:59] {2219} INFO - iteration 212, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:59] {2392} INFO -  at 115.6s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:59] {2219} INFO - iteration 213, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:27:59] {2392} INFO -  at 115.8s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:27:59] {2219} INFO - iteration 214, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:00] {2392} INFO -  at 116.8s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:00] {2219} INFO - iteration 215, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:02] {2392} INFO -  at 118.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:02] {2219} INFO - iteration 216, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:02] {2392} INFO -  at 118.6s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:02] {2219} INFO - iteration 217, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:02] {2392} INFO -  at 118.8s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:02] {2219} INFO - iteration 218, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:04] {2392} INFO -  at 121.0s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:04] {2219} INFO - iteration 219, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:05] {2392} INFO -  at 121.5s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:05] {2219} INFO - iteration 220, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:05] {2392} INFO -  at 121.8s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:05] {2219} INFO - iteration 221, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:05] {2392} INFO -  at 122.0s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:05] {2219} INFO - iteration 222, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:06] {2392} INFO -  at 122.7s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:06] {2219} INFO - iteration 223, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:06] {2392} INFO -  at 123.2s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:06] {2219} INFO - iteration 224, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:07] {2392} INFO -  at 123.5s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:07] {2219} INFO - iteration 225, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:07] {2392} INFO -  at 124.2s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:07] {2219} INFO - iteration 226, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:08] {2392} INFO -  at 124.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:08] {2219} INFO - iteration 227, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:08] {2392} INFO -  at 125.2s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:08] {2219} INFO - iteration 228, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:09] {2392} INFO -  at 125.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:09] {2219} INFO - iteration 229, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:10] {2392} INFO -  at 126.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:10] {2219} INFO - iteration 230, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:10] {2392} INFO -  at 126.6s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:10] {2219} INFO - iteration 231, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:10] {2392} INFO -  at 126.9s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:10] {2219} INFO - iteration 232, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:11] {2392} INFO -  at 127.5s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:11] {2219} INFO - iteration 233, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:11] {2392} INFO -  at 128.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:11] {2219} INFO - iteration 234, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:12] {2392} INFO -  at 128.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:12] {2219} INFO - iteration 235, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:12] {2392} INFO -  at 128.7s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:12] {2219} INFO - iteration 236, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:12] {2392} INFO -  at 129.0s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:12] {2219} INFO - iteration 237, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:12] {2392} INFO -  at 129.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:12] {2219} INFO - iteration 238, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:13] {2392} INFO -  at 130.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:13] {2219} INFO - iteration 239, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:14] {2392} INFO -  at 130.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:14] {2219} INFO - iteration 240, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:14] {2392} INFO -  at 130.9s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:14] {2219} INFO - iteration 241, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:14] {2392} INFO -  at 131.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:14] {2219} INFO - iteration 242, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:17] {2392} INFO -  at 134.0s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:17] {2219} INFO - iteration 243, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:18] {2392} INFO -  at 134.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:18] {2219} INFO - iteration 244, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:18] {2392} INFO -  at 134.9s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:18] {2219} INFO - iteration 245, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:19] {2392} INFO -  at 135.5s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:19] {2219} INFO - iteration 246, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:19] {2392} INFO -  at 135.7s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:19] {2219} INFO - iteration 247, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:19] {2392} INFO -  at 135.9s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:19] {2219} INFO - iteration 248, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:20] {2392} INFO -  at 136.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:20] {2219} INFO - iteration 249, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:20] {2392} INFO -  at 136.7s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:20] {2219} INFO - iteration 250, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:20] {2392} INFO -  at 137.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:20] {2219} INFO - iteration 251, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:21] {2392} INFO -  at 137.7s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:21] {2219} INFO - iteration 252, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:21] {2392} INFO -  at 137.9s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:21] {2219} INFO - iteration 253, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:22] {2392} INFO -  at 139.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:22] {2219} INFO - iteration 254, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:22] {2392} INFO -  at 139.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:22] {2219} INFO - iteration 255, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:23] {2392} INFO -  at 139.9s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:23] {2219} INFO - iteration 256, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:23] {2392} INFO -  at 140.2s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:23] {2219} INFO - iteration 257, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:24] {2392} INFO -  at 140.5s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:24] {2219} INFO - iteration 258, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:25] {2392} INFO -  at 142.2s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:25] {2219} INFO - iteration 259, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:27] {2392} INFO -  at 144.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:27] {2219} INFO - iteration 260, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:28] {2392} INFO -  at 144.9s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:28] {2219} INFO - iteration 261, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:29] {2392} INFO -  at 146.2s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:29] {2219} INFO - iteration 262, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:30] {2392} INFO -  at 146.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:30] {2219} INFO - iteration 263, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:30] {2392} INFO -  at 147.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:30] {2219} INFO - iteration 264, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:31] {2392} INFO -  at 147.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:31] {2219} INFO - iteration 265, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:31] {2392} INFO -  at 148.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:31] {2219} INFO - iteration 266, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:32] {2392} INFO -  at 148.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:32] {2219} INFO - iteration 267, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:32] {2392} INFO -  at 148.8s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:32] {2219} INFO - iteration 268, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:32] {2392} INFO -  at 149.2s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:32] {2219} INFO - iteration 269, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:33] {2392} INFO -  at 150.2s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:33] {2219} INFO - iteration 270, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:34] {2392} INFO -  at 150.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:34] {2219} INFO - iteration 271, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:34] {2392} INFO -  at 150.7s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:34] {2219} INFO - iteration 272, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:35] {2392} INFO -  at 152.0s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:35] {2219} INFO - iteration 273, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:36] {2392} INFO -  at 153.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:36] {2219} INFO - iteration 274, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:36] {2392} INFO -  at 153.2s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:36] {2219} INFO - iteration 275, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:37] {2392} INFO -  at 154.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:37] {2219} INFO - iteration 276, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:37] {2392} INFO -  at 154.2s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:37] {2219} INFO - iteration 277, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:38] {2392} INFO -  at 154.7s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:38] {2219} INFO - iteration 278, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:38] {2392} INFO -  at 155.0s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:38] {2219} INFO - iteration 279, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:40] {2392} INFO -  at 156.5s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:40] {2219} INFO - iteration 280, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:41] {2392} INFO -  at 157.6s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:41] {2219} INFO - iteration 281, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:41] {2392} INFO -  at 157.7s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:41] {2219} INFO - iteration 282, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:42] {2392} INFO -  at 158.7s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:42] {2219} INFO - iteration 283, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:42] {2392} INFO -  at 159.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:42] {2219} INFO - iteration 284, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:43] {2392} INFO -  at 159.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:43] {2219} INFO - iteration 285, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:43] {2392} INFO -  at 159.8s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:43] {2219} INFO - iteration 286, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:44] {2392} INFO -  at 160.6s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:44] {2219} INFO - iteration 287, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:45] {2392} INFO -  at 162.2s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:45] {2219} INFO - iteration 288, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:46] {2392} INFO -  at 162.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:46] {2219} INFO - iteration 289, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:46] {2392} INFO -  at 162.5s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:46] {2219} INFO - iteration 290, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:46] {2392} INFO -  at 163.2s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:46] {2219} INFO - iteration 291, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:47] {2392} INFO -  at 163.9s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:47] {2219} INFO - iteration 292, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:47] {2392} INFO -  at 164.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:47] {2219} INFO - iteration 293, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:48] {2392} INFO -  at 165.2s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:48] {2219} INFO - iteration 294, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:49] {2392} INFO -  at 165.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:49] {2219} INFO - iteration 295, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:49] {2392} INFO -  at 165.9s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:49] {2219} INFO - iteration 296, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:50] {2392} INFO -  at 166.5s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:50] {2219} INFO - iteration 297, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:50] {2392} INFO -  at 166.6s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:50] {2219} INFO - iteration 298, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:52] {2392} INFO -  at 169.0s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:52] {2219} INFO - iteration 299, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:52] {2392} INFO -  at 169.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:52] {2219} INFO - iteration 300, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:53] {2392} INFO -  at 169.9s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:53] {2219} INFO - iteration 301, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:53] {2392} INFO -  at 170.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:53] {2219} INFO - iteration 302, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:55] {2392} INFO -  at 171.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:55] {2219} INFO - iteration 303, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:55] {2392} INFO -  at 171.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:55] {2219} INFO - iteration 304, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:55] {2392} INFO -  at 171.9s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:55] {2219} INFO - iteration 305, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:56] {2392} INFO -  at 173.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:56] {2219} INFO - iteration 306, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:57] {2392} INFO -  at 173.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:57] {2219} INFO - iteration 307, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:57] {2392} INFO -  at 173.7s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:57] {2219} INFO - iteration 308, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:58] {2392} INFO -  at 174.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:58] {2219} INFO - iteration 309, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:58] {2392} INFO -  at 175.2s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:58] {2219} INFO - iteration 310, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:59] {2392} INFO -  at 175.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:59] {2219} INFO - iteration 311, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:59] {2392} INFO -  at 175.8s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:59] {2219} INFO - iteration 312, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:59] {2392} INFO -  at 176.0s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:59] {2219} INFO - iteration 313, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:28:59] {2392} INFO -  at 176.2s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:28:59] {2219} INFO - iteration 314, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:01] {2392} INFO -  at 177.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:01] {2219} INFO - iteration 315, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:01] {2392} INFO -  at 177.8s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:01] {2219} INFO - iteration 316, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:01] {2392} INFO -  at 178.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:01] {2219} INFO - iteration 317, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:02] {2392} INFO -  at 178.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:02] {2219} INFO - iteration 318, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:05] {2392} INFO -  at 181.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:05] {2219} INFO - iteration 319, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:05] {2392} INFO -  at 181.9s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:05] {2219} INFO - iteration 320, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:05] {2392} INFO -  at 182.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:05] {2219} INFO - iteration 321, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:06] {2392} INFO -  at 182.7s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:06] {2219} INFO - iteration 322, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:06] {2392} INFO -  at 182.9s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:06] {2219} INFO - iteration 323, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:07] {2392} INFO -  at 183.8s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:07] {2219} INFO - iteration 324, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:07] {2392} INFO -  at 184.0s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:07] {2219} INFO - iteration 325, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:07] {2392} INFO -  at 184.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:07] {2219} INFO - iteration 326, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:08] {2392} INFO -  at 185.2s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:08] {2219} INFO - iteration 327, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:09] {2392} INFO -  at 185.7s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:09] {2219} INFO - iteration 328, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:09] {2392} INFO -  at 186.2s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:09] {2219} INFO - iteration 329, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:11] {2392} INFO -  at 188.0s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:11] {2219} INFO - iteration 330, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:11] {2392} INFO -  at 188.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:11] {2219} INFO - iteration 331, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:11] {2392} INFO -  at 188.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:11] {2219} INFO - iteration 332, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:12] {2392} INFO -  at 189.2s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:12] {2219} INFO - iteration 333, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:13] {2392} INFO -  at 189.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:13] {2219} INFO - iteration 334, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:13] {2392} INFO -  at 189.8s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:13] {2219} INFO - iteration 335, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:14] {2392} INFO -  at 190.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:14] {2219} INFO - iteration 336, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:14] {2392} INFO -  at 190.6s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:14] {2219} INFO - iteration 337, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:16] {2392} INFO -  at 192.9s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:16] {2219} INFO - iteration 338, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:16] {2392} INFO -  at 193.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:16] {2219} INFO - iteration 339, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:17] {2392} INFO -  at 193.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:17] {2219} INFO - iteration 340, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:18] {2392} INFO -  at 194.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:18] {2219} INFO - iteration 341, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:18] {2392} INFO -  at 195.2s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:18] {2219} INFO - iteration 342, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:19] {2392} INFO -  at 195.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:19] {2219} INFO - iteration 343, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:19] {2392} INFO -  at 195.5s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:19] {2219} INFO - iteration 344, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:20] {2392} INFO -  at 196.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:20] {2219} INFO - iteration 345, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:20] {2392} INFO -  at 197.2s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:20] {2219} INFO - iteration 346, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:21] {2392} INFO -  at 197.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:21] {2219} INFO - iteration 347, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:21] {2392} INFO -  at 197.5s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:21] {2219} INFO - iteration 348, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:22] {2392} INFO -  at 199.2s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:22] {2219} INFO - iteration 349, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:23] {2392} INFO -  at 199.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:23] {2219} INFO - iteration 350, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:23] {2392} INFO -  at 200.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:23] {2219} INFO - iteration 351, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:24] {2392} INFO -  at 200.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:24] {2219} INFO - iteration 352, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:24] {2392} INFO -  at 200.8s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:24] {2219} INFO - iteration 353, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:25] {2392} INFO -  at 201.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:25] {2219} INFO - iteration 354, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:25] {2392} INFO -  at 201.6s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:25] {2219} INFO - iteration 355, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:25] {2392} INFO -  at 201.9s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:25] {2219} INFO - iteration 356, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:27] {2392} INFO -  at 204.2s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:27] {2219} INFO - iteration 357, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:29] {2392} INFO -  at 205.5s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:29] {2219} INFO - iteration 358, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:29] {2392} INFO -  at 205.7s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:29] {2219} INFO - iteration 359, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:29] {2392} INFO -  at 206.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:29] {2219} INFO - iteration 360, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:30] {2392} INFO -  at 206.5s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:30] {2219} INFO - iteration 361, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:30] {2392} INFO -  at 207.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:30] {2219} INFO - iteration 362, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:31] {2392} INFO -  at 207.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:31] {2219} INFO - iteration 363, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:31] {2392} INFO -  at 208.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:31] {2219} INFO - iteration 364, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:32] {2392} INFO -  at 208.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:32] {2219} INFO - iteration 365, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:32] {2392} INFO -  at 208.7s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:32] {2219} INFO - iteration 366, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:32] {2392} INFO -  at 209.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:32] {2219} INFO - iteration 367, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:33] {2392} INFO -  at 209.7s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:33] {2219} INFO - iteration 368, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:33] {2392} INFO -  at 210.0s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:33] {2219} INFO - iteration 369, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:34] {2392} INFO -  at 210.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:34] {2219} INFO - iteration 370, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:34] {2392} INFO -  at 210.9s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:34] {2219} INFO - iteration 371, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:35] {2392} INFO -  at 211.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:35] {2219} INFO - iteration 372, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:35] {2392} INFO -  at 211.6s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:35] {2219} INFO - iteration 373, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:35] {2392} INFO -  at 212.0s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:35] {2219} INFO - iteration 374, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:35] {2392} INFO -  at 212.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:35] {2219} INFO - iteration 375, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:36] {2392} INFO -  at 212.6s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:36] {2219} INFO - iteration 376, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:37] {2392} INFO -  at 213.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:37] {2219} INFO - iteration 377, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:37] {2392} INFO -  at 213.8s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:37] {2219} INFO - iteration 378, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:37] {2392} INFO -  at 214.2s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:37] {2219} INFO - iteration 379, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:40] {2392} INFO -  at 216.6s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:40] {2219} INFO - iteration 380, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:40] {2392} INFO -  at 216.9s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:40] {2219} INFO - iteration 381, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:40] {2392} INFO -  at 217.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:40] {2219} INFO - iteration 382, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:41] {2392} INFO -  at 217.9s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:41] {2219} INFO - iteration 383, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:41] {2392} INFO -  at 218.2s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:41] {2219} INFO - iteration 384, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:42] {2392} INFO -  at 218.8s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:42] {2219} INFO - iteration 385, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:42] {2392} INFO -  at 219.2s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:42] {2219} INFO - iteration 386, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:43] {2392} INFO -  at 219.5s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:43] {2219} INFO - iteration 387, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:43] {2392} INFO -  at 220.0s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:43] {2219} INFO - iteration 388, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:44] {2392} INFO -  at 220.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:44] {2219} INFO - iteration 389, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:44] {2392} INFO -  at 220.7s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:44] {2219} INFO - iteration 390, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:44] {2392} INFO -  at 221.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:44] {2219} INFO - iteration 391, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:45] {2392} INFO -  at 221.4s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:45] {2219} INFO - iteration 392, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:45] {2392} INFO -  at 221.9s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:45] {2219} INFO - iteration 393, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:45] {2392} INFO -  at 222.1s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:45] {2219} INFO - iteration 394, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:46] {2392} INFO -  at 222.8s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:46] {2219} INFO - iteration 395, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:47] {2392} INFO -  at 223.3s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:47] {2219} INFO - iteration 396, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:47] {2392} INFO -  at 223.6s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:47] {2219} INFO - iteration 397, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:47] {2392} INFO -  at 224.0s,\testimator lgbm's best error=0.2737,\tbest estimator lgbm's best error=0.2737\n",
            "[flaml.automl.logger: 03-18 08:29:47] {2219} INFO - iteration 398, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:48] {2392} INFO -  at 224.3s,\testimator lgbm's best error=0.2710,\tbest estimator lgbm's best error=0.2710\n",
            "[flaml.automl.logger: 03-18 08:29:48] {2219} INFO - iteration 399, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:48] {2392} INFO -  at 224.7s,\testimator lgbm's best error=0.2710,\tbest estimator lgbm's best error=0.2710\n",
            "[flaml.automl.logger: 03-18 08:29:48] {2219} INFO - iteration 400, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:48] {2392} INFO -  at 225.1s,\testimator lgbm's best error=0.2710,\tbest estimator lgbm's best error=0.2710\n",
            "[flaml.automl.logger: 03-18 08:29:48] {2219} INFO - iteration 401, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:49] {2392} INFO -  at 225.5s,\testimator lgbm's best error=0.2710,\tbest estimator lgbm's best error=0.2710\n",
            "[flaml.automl.logger: 03-18 08:29:49] {2219} INFO - iteration 402, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:49] {2392} INFO -  at 225.9s,\testimator lgbm's best error=0.2710,\tbest estimator lgbm's best error=0.2710\n",
            "[flaml.automl.logger: 03-18 08:29:49] {2219} INFO - iteration 403, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:50] {2392} INFO -  at 226.4s,\testimator lgbm's best error=0.2710,\tbest estimator lgbm's best error=0.2710\n",
            "[flaml.automl.logger: 03-18 08:29:50] {2219} INFO - iteration 404, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:51] {2392} INFO -  at 228.1s,\testimator lgbm's best error=0.2710,\tbest estimator lgbm's best error=0.2710\n",
            "[flaml.automl.logger: 03-18 08:29:51] {2219} INFO - iteration 405, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:52] {2392} INFO -  at 228.5s,\testimator lgbm's best error=0.2710,\tbest estimator lgbm's best error=0.2710\n",
            "[flaml.automl.logger: 03-18 08:29:52] {2219} INFO - iteration 406, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:52] {2392} INFO -  at 229.1s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:29:52] {2219} INFO - iteration 407, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:53] {2392} INFO -  at 229.7s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:29:53] {2219} INFO - iteration 408, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:53] {2392} INFO -  at 230.2s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:29:53] {2219} INFO - iteration 409, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:54] {2392} INFO -  at 230.5s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:29:54] {2219} INFO - iteration 410, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:55] {2392} INFO -  at 231.8s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:29:55] {2219} INFO - iteration 411, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:56] {2392} INFO -  at 233.1s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:29:56] {2219} INFO - iteration 412, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:57] {2392} INFO -  at 233.4s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:29:57] {2219} INFO - iteration 413, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:57] {2392} INFO -  at 234.2s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:29:57] {2219} INFO - iteration 414, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:58] {2392} INFO -  at 234.6s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:29:58] {2219} INFO - iteration 415, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:59] {2392} INFO -  at 235.3s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:29:59] {2219} INFO - iteration 416, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:29:59] {2392} INFO -  at 235.9s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:29:59] {2219} INFO - iteration 417, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:00] {2392} INFO -  at 236.5s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:00] {2219} INFO - iteration 418, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:00] {2392} INFO -  at 237.1s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:00] {2219} INFO - iteration 419, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:01] {2392} INFO -  at 238.0s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:01] {2219} INFO - iteration 420, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:03] {2392} INFO -  at 239.8s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:03] {2219} INFO - iteration 421, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:04] {2392} INFO -  at 241.2s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:04] {2219} INFO - iteration 422, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:05] {2392} INFO -  at 241.6s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:05] {2219} INFO - iteration 423, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:06] {2392} INFO -  at 242.4s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:06] {2219} INFO - iteration 424, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:06] {2392} INFO -  at 242.8s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:06] {2219} INFO - iteration 425, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:07] {2392} INFO -  at 243.4s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:07] {2219} INFO - iteration 426, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:07] {2392} INFO -  at 244.0s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:07] {2219} INFO - iteration 427, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:08] {2392} INFO -  at 244.4s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:08] {2219} INFO - iteration 428, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:08] {2392} INFO -  at 245.1s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:08] {2219} INFO - iteration 429, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:09] {2392} INFO -  at 245.5s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:09] {2219} INFO - iteration 430, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:09] {2392} INFO -  at 246.2s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:09] {2219} INFO - iteration 431, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:10] {2392} INFO -  at 246.6s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:10] {2219} INFO - iteration 432, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:11] {2392} INFO -  at 247.5s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:11] {2219} INFO - iteration 433, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:12] {2392} INFO -  at 248.3s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:12] {2219} INFO - iteration 434, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:12] {2392} INFO -  at 248.8s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:12] {2219} INFO - iteration 435, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:12] {2392} INFO -  at 249.2s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:12] {2219} INFO - iteration 436, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:13] {2392} INFO -  at 250.1s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:13] {2219} INFO - iteration 437, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:16] {2392} INFO -  at 252.4s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:16] {2219} INFO - iteration 438, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:16] {2392} INFO -  at 252.9s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:16] {2219} INFO - iteration 439, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:16] {2392} INFO -  at 253.2s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:16] {2219} INFO - iteration 440, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:18] {2392} INFO -  at 254.9s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:18] {2219} INFO - iteration 441, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:19] {2392} INFO -  at 256.2s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:19] {2219} INFO - iteration 442, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:20] {2392} INFO -  at 256.5s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:20] {2219} INFO - iteration 443, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:20] {2392} INFO -  at 257.0s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:20] {2219} INFO - iteration 444, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:21] {2392} INFO -  at 257.8s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:21] {2219} INFO - iteration 445, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:22] {2392} INFO -  at 258.7s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:22] {2219} INFO - iteration 446, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:23] {2392} INFO -  at 259.3s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:23] {2219} INFO - iteration 447, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:23] {2392} INFO -  at 259.9s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:23] {2219} INFO - iteration 448, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:24] {2392} INFO -  at 260.4s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:24] {2219} INFO - iteration 449, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:24] {2392} INFO -  at 261.0s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:24] {2219} INFO - iteration 450, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:25] {2392} INFO -  at 261.5s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:25] {2219} INFO - iteration 451, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:25] {2392} INFO -  at 262.0s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:25] {2219} INFO - iteration 452, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:28] {2392} INFO -  at 264.4s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:28] {2219} INFO - iteration 453, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:29] {2392} INFO -  at 265.4s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:29] {2219} INFO - iteration 454, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:29] {2392} INFO -  at 266.0s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:29] {2219} INFO - iteration 455, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:30] {2392} INFO -  at 266.6s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:30] {2219} INFO - iteration 456, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:30] {2392} INFO -  at 267.1s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:30] {2219} INFO - iteration 457, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:31] {2392} INFO -  at 267.4s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:31] {2219} INFO - iteration 458, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:32] {2392} INFO -  at 268.8s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:32] {2219} INFO - iteration 459, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:33] {2392} INFO -  at 270.1s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:33] {2219} INFO - iteration 460, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:34] {2392} INFO -  at 270.5s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:34] {2219} INFO - iteration 461, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:34] {2392} INFO -  at 271.0s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:34] {2219} INFO - iteration 462, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:35] {2392} INFO -  at 271.8s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:35] {2219} INFO - iteration 463, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:36] {2392} INFO -  at 273.0s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:36] {2219} INFO - iteration 464, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:37] {2392} INFO -  at 273.4s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:37] {2219} INFO - iteration 465, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:37] {2392} INFO -  at 273.7s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:37] {2219} INFO - iteration 466, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:40] {2392} INFO -  at 277.2s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:40] {2219} INFO - iteration 467, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:41] {2392} INFO -  at 277.9s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:41] {2219} INFO - iteration 468, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:42] {2392} INFO -  at 278.3s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:42] {2219} INFO - iteration 469, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:42] {2392} INFO -  at 278.9s,\testimator lgbm's best error=0.2575,\tbest estimator lgbm's best error=0.2575\n",
            "[flaml.automl.logger: 03-18 08:30:42] {2219} INFO - iteration 470, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:43] {2392} INFO -  at 279.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:30:43] {2219} INFO - iteration 471, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:43] {2392} INFO -  at 280.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:30:43] {2219} INFO - iteration 472, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:44] {2392} INFO -  at 280.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:30:44] {2219} INFO - iteration 473, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:45] {2392} INFO -  at 281.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:30:45] {2219} INFO - iteration 474, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:45] {2392} INFO -  at 282.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:30:45] {2219} INFO - iteration 475, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:46] {2392} INFO -  at 282.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:30:46] {2219} INFO - iteration 476, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:46] {2392} INFO -  at 283.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:30:46] {2219} INFO - iteration 477, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:47] {2392} INFO -  at 284.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:30:47] {2219} INFO - iteration 478, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:48] {2392} INFO -  at 284.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:30:48] {2219} INFO - iteration 479, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:48] {2392} INFO -  at 285.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:30:48] {2219} INFO - iteration 480, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:49] {2392} INFO -  at 285.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:30:49] {2219} INFO - iteration 481, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:50] {2392} INFO -  at 287.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:30:50] {2219} INFO - iteration 482, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:52] {2392} INFO -  at 288.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:30:52] {2219} INFO - iteration 483, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:52] {2392} INFO -  at 289.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:30:52] {2219} INFO - iteration 484, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:53] {2392} INFO -  at 289.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:30:53] {2219} INFO - iteration 485, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:53] {2392} INFO -  at 290.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:30:53] {2219} INFO - iteration 486, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:54] {2392} INFO -  at 290.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:30:54] {2219} INFO - iteration 487, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:55] {2392} INFO -  at 291.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:30:55] {2219} INFO - iteration 488, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:55] {2392} INFO -  at 292.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:30:55] {2219} INFO - iteration 489, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:56] {2392} INFO -  at 292.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:30:56] {2219} INFO - iteration 490, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:57] {2392} INFO -  at 293.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:30:57] {2219} INFO - iteration 491, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:58] {2392} INFO -  at 294.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:30:58] {2219} INFO - iteration 492, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:30:58] {2392} INFO -  at 294.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:30:58] {2219} INFO - iteration 493, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:00] {2392} INFO -  at 296.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:00] {2219} INFO - iteration 494, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:00] {2392} INFO -  at 296.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:00] {2219} INFO - iteration 495, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:01] {2392} INFO -  at 298.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:01] {2219} INFO - iteration 496, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:03] {2392} INFO -  at 300.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:03] {2219} INFO - iteration 497, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:04] {2392} INFO -  at 300.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:04] {2219} INFO - iteration 498, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:04] {2392} INFO -  at 301.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:04] {2219} INFO - iteration 499, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:05] {2392} INFO -  at 302.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:05] {2219} INFO - iteration 500, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:06] {2392} INFO -  at 302.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:06] {2219} INFO - iteration 501, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:07] {2392} INFO -  at 303.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:07] {2219} INFO - iteration 502, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:07] {2392} INFO -  at 304.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:07] {2219} INFO - iteration 503, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:08] {2392} INFO -  at 304.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:08] {2219} INFO - iteration 504, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:09] {2392} INFO -  at 305.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:09] {2219} INFO - iteration 505, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:09] {2392} INFO -  at 306.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:09] {2219} INFO - iteration 506, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:10] {2392} INFO -  at 306.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:10] {2219} INFO - iteration 507, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:11] {2392} INFO -  at 307.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:11] {2219} INFO - iteration 508, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:11] {2392} INFO -  at 307.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:11] {2219} INFO - iteration 509, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:11] {2392} INFO -  at 308.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:11] {2219} INFO - iteration 510, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:12] {2392} INFO -  at 309.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:12] {2219} INFO - iteration 511, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:13] {2392} INFO -  at 309.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:13] {2219} INFO - iteration 512, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:15] {2392} INFO -  at 312.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:15] {2219} INFO - iteration 513, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:16] {2392} INFO -  at 312.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:16] {2219} INFO - iteration 514, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:17] {2392} INFO -  at 313.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:17] {2219} INFO - iteration 515, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:18] {2392} INFO -  at 314.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:18] {2219} INFO - iteration 516, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:18] {2392} INFO -  at 315.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:18] {2219} INFO - iteration 517, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:19] {2392} INFO -  at 315.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:19] {2219} INFO - iteration 518, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:20] {2392} INFO -  at 316.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:20] {2219} INFO - iteration 519, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:20] {2392} INFO -  at 316.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:20] {2219} INFO - iteration 520, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:21] {2392} INFO -  at 317.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:21] {2219} INFO - iteration 521, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:21] {2392} INFO -  at 318.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:21] {2219} INFO - iteration 522, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:22] {2392} INFO -  at 318.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:22] {2219} INFO - iteration 523, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:23] {2392} INFO -  at 319.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:23] {2219} INFO - iteration 524, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:24] {2392} INFO -  at 320.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:24] {2219} INFO - iteration 525, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:24] {2392} INFO -  at 321.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:24] {2219} INFO - iteration 526, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:25] {2392} INFO -  at 321.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:25] {2219} INFO - iteration 527, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:28] {2392} INFO -  at 324.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:28] {2219} INFO - iteration 528, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:28] {2392} INFO -  at 324.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:28] {2219} INFO - iteration 529, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:29] {2392} INFO -  at 326.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:29] {2219} INFO - iteration 530, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:30] {2392} INFO -  at 326.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:30] {2219} INFO - iteration 531, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:31] {2392} INFO -  at 327.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:31] {2219} INFO - iteration 532, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:31] {2392} INFO -  at 327.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:31] {2219} INFO - iteration 533, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:32] {2392} INFO -  at 328.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:32] {2219} INFO - iteration 534, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:32] {2392} INFO -  at 329.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:32] {2219} INFO - iteration 535, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:34] {2392} INFO -  at 330.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:34] {2219} INFO - iteration 536, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:34] {2392} INFO -  at 330.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:34] {2219} INFO - iteration 537, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:35] {2392} INFO -  at 331.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:35] {2219} INFO - iteration 538, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:35] {2392} INFO -  at 332.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:35] {2219} INFO - iteration 539, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:36] {2392} INFO -  at 332.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:36] {2219} INFO - iteration 540, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:37] {2392} INFO -  at 333.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:37] {2219} INFO - iteration 541, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:40] {2392} INFO -  at 337.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:40] {2219} INFO - iteration 542, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:41] {2392} INFO -  at 337.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:41] {2219} INFO - iteration 543, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:41] {2392} INFO -  at 337.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:41] {2219} INFO - iteration 544, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:42] {2392} INFO -  at 338.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:42] {2219} INFO - iteration 545, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:42] {2392} INFO -  at 339.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:42] {2219} INFO - iteration 546, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:43] {2392} INFO -  at 340.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:43] {2219} INFO - iteration 547, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:44] {2392} INFO -  at 340.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:44] {2219} INFO - iteration 548, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:44] {2392} INFO -  at 341.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:44] {2219} INFO - iteration 549, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:45] {2392} INFO -  at 341.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:45] {2219} INFO - iteration 550, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:46] {2392} INFO -  at 342.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:46] {2219} INFO - iteration 551, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:47] {2392} INFO -  at 343.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:47] {2219} INFO - iteration 552, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:47] {2392} INFO -  at 343.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:47] {2219} INFO - iteration 553, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:48] {2392} INFO -  at 344.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:48] {2219} INFO - iteration 554, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:48] {2392} INFO -  at 345.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:48] {2219} INFO - iteration 555, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:51] {2392} INFO -  at 348.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:51] {2219} INFO - iteration 556, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:52] {2392} INFO -  at 348.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:52] {2219} INFO - iteration 557, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:52] {2392} INFO -  at 348.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:52] {2219} INFO - iteration 558, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:54] {2392} INFO -  at 350.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:54] {2219} INFO - iteration 559, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:55] {2392} INFO -  at 351.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:55] {2219} INFO - iteration 560, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:55] {2392} INFO -  at 351.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:55] {2219} INFO - iteration 561, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:57] {2392} INFO -  at 353.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:57] {2219} INFO - iteration 562, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:57] {2392} INFO -  at 353.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:57] {2219} INFO - iteration 563, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:57] {2392} INFO -  at 354.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:57] {2219} INFO - iteration 564, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:58] {2392} INFO -  at 355.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:58] {2219} INFO - iteration 565, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:31:59] {2392} INFO -  at 355.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:31:59] {2219} INFO - iteration 566, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:00] {2392} INFO -  at 357.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:00] {2219} INFO - iteration 567, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:02] {2392} INFO -  at 359.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:02] {2219} INFO - iteration 568, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:03] {2392} INFO -  at 359.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:03] {2219} INFO - iteration 569, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:03] {2392} INFO -  at 360.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:03] {2219} INFO - iteration 570, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:05] {2392} INFO -  at 361.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:05] {2219} INFO - iteration 571, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:06] {2392} INFO -  at 362.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:06] {2219} INFO - iteration 572, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:06] {2392} INFO -  at 362.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:06] {2219} INFO - iteration 573, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:06] {2392} INFO -  at 363.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:06] {2219} INFO - iteration 574, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:08] {2392} INFO -  at 364.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:08] {2219} INFO - iteration 575, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:08] {2392} INFO -  at 365.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:08] {2219} INFO - iteration 576, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:09] {2392} INFO -  at 365.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:09] {2219} INFO - iteration 577, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:10] {2392} INFO -  at 366.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:10] {2219} INFO - iteration 578, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:10] {2392} INFO -  at 367.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:10] {2219} INFO - iteration 579, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:11] {2392} INFO -  at 367.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:11] {2219} INFO - iteration 580, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:12] {2392} INFO -  at 368.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:12] {2219} INFO - iteration 581, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:12] {2392} INFO -  at 369.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:12] {2219} INFO - iteration 582, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:14] {2392} INFO -  at 371.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:14] {2219} INFO - iteration 583, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:15] {2392} INFO -  at 371.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:15] {2219} INFO - iteration 584, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:16] {2392} INFO -  at 373.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:16] {2219} INFO - iteration 585, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:17] {2392} INFO -  at 373.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:17] {2219} INFO - iteration 586, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:18] {2392} INFO -  at 374.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:18] {2219} INFO - iteration 587, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:18] {2392} INFO -  at 374.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:18] {2219} INFO - iteration 588, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:19] {2392} INFO -  at 375.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:19] {2219} INFO - iteration 589, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:20] {2392} INFO -  at 376.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:20] {2219} INFO - iteration 590, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:21] {2392} INFO -  at 377.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:21] {2219} INFO - iteration 591, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:21] {2392} INFO -  at 378.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:21] {2219} INFO - iteration 592, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:22] {2392} INFO -  at 378.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:22] {2219} INFO - iteration 593, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:23] {2392} INFO -  at 379.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:23] {2219} INFO - iteration 594, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:23] {2392} INFO -  at 380.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:23] {2219} INFO - iteration 595, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:23] {2392} INFO -  at 380.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:23] {2219} INFO - iteration 596, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:26] {2392} INFO -  at 382.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:26] {2219} INFO - iteration 597, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:27] {2392} INFO -  at 383.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:27] {2219} INFO - iteration 598, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:28] {2392} INFO -  at 384.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:28] {2219} INFO - iteration 599, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:28] {2392} INFO -  at 384.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:28] {2219} INFO - iteration 600, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:29] {2392} INFO -  at 385.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:29] {2219} INFO - iteration 601, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:30] {2392} INFO -  at 386.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:30] {2219} INFO - iteration 602, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:30] {2392} INFO -  at 386.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:30] {2219} INFO - iteration 603, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:31] {2392} INFO -  at 387.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:31] {2219} INFO - iteration 604, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:31] {2392} INFO -  at 388.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:31] {2219} INFO - iteration 605, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:32] {2392} INFO -  at 388.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:32] {2219} INFO - iteration 606, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:33] {2392} INFO -  at 389.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:33] {2219} INFO - iteration 607, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:33] {2392} INFO -  at 390.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:34] {2219} INFO - iteration 608, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:34] {2392} INFO -  at 390.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:34] {2219} INFO - iteration 609, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:34] {2392} INFO -  at 391.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:34] {2219} INFO - iteration 610, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:35] {2392} INFO -  at 392.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:35] {2219} INFO - iteration 611, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:36] {2392} INFO -  at 393.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:36] {2219} INFO - iteration 612, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:39] {2392} INFO -  at 395.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:39] {2219} INFO - iteration 613, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:40] {2392} INFO -  at 396.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:40] {2219} INFO - iteration 614, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:40] {2392} INFO -  at 396.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:40] {2219} INFO - iteration 615, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:40] {2392} INFO -  at 397.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:40] {2219} INFO - iteration 616, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:41] {2392} INFO -  at 398.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:41] {2219} INFO - iteration 617, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:42] {2392} INFO -  at 398.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:42] {2219} INFO - iteration 618, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:43] {2392} INFO -  at 399.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:43] {2219} INFO - iteration 619, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:44] {2392} INFO -  at 401.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:44] {2219} INFO - iteration 620, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:45] {2392} INFO -  at 401.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:45] {2219} INFO - iteration 621, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:45] {2392} INFO -  at 401.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:45] {2219} INFO - iteration 622, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:46] {2392} INFO -  at 402.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:46] {2219} INFO - iteration 623, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:46] {2392} INFO -  at 403.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:46] {2219} INFO - iteration 624, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:47] {2392} INFO -  at 403.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:47] {2219} INFO - iteration 625, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:48] {2392} INFO -  at 405.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:48] {2219} INFO - iteration 626, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:50] {2392} INFO -  at 407.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:50] {2219} INFO - iteration 627, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:52] {2392} INFO -  at 408.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:52] {2219} INFO - iteration 628, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:52] {2392} INFO -  at 409.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:52] {2219} INFO - iteration 629, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:53] {2392} INFO -  at 410.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:53] {2219} INFO - iteration 630, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:54] {2392} INFO -  at 410.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:54] {2219} INFO - iteration 631, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:54] {2392} INFO -  at 411.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:54] {2219} INFO - iteration 632, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:55] {2392} INFO -  at 411.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:55] {2219} INFO - iteration 633, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:56] {2392} INFO -  at 413.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:56] {2219} INFO - iteration 634, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:57] {2392} INFO -  at 413.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:57] {2219} INFO - iteration 635, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:57] {2392} INFO -  at 413.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:57] {2219} INFO - iteration 636, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:58] {2392} INFO -  at 414.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:58] {2219} INFO - iteration 637, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:58] {2392} INFO -  at 415.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:58] {2219} INFO - iteration 638, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:59] {2392} INFO -  at 415.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:59] {2219} INFO - iteration 639, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:32:59] {2392} INFO -  at 416.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:32:59] {2219} INFO - iteration 640, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:02] {2392} INFO -  at 418.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:02] {2219} INFO - iteration 641, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:03] {2392} INFO -  at 419.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:03] {2219} INFO - iteration 642, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:03] {2392} INFO -  at 420.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:03] {2219} INFO - iteration 643, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:04] {2392} INFO -  at 420.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:04] {2219} INFO - iteration 644, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:05] {2392} INFO -  at 421.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:05] {2219} INFO - iteration 645, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:05] {2392} INFO -  at 422.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:05] {2219} INFO - iteration 646, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:06] {2392} INFO -  at 422.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:06] {2219} INFO - iteration 647, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:07] {2392} INFO -  at 423.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:07] {2219} INFO - iteration 648, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:07] {2392} INFO -  at 423.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:07] {2219} INFO - iteration 649, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:08] {2392} INFO -  at 424.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:08] {2219} INFO - iteration 650, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:08] {2392} INFO -  at 425.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:08] {2219} INFO - iteration 651, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:09] {2392} INFO -  at 425.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:09] {2219} INFO - iteration 652, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:10] {2392} INFO -  at 426.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:10] {2219} INFO - iteration 653, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:11] {2392} INFO -  at 427.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:11] {2219} INFO - iteration 654, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:11] {2392} INFO -  at 428.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:11] {2219} INFO - iteration 655, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:12] {2392} INFO -  at 428.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:12] {2219} INFO - iteration 656, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:14] {2392} INFO -  at 431.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:14] {2219} INFO - iteration 657, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:15] {2392} INFO -  at 431.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:15] {2219} INFO - iteration 658, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:16] {2392} INFO -  at 432.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:16] {2219} INFO - iteration 659, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:16] {2392} INFO -  at 433.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:16] {2219} INFO - iteration 660, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:17] {2392} INFO -  at 433.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:17] {2219} INFO - iteration 661, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:18] {2392} INFO -  at 434.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:18] {2219} INFO - iteration 662, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:18] {2392} INFO -  at 435.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:18] {2219} INFO - iteration 663, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:19] {2392} INFO -  at 435.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:19] {2219} INFO - iteration 664, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:20] {2392} INFO -  at 436.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:20] {2219} INFO - iteration 665, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:20] {2392} INFO -  at 437.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:20] {2219} INFO - iteration 666, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:21] {2392} INFO -  at 437.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:21] {2219} INFO - iteration 667, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:22] {2392} INFO -  at 438.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:22] {2219} INFO - iteration 668, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:22] {2392} INFO -  at 439.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:22] {2219} INFO - iteration 669, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:24] {2392} INFO -  at 440.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:24] {2219} INFO - iteration 670, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:24] {2392} INFO -  at 440.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:24] {2219} INFO - iteration 671, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:26] {2392} INFO -  at 443.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:26] {2219} INFO - iteration 672, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:27] {2392} INFO -  at 443.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:27] {2219} INFO - iteration 673, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:27] {2392} INFO -  at 444.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:27] {2219} INFO - iteration 674, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:28] {2392} INFO -  at 445.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:28] {2219} INFO - iteration 675, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:29] {2392} INFO -  at 445.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:29] {2219} INFO - iteration 676, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:30] {2392} INFO -  at 446.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:30] {2219} INFO - iteration 677, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:31] {2392} INFO -  at 447.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:31] {2219} INFO - iteration 678, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:31] {2392} INFO -  at 448.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:31] {2219} INFO - iteration 679, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:32] {2392} INFO -  at 448.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:32] {2219} INFO - iteration 680, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:33] {2392} INFO -  at 449.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:33] {2219} INFO - iteration 681, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:34] {2392} INFO -  at 450.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:34] {2219} INFO - iteration 682, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:35] {2392} INFO -  at 451.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:35] {2219} INFO - iteration 683, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:35] {2392} INFO -  at 451.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:35] {2219} INFO - iteration 684, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:37] {2392} INFO -  at 453.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:37] {2219} INFO - iteration 685, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:39] {2392} INFO -  at 455.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:39] {2219} INFO - iteration 686, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:39] {2392} INFO -  at 456.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:39] {2219} INFO - iteration 687, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:40] {2392} INFO -  at 456.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:40] {2219} INFO - iteration 688, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:41] {2392} INFO -  at 457.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:41] {2219} INFO - iteration 689, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:42] {2392} INFO -  at 458.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:42] {2219} INFO - iteration 690, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:42] {2392} INFO -  at 458.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:42] {2219} INFO - iteration 691, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:43] {2392} INFO -  at 459.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:43] {2219} INFO - iteration 692, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:43] {2392} INFO -  at 460.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:43] {2219} INFO - iteration 693, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:45] {2392} INFO -  at 461.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:45] {2219} INFO - iteration 694, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:46] {2392} INFO -  at 462.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:46] {2219} INFO - iteration 695, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:46] {2392} INFO -  at 462.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:46] {2219} INFO - iteration 696, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:48] {2392} INFO -  at 464.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:48] {2219} INFO - iteration 697, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:51] {2392} INFO -  at 468.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:51] {2219} INFO - iteration 698, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:53] {2392} INFO -  at 469.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:53] {2219} INFO - iteration 699, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:53] {2392} INFO -  at 469.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:53] {2219} INFO - iteration 700, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:55] {2392} INFO -  at 471.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:55] {2219} INFO - iteration 701, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:56] {2392} INFO -  at 472.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:56] {2219} INFO - iteration 702, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:56] {2392} INFO -  at 473.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:56] {2219} INFO - iteration 703, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:57] {2392} INFO -  at 473.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:57] {2219} INFO - iteration 704, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:58] {2392} INFO -  at 474.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:58] {2219} INFO - iteration 705, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:58] {2392} INFO -  at 474.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:58] {2219} INFO - iteration 706, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:33:59] {2392} INFO -  at 475.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:33:59] {2219} INFO - iteration 707, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:00] {2392} INFO -  at 476.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:00] {2219} INFO - iteration 708, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:00] {2392} INFO -  at 476.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:00] {2219} INFO - iteration 709, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:01] {2392} INFO -  at 477.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:01] {2219} INFO - iteration 710, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:02] {2392} INFO -  at 478.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:02] {2219} INFO - iteration 711, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:02] {2392} INFO -  at 479.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:02] {2219} INFO - iteration 712, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:04] {2392} INFO -  at 481.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:04] {2219} INFO - iteration 713, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:05] {2392} INFO -  at 481.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:05] {2219} INFO - iteration 714, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:05] {2392} INFO -  at 482.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:05] {2219} INFO - iteration 715, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:07] {2392} INFO -  at 483.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:07] {2219} INFO - iteration 716, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:07] {2392} INFO -  at 483.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:07] {2219} INFO - iteration 717, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:08] {2392} INFO -  at 484.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:08] {2219} INFO - iteration 718, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:08] {2392} INFO -  at 485.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:08] {2219} INFO - iteration 719, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:09] {2392} INFO -  at 485.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:09] {2219} INFO - iteration 720, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:10] {2392} INFO -  at 486.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:10] {2219} INFO - iteration 721, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:10] {2392} INFO -  at 486.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:10] {2219} INFO - iteration 722, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:11] {2392} INFO -  at 487.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:11] {2219} INFO - iteration 723, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:12] {2392} INFO -  at 489.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:12] {2219} INFO - iteration 724, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:13] {2392} INFO -  at 489.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:13] {2219} INFO - iteration 725, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:13] {2392} INFO -  at 490.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:13] {2219} INFO - iteration 726, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:14] {2392} INFO -  at 490.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:14] {2219} INFO - iteration 727, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:16] {2392} INFO -  at 493.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:16] {2219} INFO - iteration 728, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:17] {2392} INFO -  at 493.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:17] {2219} INFO - iteration 729, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:17] {2392} INFO -  at 494.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:17] {2219} INFO - iteration 730, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:18] {2392} INFO -  at 494.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:18] {2219} INFO - iteration 731, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:19] {2392} INFO -  at 495.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:19] {2219} INFO - iteration 732, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:19] {2392} INFO -  at 495.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:19] {2219} INFO - iteration 733, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:20] {2392} INFO -  at 496.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:20] {2219} INFO - iteration 734, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:20] {2392} INFO -  at 497.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:20] {2219} INFO - iteration 735, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:21] {2392} INFO -  at 497.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:21] {2219} INFO - iteration 736, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:21] {2392} INFO -  at 498.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:21] {2219} INFO - iteration 737, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:22] {2392} INFO -  at 499.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:22] {2219} INFO - iteration 738, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:23] {2392} INFO -  at 499.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:23] {2219} INFO - iteration 739, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:23] {2392} INFO -  at 499.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:23] {2219} INFO - iteration 740, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:24] {2392} INFO -  at 500.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:24] {2219} INFO - iteration 741, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:24] {2392} INFO -  at 501.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:24] {2219} INFO - iteration 742, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:25] {2392} INFO -  at 502.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:25] {2219} INFO - iteration 743, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:26] {2392} INFO -  at 502.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:26] {2219} INFO - iteration 744, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:28] {2392} INFO -  at 504.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:28] {2219} INFO - iteration 745, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:28] {2392} INFO -  at 505.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:28] {2219} INFO - iteration 746, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:29] {2392} INFO -  at 506.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:29] {2219} INFO - iteration 747, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:30] {2392} INFO -  at 506.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:30] {2219} INFO - iteration 748, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:31] {2392} INFO -  at 507.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:31] {2219} INFO - iteration 749, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:31] {2392} INFO -  at 508.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:31] {2219} INFO - iteration 750, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:32] {2392} INFO -  at 508.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:32] {2219} INFO - iteration 751, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:33] {2392} INFO -  at 509.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:33] {2219} INFO - iteration 752, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:33] {2392} INFO -  at 509.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:33] {2219} INFO - iteration 753, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:34] {2392} INFO -  at 510.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:34] {2219} INFO - iteration 754, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:35] {2392} INFO -  at 511.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:35] {2219} INFO - iteration 755, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:35] {2392} INFO -  at 512.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:35] {2219} INFO - iteration 756, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:36] {2392} INFO -  at 512.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:36] {2219} INFO - iteration 757, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:36] {2392} INFO -  at 513.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:36] {2219} INFO - iteration 758, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:37] {2392} INFO -  at 513.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:37] {2219} INFO - iteration 759, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:37] {2392} INFO -  at 514.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:37] {2219} INFO - iteration 760, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:39] {2392} INFO -  at 516.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:39] {2219} INFO - iteration 761, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:40] {2392} INFO -  at 516.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:40] {2219} INFO - iteration 762, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:41] {2392} INFO -  at 517.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:41] {2219} INFO - iteration 763, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:41] {2392} INFO -  at 518.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:41] {2219} INFO - iteration 764, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:42] {2392} INFO -  at 518.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:42] {2219} INFO - iteration 765, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:42] {2392} INFO -  at 519.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:42] {2219} INFO - iteration 766, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:43] {2392} INFO -  at 519.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:43] {2219} INFO - iteration 767, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:43] {2392} INFO -  at 520.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:43] {2219} INFO - iteration 768, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:44] {2392} INFO -  at 521.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:44] {2219} INFO - iteration 769, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:45] {2392} INFO -  at 521.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:45] {2219} INFO - iteration 770, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:46] {2392} INFO -  at 522.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:46] {2219} INFO - iteration 771, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:46] {2392} INFO -  at 523.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:46] {2219} INFO - iteration 772, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:47] {2392} INFO -  at 523.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:47] {2219} INFO - iteration 773, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:48] {2392} INFO -  at 524.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:48] {2219} INFO - iteration 774, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:48] {2392} INFO -  at 525.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:48] {2219} INFO - iteration 775, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:49] {2392} INFO -  at 525.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:49] {2219} INFO - iteration 776, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:51] {2392} INFO -  at 527.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:51] {2219} INFO - iteration 777, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:51] {2392} INFO -  at 527.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:51] {2219} INFO - iteration 778, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:52] {2392} INFO -  at 529.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:52] {2219} INFO - iteration 779, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:53] {2392} INFO -  at 529.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:53] {2219} INFO - iteration 780, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:54] {2392} INFO -  at 530.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:54] {2219} INFO - iteration 781, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:54] {2392} INFO -  at 531.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:54] {2219} INFO - iteration 782, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:55] {2392} INFO -  at 531.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:55] {2219} INFO - iteration 783, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:55] {2392} INFO -  at 532.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:55] {2219} INFO - iteration 784, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:56] {2392} INFO -  at 533.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:56] {2219} INFO - iteration 785, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:57] {2392} INFO -  at 533.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:57] {2219} INFO - iteration 786, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:58] {2392} INFO -  at 534.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:58] {2219} INFO - iteration 787, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:58] {2392} INFO -  at 534.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:58] {2219} INFO - iteration 788, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:34:59] {2392} INFO -  at 535.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:34:59] {2219} INFO - iteration 789, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:00] {2392} INFO -  at 536.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:00] {2219} INFO - iteration 790, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:00] {2392} INFO -  at 537.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:00] {2219} INFO - iteration 791, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:01] {2392} INFO -  at 537.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:01] {2219} INFO - iteration 792, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:03] {2392} INFO -  at 540.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:03] {2219} INFO - iteration 793, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:04] {2392} INFO -  at 540.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:04] {2219} INFO - iteration 794, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:05] {2392} INFO -  at 541.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:05] {2219} INFO - iteration 795, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:05] {2392} INFO -  at 542.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:05] {2219} INFO - iteration 796, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:06] {2392} INFO -  at 542.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:06] {2219} INFO - iteration 797, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:06] {2392} INFO -  at 543.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:06] {2219} INFO - iteration 798, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:07] {2392} INFO -  at 543.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:07] {2219} INFO - iteration 799, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:08] {2392} INFO -  at 544.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:08] {2219} INFO - iteration 800, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:08] {2392} INFO -  at 545.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:08] {2219} INFO - iteration 801, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:09] {2392} INFO -  at 545.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:09] {2219} INFO - iteration 802, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:10] {2392} INFO -  at 546.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:10] {2219} INFO - iteration 803, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:11] {2392} INFO -  at 547.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:11] {2219} INFO - iteration 804, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:11] {2392} INFO -  at 547.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:11] {2219} INFO - iteration 805, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:12] {2392} INFO -  at 548.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:12] {2219} INFO - iteration 806, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:12] {2392} INFO -  at 549.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:12] {2219} INFO - iteration 807, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:15] {2392} INFO -  at 551.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:15] {2219} INFO - iteration 808, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:15] {2392} INFO -  at 552.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:15] {2219} INFO - iteration 809, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:16] {2392} INFO -  at 552.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:16] {2219} INFO - iteration 810, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:16] {2392} INFO -  at 553.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:16] {2219} INFO - iteration 811, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:17] {2392} INFO -  at 553.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:17] {2219} INFO - iteration 812, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:18] {2392} INFO -  at 554.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:18] {2219} INFO - iteration 813, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:18] {2392} INFO -  at 555.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:18] {2219} INFO - iteration 814, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:19] {2392} INFO -  at 555.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:19] {2219} INFO - iteration 815, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:19] {2392} INFO -  at 556.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:19] {2219} INFO - iteration 816, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:20] {2392} INFO -  at 556.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:20] {2219} INFO - iteration 817, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:21] {2392} INFO -  at 557.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:21] {2219} INFO - iteration 818, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:21] {2392} INFO -  at 557.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:21] {2219} INFO - iteration 819, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:22] {2392} INFO -  at 558.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:22] {2219} INFO - iteration 820, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:22] {2392} INFO -  at 559.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:22] {2219} INFO - iteration 821, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:23] {2392} INFO -  at 560.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:23] {2219} INFO - iteration 822, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:24] {2392} INFO -  at 560.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:24] {2219} INFO - iteration 823, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:26] {2392} INFO -  at 562.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:26] {2219} INFO - iteration 824, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:26] {2392} INFO -  at 563.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:26] {2219} INFO - iteration 825, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:27] {2392} INFO -  at 563.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:27] {2219} INFO - iteration 826, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:28] {2392} INFO -  at 564.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:28] {2219} INFO - iteration 827, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:28] {2392} INFO -  at 564.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:28] {2219} INFO - iteration 828, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:29] {2392} INFO -  at 565.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:29] {2219} INFO - iteration 829, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:29] {2392} INFO -  at 566.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:29] {2219} INFO - iteration 830, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:30] {2392} INFO -  at 566.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:30] {2219} INFO - iteration 831, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:31] {2392} INFO -  at 567.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:31] {2219} INFO - iteration 832, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:31] {2392} INFO -  at 568.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:31] {2219} INFO - iteration 833, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:32] {2392} INFO -  at 569.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:32] {2219} INFO - iteration 834, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:33] {2392} INFO -  at 569.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:33] {2219} INFO - iteration 835, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:33] {2392} INFO -  at 569.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:33] {2219} INFO - iteration 836, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:34] {2392} INFO -  at 570.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:34] {2219} INFO - iteration 837, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:34] {2392} INFO -  at 571.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:34] {2219} INFO - iteration 838, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:35] {2392} INFO -  at 572.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:35] {2219} INFO - iteration 839, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:36] {2392} INFO -  at 572.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:36] {2219} INFO - iteration 840, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:38] {2392} INFO -  at 575.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:38] {2219} INFO - iteration 841, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:39] {2392} INFO -  at 575.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:39] {2219} INFO - iteration 842, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:40] {2392} INFO -  at 576.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:40] {2219} INFO - iteration 843, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:40] {2392} INFO -  at 577.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:40] {2219} INFO - iteration 844, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:41] {2392} INFO -  at 577.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:41] {2219} INFO - iteration 845, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:41] {2392} INFO -  at 578.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:41] {2219} INFO - iteration 846, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:42] {2392} INFO -  at 579.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:42] {2219} INFO - iteration 847, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:43] {2392} INFO -  at 579.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:43] {2219} INFO - iteration 848, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:44] {2392} INFO -  at 580.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:44] {2219} INFO - iteration 849, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:44] {2392} INFO -  at 581.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:44] {2219} INFO - iteration 850, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:45] {2392} INFO -  at 581.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:45] {2219} INFO - iteration 851, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:46] {2392} INFO -  at 582.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:46] {2219} INFO - iteration 852, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:46] {2392} INFO -  at 583.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:46] {2219} INFO - iteration 853, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:47] {2392} INFO -  at 583.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:47] {2219} INFO - iteration 854, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:48] {2392} INFO -  at 584.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:48] {2219} INFO - iteration 855, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:50] {2392} INFO -  at 586.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:50] {2219} INFO - iteration 856, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:51] {2392} INFO -  at 587.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:51] {2219} INFO - iteration 857, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:51] {2392} INFO -  at 588.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:51] {2219} INFO - iteration 858, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:52] {2392} INFO -  at 588.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:52] {2219} INFO - iteration 859, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:52] {2392} INFO -  at 589.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:52] {2219} INFO - iteration 860, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:53] {2392} INFO -  at 590.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:53] {2219} INFO - iteration 861, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:54] {2392} INFO -  at 590.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:54] {2219} INFO - iteration 862, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:54] {2392} INFO -  at 591.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:54] {2219} INFO - iteration 863, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:55] {2392} INFO -  at 591.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:55] {2219} INFO - iteration 864, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:56] {2392} INFO -  at 592.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:56] {2219} INFO - iteration 865, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:56] {2392} INFO -  at 593.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:56] {2219} INFO - iteration 866, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:57] {2392} INFO -  at 593.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:57] {2219} INFO - iteration 867, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:57] {2392} INFO -  at 594.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:57] {2219} INFO - iteration 868, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:58] {2392} INFO -  at 594.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:58] {2219} INFO - iteration 869, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:35:58] {2392} INFO -  at 595.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:35:58] {2219} INFO - iteration 870, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:01] {2392} INFO -  at 597.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:01] {2219} INFO - iteration 871, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:02] {2392} INFO -  at 598.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:02] {2219} INFO - iteration 872, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:02] {2392} INFO -  at 599.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:02] {2219} INFO - iteration 873, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:03] {2392} INFO -  at 600.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:03] {2219} INFO - iteration 874, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:04] {2392} INFO -  at 600.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:04] {2219} INFO - iteration 875, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:05] {2392} INFO -  at 601.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:05] {2219} INFO - iteration 876, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:05] {2392} INFO -  at 601.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:05] {2219} INFO - iteration 877, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:05] {2392} INFO -  at 602.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:05] {2219} INFO - iteration 878, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:07] {2392} INFO -  at 603.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:07] {2219} INFO - iteration 879, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:07] {2392} INFO -  at 604.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:07] {2219} INFO - iteration 880, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:08] {2392} INFO -  at 604.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:08] {2219} INFO - iteration 881, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:08] {2392} INFO -  at 605.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:08] {2219} INFO - iteration 882, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:09] {2392} INFO -  at 606.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:09] {2219} INFO - iteration 883, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:10] {2392} INFO -  at 606.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:10] {2219} INFO - iteration 884, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:11] {2392} INFO -  at 607.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:11] {2219} INFO - iteration 885, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:13] {2392} INFO -  at 609.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:13] {2219} INFO - iteration 886, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:14] {2392} INFO -  at 610.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:14] {2219} INFO - iteration 887, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:14] {2392} INFO -  at 610.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:14] {2219} INFO - iteration 888, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:15] {2392} INFO -  at 611.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:15] {2219} INFO - iteration 889, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:15] {2392} INFO -  at 612.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:15] {2219} INFO - iteration 890, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:16] {2392} INFO -  at 612.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:16] {2219} INFO - iteration 891, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:16] {2392} INFO -  at 613.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:16] {2219} INFO - iteration 892, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:17] {2392} INFO -  at 613.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:17] {2219} INFO - iteration 893, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:17] {2392} INFO -  at 614.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:17] {2219} INFO - iteration 894, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:18] {2392} INFO -  at 615.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:18] {2219} INFO - iteration 895, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:19] {2392} INFO -  at 615.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:19] {2219} INFO - iteration 896, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:20] {2392} INFO -  at 616.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:20] {2219} INFO - iteration 897, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:20] {2392} INFO -  at 616.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:20] {2219} INFO - iteration 898, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:21] {2392} INFO -  at 617.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:21] {2219} INFO - iteration 899, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:22] {2392} INFO -  at 618.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:22] {2219} INFO - iteration 900, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:22] {2392} INFO -  at 618.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:22] {2219} INFO - iteration 901, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:25] {2392} INFO -  at 621.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:25] {2219} INFO - iteration 902, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:25] {2392} INFO -  at 622.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:25] {2219} INFO - iteration 903, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:26] {2392} INFO -  at 622.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:26] {2219} INFO - iteration 904, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:26] {2392} INFO -  at 623.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:26] {2219} INFO - iteration 905, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:27] {2392} INFO -  at 623.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:27] {2219} INFO - iteration 906, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:28] {2392} INFO -  at 624.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:28] {2219} INFO - iteration 907, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:29] {2392} INFO -  at 625.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:29] {2219} INFO - iteration 908, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:29] {2392} INFO -  at 625.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:29] {2219} INFO - iteration 909, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:30] {2392} INFO -  at 626.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:30] {2219} INFO - iteration 910, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:30] {2392} INFO -  at 626.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:30] {2219} INFO - iteration 911, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:31] {2392} INFO -  at 627.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:31] {2219} INFO - iteration 912, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:31] {2392} INFO -  at 628.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:31] {2219} INFO - iteration 913, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:32] {2392} INFO -  at 629.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:32] {2219} INFO - iteration 914, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:33] {2392} INFO -  at 629.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:33] {2219} INFO - iteration 915, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:33] {2392} INFO -  at 630.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:33] {2219} INFO - iteration 916, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:34] {2392} INFO -  at 630.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:34] {2219} INFO - iteration 917, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:34] {2392} INFO -  at 631.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:34] {2219} INFO - iteration 918, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:37] {2392} INFO -  at 633.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:37] {2219} INFO - iteration 919, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:37] {2392} INFO -  at 633.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:37] {2219} INFO - iteration 920, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:38] {2392} INFO -  at 634.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:38] {2219} INFO - iteration 921, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:38] {2392} INFO -  at 635.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:38] {2219} INFO - iteration 922, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:39] {2392} INFO -  at 635.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:39] {2219} INFO - iteration 923, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:40] {2392} INFO -  at 636.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:40] {2219} INFO - iteration 924, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:41] {2392} INFO -  at 637.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:41] {2219} INFO - iteration 925, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:41] {2392} INFO -  at 638.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:41] {2219} INFO - iteration 926, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:42] {2392} INFO -  at 638.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:42] {2219} INFO - iteration 927, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:43] {2392} INFO -  at 639.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:43] {2219} INFO - iteration 928, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:43] {2392} INFO -  at 639.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:43] {2219} INFO - iteration 929, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:44] {2392} INFO -  at 640.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:44] {2219} INFO - iteration 930, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:44] {2392} INFO -  at 641.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:44] {2219} INFO - iteration 931, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:45] {2392} INFO -  at 641.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:45] {2219} INFO - iteration 932, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:46] {2392} INFO -  at 642.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:46] {2219} INFO - iteration 933, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:46] {2392} INFO -  at 643.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:46] {2219} INFO - iteration 934, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:48] {2392} INFO -  at 645.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:48] {2219} INFO - iteration 935, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:49] {2392} INFO -  at 645.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:49] {2219} INFO - iteration 936, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:50] {2392} INFO -  at 646.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:50] {2219} INFO - iteration 937, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:50] {2392} INFO -  at 646.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:50] {2219} INFO - iteration 938, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:51] {2392} INFO -  at 647.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:51] {2219} INFO - iteration 939, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:51] {2392} INFO -  at 648.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:51] {2219} INFO - iteration 940, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:52] {2392} INFO -  at 648.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:52] {2219} INFO - iteration 941, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:53] {2392} INFO -  at 649.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:53] {2219} INFO - iteration 942, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:53] {2392} INFO -  at 650.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:53] {2219} INFO - iteration 943, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:54] {2392} INFO -  at 650.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:54] {2219} INFO - iteration 944, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:55] {2392} INFO -  at 651.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:55] {2219} INFO - iteration 945, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:55] {2392} INFO -  at 652.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:55] {2219} INFO - iteration 946, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:56] {2392} INFO -  at 652.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:56] {2219} INFO - iteration 947, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:56] {2392} INFO -  at 653.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:56] {2219} INFO - iteration 948, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:57] {2392} INFO -  at 654.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:57] {2219} INFO - iteration 949, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:36:58] {2392} INFO -  at 654.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:36:58] {2219} INFO - iteration 950, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:00] {2392} INFO -  at 656.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:00] {2219} INFO - iteration 951, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:01] {2392} INFO -  at 657.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:01] {2219} INFO - iteration 952, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:01] {2392} INFO -  at 658.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:01] {2219} INFO - iteration 953, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:02] {2392} INFO -  at 658.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:02] {2219} INFO - iteration 954, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:02] {2392} INFO -  at 659.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:02] {2219} INFO - iteration 955, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:03] {2392} INFO -  at 659.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:03] {2219} INFO - iteration 956, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:04] {2392} INFO -  at 660.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:04] {2219} INFO - iteration 957, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:04] {2392} INFO -  at 661.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:04] {2219} INFO - iteration 958, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:05] {2392} INFO -  at 661.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:05] {2219} INFO - iteration 959, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:05] {2392} INFO -  at 662.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:05] {2219} INFO - iteration 960, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:06] {2392} INFO -  at 663.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:06] {2219} INFO - iteration 961, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:07] {2392} INFO -  at 663.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:07] {2219} INFO - iteration 962, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:08] {2392} INFO -  at 664.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:08] {2219} INFO - iteration 963, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:08] {2392} INFO -  at 665.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:08] {2219} INFO - iteration 964, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:09] {2392} INFO -  at 665.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:09] {2219} INFO - iteration 965, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:10] {2392} INFO -  at 666.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:10] {2219} INFO - iteration 966, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:12] {2392} INFO -  at 668.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:12] {2219} INFO - iteration 967, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:13] {2392} INFO -  at 669.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:13] {2219} INFO - iteration 968, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:13] {2392} INFO -  at 669.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:13] {2219} INFO - iteration 969, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:14] {2392} INFO -  at 670.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:14] {2219} INFO - iteration 970, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:14] {2392} INFO -  at 671.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:14] {2219} INFO - iteration 971, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:15] {2392} INFO -  at 671.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:15] {2219} INFO - iteration 972, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:16] {2392} INFO -  at 672.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:16] {2219} INFO - iteration 973, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:16] {2392} INFO -  at 673.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:16] {2219} INFO - iteration 974, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:17] {2392} INFO -  at 673.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:17] {2219} INFO - iteration 975, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:17] {2392} INFO -  at 674.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:18] {2219} INFO - iteration 976, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:18] {2392} INFO -  at 675.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:18] {2219} INFO - iteration 977, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:19] {2392} INFO -  at 676.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:19] {2219} INFO - iteration 978, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:20] {2392} INFO -  at 676.5s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:20] {2219} INFO - iteration 979, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:20] {2392} INFO -  at 677.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:20] {2219} INFO - iteration 980, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:21] {2392} INFO -  at 677.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:21] {2219} INFO - iteration 981, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:22] {2392} INFO -  at 678.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:22] {2219} INFO - iteration 982, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:24] {2392} INFO -  at 680.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:24] {2219} INFO - iteration 983, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:24] {2392} INFO -  at 681.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:24] {2219} INFO - iteration 984, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:25] {2392} INFO -  at 681.6s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:25] {2219} INFO - iteration 985, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:25] {2392} INFO -  at 682.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:25] {2219} INFO - iteration 986, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:26] {2392} INFO -  at 682.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:26] {2219} INFO - iteration 987, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:26] {2392} INFO -  at 683.3s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:26] {2219} INFO - iteration 988, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:27] {2392} INFO -  at 684.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:27] {2219} INFO - iteration 989, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:28] {2392} INFO -  at 684.8s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:28] {2219} INFO - iteration 990, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:29] {2392} INFO -  at 685.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:29] {2219} INFO - iteration 991, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:29] {2392} INFO -  at 686.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:29] {2219} INFO - iteration 992, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:30] {2392} INFO -  at 686.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:30] {2219} INFO - iteration 993, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:30] {2392} INFO -  at 687.1s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:30] {2219} INFO - iteration 994, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:31] {2392} INFO -  at 688.0s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:31] {2219} INFO - iteration 995, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:32] {2392} INFO -  at 688.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:32] {2219} INFO - iteration 996, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:33] {2392} INFO -  at 689.4s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:33] {2219} INFO - iteration 997, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:35] {2392} INFO -  at 691.7s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:35] {2219} INFO - iteration 998, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:35] {2392} INFO -  at 692.2s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:35] {2219} INFO - iteration 999, current learner lgbm\n",
            "[flaml.automl.logger: 03-18 08:37:36] {2392} INFO -  at 692.9s,\testimator lgbm's best error=0.2141,\tbest estimator lgbm's best error=0.2141\n",
            "[flaml.automl.logger: 03-18 08:37:36] {2494} INFO - selected model: LGBMClassifier(colsample_bytree=0.8367963922792151,\n",
            "               learning_rate=0.4262706132651898, max_bin=1023,\n",
            "               min_child_samples=8, n_estimators=1, n_jobs=-1, num_leaves=5,\n",
            "               reg_alpha=0.032199870944391765, reg_lambda=0.2662920618667403,\n",
            "               verbose=-1)\n",
            "[flaml.automl.logger: 03-18 08:37:36] {1931} INFO - fit succeeded\n",
            "[flaml.automl.logger: 03-18 08:37:36] {1932} INFO - Time taken to find the best model: 279.5030481815338\n"
          ]
        }
      ],
      "source": [
        "# !pip -q install flaml\n",
        "from flaml import AutoML\n",
        "automl = AutoML()\n",
        "automl.fit(indicators, target, X_val=val_indicators,y_val=val_target,task=\"classification\", max_iter=1000,metric='micro_f1',estimator_list=[\"lgbm\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_b-cST7lHrGp"
      },
      "outputs": [],
      "source": [
        "df=df.fillna(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hkcaUcrQ8Vj",
        "outputId": "76842c59-4d2b-402d-a86c-5bdeeeed4b84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "55/55 [==============================] - 3s 13ms/step - loss: 1.2818 - accuracy: 0.4642 - precision: 0.4723 - recall: 0.4001 - val_loss: 1.0334 - val_accuracy: 0.4280 - val_precision: 0.5463 - val_recall: 0.1573\n",
            "Epoch 2/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 1.1606 - accuracy: 0.4865 - precision: 0.5066 - recall: 0.4156 - val_loss: 1.0488 - val_accuracy: 0.4680 - val_precision: 0.5239 - val_recall: 0.2627\n",
            "Epoch 3/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 1.0528 - accuracy: 0.5192 - precision: 0.5577 - recall: 0.4511 - val_loss: 1.0677 - val_accuracy: 0.4853 - val_precision: 0.5553 - val_recall: 0.3013\n",
            "Epoch 4/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.9995 - accuracy: 0.5478 - precision: 0.5743 - recall: 0.4602 - val_loss: 1.0765 - val_accuracy: 0.4813 - val_precision: 0.5599 - val_recall: 0.3987\n",
            "Epoch 5/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.9599 - accuracy: 0.5484 - precision: 0.5909 - recall: 0.4596 - val_loss: 1.1310 - val_accuracy: 0.4560 - val_precision: 0.5150 - val_recall: 0.3653\n",
            "Epoch 6/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.9357 - accuracy: 0.5547 - precision: 0.6067 - recall: 0.4671 - val_loss: 1.2119 - val_accuracy: 0.4320 - val_precision: 0.4588 - val_recall: 0.3640\n",
            "Epoch 7/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.9179 - accuracy: 0.5690 - precision: 0.6101 - recall: 0.4648 - val_loss: 1.3172 - val_accuracy: 0.4080 - val_precision: 0.4226 - val_recall: 0.3787\n",
            "Epoch 8/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.9132 - accuracy: 0.5558 - precision: 0.6146 - recall: 0.4682 - val_loss: 1.2317 - val_accuracy: 0.4253 - val_precision: 0.4446 - val_recall: 0.3693\n",
            "Epoch 9/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.8678 - accuracy: 0.5793 - precision: 0.6321 - recall: 0.4808 - val_loss: 1.4359 - val_accuracy: 0.3947 - val_precision: 0.4107 - val_recall: 0.3773\n",
            "Epoch 10/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.8535 - accuracy: 0.5902 - precision: 0.6422 - recall: 0.4848 - val_loss: 1.3474 - val_accuracy: 0.4373 - val_precision: 0.4704 - val_recall: 0.4027\n",
            "Epoch 11/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.8499 - accuracy: 0.5913 - precision: 0.6626 - recall: 0.4969 - val_loss: 1.3668 - val_accuracy: 0.4027 - val_precision: 0.4299 - val_recall: 0.3640\n",
            "Epoch 12/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.8342 - accuracy: 0.6153 - precision: 0.6796 - recall: 0.5003 - val_loss: 1.3193 - val_accuracy: 0.4293 - val_precision: 0.4732 - val_recall: 0.4000\n",
            "Epoch 13/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.8356 - accuracy: 0.6016 - precision: 0.6605 - recall: 0.4923 - val_loss: 1.4340 - val_accuracy: 0.4120 - val_precision: 0.4174 - val_recall: 0.3707\n",
            "Epoch 14/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.8077 - accuracy: 0.6211 - precision: 0.6746 - recall: 0.5197 - val_loss: 1.4090 - val_accuracy: 0.4227 - val_precision: 0.4433 - val_recall: 0.3853\n",
            "Epoch 15/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.8195 - accuracy: 0.6068 - precision: 0.6600 - recall: 0.4888 - val_loss: 1.4453 - val_accuracy: 0.4093 - val_precision: 0.4138 - val_recall: 0.3747\n",
            "Epoch 16/1000\n",
            "55/55 [==============================] - 0s 5ms/step - loss: 0.8070 - accuracy: 0.6062 - precision: 0.6684 - recall: 0.5077 - val_loss: 1.4729 - val_accuracy: 0.4347 - val_precision: 0.4426 - val_recall: 0.4013\n",
            "Epoch 17/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.8099 - accuracy: 0.6142 - precision: 0.6699 - recall: 0.5203 - val_loss: 1.3576 - val_accuracy: 0.4493 - val_precision: 0.4653 - val_recall: 0.4027\n",
            "Epoch 18/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.7932 - accuracy: 0.6239 - precision: 0.6773 - recall: 0.5238 - val_loss: 1.4350 - val_accuracy: 0.4333 - val_precision: 0.4598 - val_recall: 0.3960\n",
            "Epoch 19/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.7871 - accuracy: 0.6342 - precision: 0.6827 - recall: 0.5283 - val_loss: 1.5232 - val_accuracy: 0.4720 - val_precision: 0.4839 - val_recall: 0.4600\n",
            "Epoch 20/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.7875 - accuracy: 0.6348 - precision: 0.6901 - recall: 0.5404 - val_loss: 1.4583 - val_accuracy: 0.4293 - val_precision: 0.4572 - val_recall: 0.3987\n",
            "Epoch 21/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.7969 - accuracy: 0.6262 - precision: 0.6885 - recall: 0.5301 - val_loss: 1.6075 - val_accuracy: 0.4280 - val_precision: 0.4298 - val_recall: 0.4000\n",
            "Epoch 22/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.7711 - accuracy: 0.6463 - precision: 0.6996 - recall: 0.5518 - val_loss: 1.4951 - val_accuracy: 0.4480 - val_precision: 0.4730 - val_recall: 0.4200\n",
            "Epoch 23/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.7788 - accuracy: 0.6440 - precision: 0.6903 - recall: 0.5472 - val_loss: 1.4771 - val_accuracy: 0.4333 - val_precision: 0.4602 - val_recall: 0.4013\n",
            "Epoch 24/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.7795 - accuracy: 0.6211 - precision: 0.6783 - recall: 0.5323 - val_loss: 1.4781 - val_accuracy: 0.4400 - val_precision: 0.4672 - val_recall: 0.4080\n",
            "Epoch 25/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.7795 - accuracy: 0.6314 - precision: 0.6933 - recall: 0.5421 - val_loss: 1.5679 - val_accuracy: 0.4307 - val_precision: 0.4521 - val_recall: 0.4027\n",
            "Epoch 26/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.7590 - accuracy: 0.6440 - precision: 0.7001 - recall: 0.5587 - val_loss: 1.5352 - val_accuracy: 0.4707 - val_precision: 0.4845 - val_recall: 0.4587\n",
            "Epoch 27/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.7706 - accuracy: 0.6445 - precision: 0.6940 - recall: 0.5426 - val_loss: 1.4711 - val_accuracy: 0.4453 - val_precision: 0.4642 - val_recall: 0.4067\n",
            "Epoch 28/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.7696 - accuracy: 0.6457 - precision: 0.7004 - recall: 0.5421 - val_loss: 1.6534 - val_accuracy: 0.4680 - val_precision: 0.4773 - val_recall: 0.4627\n",
            "Epoch 29/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.7561 - accuracy: 0.6411 - precision: 0.6883 - recall: 0.5472 - val_loss: 1.5358 - val_accuracy: 0.4613 - val_precision: 0.4774 - val_recall: 0.4373\n",
            "Epoch 30/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.7703 - accuracy: 0.6445 - precision: 0.6928 - recall: 0.5421 - val_loss: 1.5665 - val_accuracy: 0.4680 - val_precision: 0.4886 - val_recall: 0.4560\n",
            "Epoch 31/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.7433 - accuracy: 0.6537 - precision: 0.7135 - recall: 0.5673 - val_loss: 1.5507 - val_accuracy: 0.4520 - val_precision: 0.4678 - val_recall: 0.4067\n",
            "Epoch 32/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.7501 - accuracy: 0.6440 - precision: 0.7040 - recall: 0.5581 - val_loss: 1.4595 - val_accuracy: 0.4747 - val_precision: 0.5045 - val_recall: 0.4467\n",
            "Epoch 33/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.7555 - accuracy: 0.6474 - precision: 0.7011 - recall: 0.5598 - val_loss: 1.4322 - val_accuracy: 0.4720 - val_precision: 0.4819 - val_recall: 0.3907\n",
            "Epoch 34/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.7578 - accuracy: 0.6451 - precision: 0.6983 - recall: 0.5564 - val_loss: 1.5895 - val_accuracy: 0.3613 - val_precision: 0.3664 - val_recall: 0.3347\n",
            "Epoch 35/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7406 - accuracy: 0.6594 - precision: 0.7153 - recall: 0.5667 - val_loss: 1.4689 - val_accuracy: 0.4507 - val_precision: 0.4754 - val_recall: 0.4120\n",
            "Epoch 36/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.7501 - accuracy: 0.6497 - precision: 0.7031 - recall: 0.5667 - val_loss: 1.6226 - val_accuracy: 0.4320 - val_precision: 0.4545 - val_recall: 0.4200\n",
            "Epoch 37/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7403 - accuracy: 0.6611 - precision: 0.7095 - recall: 0.5718 - val_loss: 1.8511 - val_accuracy: 0.4307 - val_precision: 0.4449 - val_recall: 0.4253\n",
            "Epoch 38/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.7366 - accuracy: 0.6480 - precision: 0.6869 - recall: 0.5501 - val_loss: 1.6826 - val_accuracy: 0.4240 - val_precision: 0.4490 - val_recall: 0.4107\n",
            "Epoch 39/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.7312 - accuracy: 0.6611 - precision: 0.7162 - recall: 0.5793 - val_loss: 1.5423 - val_accuracy: 0.4547 - val_precision: 0.4831 - val_recall: 0.4387\n",
            "Epoch 40/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.7117 - accuracy: 0.6789 - precision: 0.7262 - recall: 0.5799 - val_loss: 1.6213 - val_accuracy: 0.4427 - val_precision: 0.4676 - val_recall: 0.4227\n",
            "Epoch 41/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.7251 - accuracy: 0.6703 - precision: 0.7036 - recall: 0.5747 - val_loss: 1.8027 - val_accuracy: 0.4267 - val_precision: 0.4520 - val_recall: 0.4147\n",
            "Epoch 42/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.7133 - accuracy: 0.6840 - precision: 0.7301 - recall: 0.5993 - val_loss: 1.7878 - val_accuracy: 0.4267 - val_precision: 0.4427 - val_recall: 0.4120\n",
            "Epoch 43/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.7063 - accuracy: 0.6760 - precision: 0.7160 - recall: 0.5930 - val_loss: 1.6655 - val_accuracy: 0.4560 - val_precision: 0.4660 - val_recall: 0.4480\n",
            "Epoch 44/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.7184 - accuracy: 0.6812 - precision: 0.7256 - recall: 0.5993 - val_loss: 1.7062 - val_accuracy: 0.4493 - val_precision: 0.4667 - val_recall: 0.4387\n",
            "Epoch 45/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.7024 - accuracy: 0.6857 - precision: 0.7271 - recall: 0.6085 - val_loss: 1.9436 - val_accuracy: 0.4467 - val_precision: 0.4511 - val_recall: 0.4427\n",
            "Epoch 46/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.6941 - accuracy: 0.6840 - precision: 0.7301 - recall: 0.6131 - val_loss: 1.8068 - val_accuracy: 0.4613 - val_precision: 0.4698 - val_recall: 0.4560\n",
            "Epoch 47/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.7186 - accuracy: 0.6812 - precision: 0.7260 - recall: 0.6005 - val_loss: 1.8080 - val_accuracy: 0.4213 - val_precision: 0.4282 - val_recall: 0.4093\n",
            "Epoch 48/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.7103 - accuracy: 0.6749 - precision: 0.7132 - recall: 0.5993 - val_loss: 1.7065 - val_accuracy: 0.4560 - val_precision: 0.4747 - val_recall: 0.4507\n",
            "Epoch 49/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.7109 - accuracy: 0.6783 - precision: 0.7042 - recall: 0.5913 - val_loss: 1.7289 - val_accuracy: 0.4533 - val_precision: 0.4754 - val_recall: 0.4507\n",
            "Epoch 50/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.6902 - accuracy: 0.6892 - precision: 0.7313 - recall: 0.6108 - val_loss: 1.8005 - val_accuracy: 0.4680 - val_precision: 0.4690 - val_recall: 0.4640\n",
            "Epoch 51/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6949 - accuracy: 0.6857 - precision: 0.7229 - recall: 0.6005 - val_loss: 1.7656 - val_accuracy: 0.4480 - val_precision: 0.4694 - val_recall: 0.4400\n",
            "Epoch 52/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6861 - accuracy: 0.6966 - precision: 0.7256 - recall: 0.6251 - val_loss: 1.9834 - val_accuracy: 0.4120 - val_precision: 0.4199 - val_recall: 0.4053\n",
            "Epoch 53/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6838 - accuracy: 0.6926 - precision: 0.7385 - recall: 0.6274 - val_loss: 2.0014 - val_accuracy: 0.3720 - val_precision: 0.3855 - val_recall: 0.3680\n",
            "Epoch 54/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6844 - accuracy: 0.7023 - precision: 0.7301 - recall: 0.6148 - val_loss: 1.9186 - val_accuracy: 0.4440 - val_precision: 0.4502 - val_recall: 0.4400\n",
            "Epoch 55/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.6800 - accuracy: 0.6789 - precision: 0.7328 - recall: 0.6262 - val_loss: 1.8098 - val_accuracy: 0.4493 - val_precision: 0.4607 - val_recall: 0.4453\n",
            "Epoch 56/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.6917 - accuracy: 0.6835 - precision: 0.7205 - recall: 0.6256 - val_loss: 1.8099 - val_accuracy: 0.4760 - val_precision: 0.4882 - val_recall: 0.4680\n",
            "Epoch 57/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.6894 - accuracy: 0.7035 - precision: 0.7420 - recall: 0.6337 - val_loss: 1.9913 - val_accuracy: 0.4400 - val_precision: 0.4443 - val_recall: 0.4360\n",
            "Epoch 58/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6655 - accuracy: 0.7058 - precision: 0.7428 - recall: 0.6382 - val_loss: 1.9794 - val_accuracy: 0.4467 - val_precision: 0.4494 - val_recall: 0.4440\n",
            "Epoch 59/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6793 - accuracy: 0.6978 - precision: 0.7322 - recall: 0.6308 - val_loss: 1.9496 - val_accuracy: 0.4507 - val_precision: 0.4538 - val_recall: 0.4453\n",
            "Epoch 60/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.6730 - accuracy: 0.7069 - precision: 0.7433 - recall: 0.6382 - val_loss: 2.1243 - val_accuracy: 0.4040 - val_precision: 0.4095 - val_recall: 0.4040\n",
            "Epoch 61/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.6663 - accuracy: 0.7012 - precision: 0.7377 - recall: 0.6457 - val_loss: 1.9149 - val_accuracy: 0.4133 - val_precision: 0.4186 - val_recall: 0.4080\n",
            "Epoch 62/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6740 - accuracy: 0.7023 - precision: 0.7333 - recall: 0.6359 - val_loss: 1.9329 - val_accuracy: 0.4120 - val_precision: 0.4145 - val_recall: 0.4040\n",
            "Epoch 63/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.6296 - accuracy: 0.7178 - precision: 0.7506 - recall: 0.6617 - val_loss: 1.7872 - val_accuracy: 0.4200 - val_precision: 0.4427 - val_recall: 0.4120\n",
            "Epoch 64/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6551 - accuracy: 0.7195 - precision: 0.7549 - recall: 0.6560 - val_loss: 1.8528 - val_accuracy: 0.4400 - val_precision: 0.4499 - val_recall: 0.4373\n",
            "Epoch 65/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6514 - accuracy: 0.7218 - precision: 0.7498 - recall: 0.6571 - val_loss: 2.0580 - val_accuracy: 0.4267 - val_precision: 0.4297 - val_recall: 0.4240\n",
            "Epoch 66/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6578 - accuracy: 0.7041 - precision: 0.7434 - recall: 0.6485 - val_loss: 1.8753 - val_accuracy: 0.4413 - val_precision: 0.4466 - val_recall: 0.4347\n",
            "Epoch 67/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6566 - accuracy: 0.7052 - precision: 0.7493 - recall: 0.6485 - val_loss: 1.9458 - val_accuracy: 0.4653 - val_precision: 0.4707 - val_recall: 0.4613\n",
            "Epoch 68/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.6490 - accuracy: 0.7155 - precision: 0.7411 - recall: 0.6537 - val_loss: 2.1990 - val_accuracy: 0.4253 - val_precision: 0.4282 - val_recall: 0.4253\n",
            "Epoch 69/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.6766 - accuracy: 0.6943 - precision: 0.7299 - recall: 0.6434 - val_loss: 2.1194 - val_accuracy: 0.4213 - val_precision: 0.4253 - val_recall: 0.4173\n",
            "Epoch 70/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.6500 - accuracy: 0.7092 - precision: 0.7376 - recall: 0.6566 - val_loss: 2.0103 - val_accuracy: 0.4387 - val_precision: 0.4450 - val_recall: 0.4373\n",
            "Epoch 71/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6401 - accuracy: 0.7184 - precision: 0.7534 - recall: 0.6629 - val_loss: 2.1983 - val_accuracy: 0.4067 - val_precision: 0.4070 - val_recall: 0.4027\n",
            "Epoch 72/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.6681 - accuracy: 0.7046 - precision: 0.7316 - recall: 0.6302 - val_loss: 2.1371 - val_accuracy: 0.4027 - val_precision: 0.4071 - val_recall: 0.4000\n",
            "Epoch 73/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6550 - accuracy: 0.7247 - precision: 0.7537 - recall: 0.6674 - val_loss: 2.0681 - val_accuracy: 0.3787 - val_precision: 0.3817 - val_recall: 0.3720\n",
            "Epoch 74/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6746 - accuracy: 0.7075 - precision: 0.7449 - recall: 0.6485 - val_loss: 2.0636 - val_accuracy: 0.4333 - val_precision: 0.4354 - val_recall: 0.4267\n",
            "Epoch 75/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6732 - accuracy: 0.7046 - precision: 0.7454 - recall: 0.6468 - val_loss: 1.9346 - val_accuracy: 0.4333 - val_precision: 0.4399 - val_recall: 0.4293\n",
            "Epoch 76/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6507 - accuracy: 0.7155 - precision: 0.7515 - recall: 0.6594 - val_loss: 1.9205 - val_accuracy: 0.4147 - val_precision: 0.4205 - val_recall: 0.4053\n",
            "Epoch 77/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.6338 - accuracy: 0.7109 - precision: 0.7415 - recall: 0.6485 - val_loss: 1.8307 - val_accuracy: 0.4347 - val_precision: 0.4476 - val_recall: 0.4267\n",
            "Epoch 78/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.6299 - accuracy: 0.7178 - precision: 0.7539 - recall: 0.6697 - val_loss: 1.9971 - val_accuracy: 0.4147 - val_precision: 0.4262 - val_recall: 0.4120\n",
            "Epoch 79/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.6510 - accuracy: 0.7098 - precision: 0.7395 - recall: 0.6566 - val_loss: 2.0121 - val_accuracy: 0.3960 - val_precision: 0.4061 - val_recall: 0.3893\n",
            "Epoch 80/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.6332 - accuracy: 0.7258 - precision: 0.7635 - recall: 0.6726 - val_loss: 2.1733 - val_accuracy: 0.4253 - val_precision: 0.4290 - val_recall: 0.4227\n",
            "Epoch 81/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.6334 - accuracy: 0.7127 - precision: 0.7433 - recall: 0.6629 - val_loss: 2.0986 - val_accuracy: 0.4080 - val_precision: 0.4209 - val_recall: 0.4080\n",
            "Epoch 82/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.6140 - accuracy: 0.7252 - precision: 0.7529 - recall: 0.6732 - val_loss: 2.1305 - val_accuracy: 0.4120 - val_precision: 0.4114 - val_recall: 0.4053\n",
            "Epoch 83/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6384 - accuracy: 0.7247 - precision: 0.7546 - recall: 0.6743 - val_loss: 2.1875 - val_accuracy: 0.3960 - val_precision: 0.3970 - val_recall: 0.3907\n",
            "Epoch 84/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.6315 - accuracy: 0.7178 - precision: 0.7502 - recall: 0.6703 - val_loss: 1.8648 - val_accuracy: 0.4267 - val_precision: 0.4311 - val_recall: 0.4213\n",
            "Epoch 85/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.6436 - accuracy: 0.7195 - precision: 0.7440 - recall: 0.6703 - val_loss: 2.0325 - val_accuracy: 0.4213 - val_precision: 0.4233 - val_recall: 0.4160\n",
            "Epoch 86/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.6510 - accuracy: 0.7115 - precision: 0.7429 - recall: 0.6600 - val_loss: 2.2416 - val_accuracy: 0.3547 - val_precision: 0.3611 - val_recall: 0.3520\n",
            "Epoch 87/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.6602 - accuracy: 0.7132 - precision: 0.7497 - recall: 0.6566 - val_loss: 1.8888 - val_accuracy: 0.4067 - val_precision: 0.4153 - val_recall: 0.3987\n",
            "Epoch 88/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.6681 - accuracy: 0.7006 - precision: 0.7388 - recall: 0.6491 - val_loss: 2.1044 - val_accuracy: 0.4347 - val_precision: 0.4351 - val_recall: 0.4293\n",
            "Epoch 89/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6527 - accuracy: 0.7207 - precision: 0.7492 - recall: 0.6600 - val_loss: 2.3162 - val_accuracy: 0.3773 - val_precision: 0.3808 - val_recall: 0.3707\n",
            "Epoch 90/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6353 - accuracy: 0.7069 - precision: 0.7423 - recall: 0.6594 - val_loss: 2.2765 - val_accuracy: 0.4213 - val_precision: 0.4241 - val_recall: 0.4173\n",
            "Epoch 91/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.6328 - accuracy: 0.7184 - precision: 0.7548 - recall: 0.6732 - val_loss: 2.0314 - val_accuracy: 0.4133 - val_precision: 0.4229 - val_recall: 0.4093\n",
            "Epoch 92/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.6499 - accuracy: 0.7127 - precision: 0.7460 - recall: 0.6623 - val_loss: 2.2262 - val_accuracy: 0.4147 - val_precision: 0.4168 - val_recall: 0.4107\n",
            "Epoch 93/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.6309 - accuracy: 0.7304 - precision: 0.7559 - recall: 0.6789 - val_loss: 2.2047 - val_accuracy: 0.4133 - val_precision: 0.4142 - val_recall: 0.4053\n",
            "Epoch 94/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6386 - accuracy: 0.7258 - precision: 0.7545 - recall: 0.6789 - val_loss: 1.8511 - val_accuracy: 0.4427 - val_precision: 0.4543 - val_recall: 0.4373\n",
            "Epoch 95/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.6308 - accuracy: 0.7235 - precision: 0.7615 - recall: 0.6726 - val_loss: 2.2491 - val_accuracy: 0.3893 - val_precision: 0.3973 - val_recall: 0.3867\n",
            "Epoch 96/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6237 - accuracy: 0.7235 - precision: 0.7593 - recall: 0.6754 - val_loss: 2.1546 - val_accuracy: 0.4107 - val_precision: 0.4167 - val_recall: 0.4067\n",
            "Epoch 97/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.6151 - accuracy: 0.7270 - precision: 0.7563 - recall: 0.6875 - val_loss: 2.0747 - val_accuracy: 0.4120 - val_precision: 0.4203 - val_recall: 0.4080\n",
            "Epoch 98/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6164 - accuracy: 0.7298 - precision: 0.7570 - recall: 0.6795 - val_loss: 1.9187 - val_accuracy: 0.4347 - val_precision: 0.4454 - val_recall: 0.4293\n",
            "Epoch 99/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6172 - accuracy: 0.7310 - precision: 0.7587 - recall: 0.6892 - val_loss: 2.1260 - val_accuracy: 0.4107 - val_precision: 0.4217 - val_recall: 0.4093\n",
            "Epoch 100/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6078 - accuracy: 0.7378 - precision: 0.7682 - recall: 0.7001 - val_loss: 2.5261 - val_accuracy: 0.3667 - val_precision: 0.3689 - val_recall: 0.3640\n",
            "Epoch 101/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.6199 - accuracy: 0.7195 - precision: 0.7510 - recall: 0.6749 - val_loss: 2.5317 - val_accuracy: 0.3560 - val_precision: 0.3553 - val_recall: 0.3520\n",
            "Epoch 102/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6206 - accuracy: 0.7252 - precision: 0.7525 - recall: 0.6857 - val_loss: 2.0750 - val_accuracy: 0.4280 - val_precision: 0.4290 - val_recall: 0.4227\n",
            "Epoch 103/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6043 - accuracy: 0.7418 - precision: 0.7740 - recall: 0.6863 - val_loss: 1.9749 - val_accuracy: 0.4280 - val_precision: 0.4319 - val_recall: 0.4227\n",
            "Epoch 104/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5998 - accuracy: 0.7516 - precision: 0.7760 - recall: 0.7041 - val_loss: 2.1097 - val_accuracy: 0.3693 - val_precision: 0.3776 - val_recall: 0.3600\n",
            "Epoch 105/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5981 - accuracy: 0.7436 - precision: 0.7723 - recall: 0.7029 - val_loss: 2.2659 - val_accuracy: 0.3640 - val_precision: 0.3719 - val_recall: 0.3640\n",
            "Epoch 106/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.6066 - accuracy: 0.7338 - precision: 0.7613 - recall: 0.6920 - val_loss: 2.2024 - val_accuracy: 0.3987 - val_precision: 0.4030 - val_recall: 0.3933\n",
            "Epoch 107/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6070 - accuracy: 0.7315 - precision: 0.7614 - recall: 0.6795 - val_loss: 2.2405 - val_accuracy: 0.4200 - val_precision: 0.4218 - val_recall: 0.4173\n",
            "Epoch 108/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6177 - accuracy: 0.7298 - precision: 0.7604 - recall: 0.6886 - val_loss: 2.0910 - val_accuracy: 0.4107 - val_precision: 0.4161 - val_recall: 0.4067\n",
            "Epoch 109/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6209 - accuracy: 0.7333 - precision: 0.7574 - recall: 0.6880 - val_loss: 2.1328 - val_accuracy: 0.4040 - val_precision: 0.4082 - val_recall: 0.4000\n",
            "Epoch 110/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6140 - accuracy: 0.7401 - precision: 0.7692 - recall: 0.6926 - val_loss: 2.0443 - val_accuracy: 0.4040 - val_precision: 0.4074 - val_recall: 0.3960\n",
            "Epoch 111/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5992 - accuracy: 0.7373 - precision: 0.7690 - recall: 0.6938 - val_loss: 2.2505 - val_accuracy: 0.3720 - val_precision: 0.3779 - val_recall: 0.3693\n",
            "Epoch 112/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5947 - accuracy: 0.7407 - precision: 0.7712 - recall: 0.7023 - val_loss: 2.2210 - val_accuracy: 0.3707 - val_precision: 0.3793 - val_recall: 0.3667\n",
            "Epoch 113/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6117 - accuracy: 0.7338 - precision: 0.7541 - recall: 0.6915 - val_loss: 2.2942 - val_accuracy: 0.3947 - val_precision: 0.3978 - val_recall: 0.3920\n",
            "Epoch 114/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.6182 - accuracy: 0.7367 - precision: 0.7601 - recall: 0.6966 - val_loss: 2.4018 - val_accuracy: 0.3493 - val_precision: 0.3533 - val_recall: 0.3453\n",
            "Epoch 115/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.6173 - accuracy: 0.7355 - precision: 0.7640 - recall: 0.6932 - val_loss: 2.2768 - val_accuracy: 0.3573 - val_precision: 0.3601 - val_recall: 0.3533\n",
            "Epoch 116/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6052 - accuracy: 0.7355 - precision: 0.7628 - recall: 0.6886 - val_loss: 2.1391 - val_accuracy: 0.3840 - val_precision: 0.3920 - val_recall: 0.3800\n",
            "Epoch 117/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5820 - accuracy: 0.7533 - precision: 0.7743 - recall: 0.7029 - val_loss: 2.0891 - val_accuracy: 0.4253 - val_precision: 0.4317 - val_recall: 0.4213\n",
            "Epoch 118/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5864 - accuracy: 0.7493 - precision: 0.7789 - recall: 0.7058 - val_loss: 2.4091 - val_accuracy: 0.4000 - val_precision: 0.4000 - val_recall: 0.3920\n",
            "Epoch 119/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.6059 - accuracy: 0.7390 - precision: 0.7661 - recall: 0.6995 - val_loss: 2.5048 - val_accuracy: 0.3493 - val_precision: 0.3516 - val_recall: 0.3427\n",
            "Epoch 120/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6325 - accuracy: 0.7281 - precision: 0.7622 - recall: 0.6863 - val_loss: 2.3965 - val_accuracy: 0.3507 - val_precision: 0.3559 - val_recall: 0.3440\n",
            "Epoch 121/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6031 - accuracy: 0.7459 - precision: 0.7701 - recall: 0.7035 - val_loss: 2.1580 - val_accuracy: 0.3720 - val_precision: 0.3748 - val_recall: 0.3573\n",
            "Epoch 122/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.6085 - accuracy: 0.7373 - precision: 0.7669 - recall: 0.6932 - val_loss: 2.2960 - val_accuracy: 0.3613 - val_precision: 0.3673 - val_recall: 0.3600\n",
            "Epoch 123/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6170 - accuracy: 0.7436 - precision: 0.7715 - recall: 0.6920 - val_loss: 2.4064 - val_accuracy: 0.3667 - val_precision: 0.3731 - val_recall: 0.3627\n",
            "Epoch 124/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6187 - accuracy: 0.7224 - precision: 0.7490 - recall: 0.6714 - val_loss: 2.2104 - val_accuracy: 0.3907 - val_precision: 0.3997 - val_recall: 0.3853\n",
            "Epoch 125/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6210 - accuracy: 0.7310 - precision: 0.7570 - recall: 0.6829 - val_loss: 1.9878 - val_accuracy: 0.3987 - val_precision: 0.4123 - val_recall: 0.3947\n",
            "Epoch 126/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5903 - accuracy: 0.7487 - precision: 0.7738 - recall: 0.7069 - val_loss: 1.9915 - val_accuracy: 0.4160 - val_precision: 0.4226 - val_recall: 0.4040\n",
            "Epoch 127/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6164 - accuracy: 0.7378 - precision: 0.7650 - recall: 0.6949 - val_loss: 1.9805 - val_accuracy: 0.4187 - val_precision: 0.4274 - val_recall: 0.4120\n",
            "Epoch 128/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6024 - accuracy: 0.7436 - precision: 0.7731 - recall: 0.6943 - val_loss: 2.1651 - val_accuracy: 0.4133 - val_precision: 0.4169 - val_recall: 0.4080\n",
            "Epoch 129/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.5899 - accuracy: 0.7373 - precision: 0.7689 - recall: 0.6932 - val_loss: 2.1216 - val_accuracy: 0.4053 - val_precision: 0.4163 - val_recall: 0.4013\n",
            "Epoch 130/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.5928 - accuracy: 0.7556 - precision: 0.7811 - recall: 0.7109 - val_loss: 1.9361 - val_accuracy: 0.3693 - val_precision: 0.3902 - val_recall: 0.3627\n",
            "Epoch 131/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5739 - accuracy: 0.7493 - precision: 0.7732 - recall: 0.7121 - val_loss: 2.1038 - val_accuracy: 0.3747 - val_precision: 0.3828 - val_recall: 0.3680\n",
            "Epoch 132/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6049 - accuracy: 0.7310 - precision: 0.7641 - recall: 0.6989 - val_loss: 2.0949 - val_accuracy: 0.3733 - val_precision: 0.3786 - val_recall: 0.3640\n",
            "Epoch 133/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5979 - accuracy: 0.7390 - precision: 0.7667 - recall: 0.6961 - val_loss: 2.2164 - val_accuracy: 0.3507 - val_precision: 0.3638 - val_recall: 0.3453\n",
            "Epoch 134/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5725 - accuracy: 0.7527 - precision: 0.7791 - recall: 0.7086 - val_loss: 2.1913 - val_accuracy: 0.3773 - val_precision: 0.3871 - val_recall: 0.3747\n",
            "Epoch 135/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5903 - accuracy: 0.7624 - precision: 0.7827 - recall: 0.7235 - val_loss: 2.2735 - val_accuracy: 0.3840 - val_precision: 0.3864 - val_recall: 0.3787\n",
            "Epoch 136/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5697 - accuracy: 0.7607 - precision: 0.7789 - recall: 0.7138 - val_loss: 2.3596 - val_accuracy: 0.3973 - val_precision: 0.3997 - val_recall: 0.3907\n",
            "Epoch 137/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5614 - accuracy: 0.7550 - precision: 0.7801 - recall: 0.7149 - val_loss: 2.4211 - val_accuracy: 0.4053 - val_precision: 0.4070 - val_recall: 0.4027\n",
            "Epoch 138/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6000 - accuracy: 0.7418 - precision: 0.7684 - recall: 0.7046 - val_loss: 2.2741 - val_accuracy: 0.3600 - val_precision: 0.3702 - val_recall: 0.3573\n",
            "Epoch 139/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5942 - accuracy: 0.7527 - precision: 0.7779 - recall: 0.7058 - val_loss: 1.9597 - val_accuracy: 0.4147 - val_precision: 0.4242 - val_recall: 0.4067\n",
            "Epoch 140/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5684 - accuracy: 0.7619 - precision: 0.7839 - recall: 0.7207 - val_loss: 2.2548 - val_accuracy: 0.3720 - val_precision: 0.3743 - val_recall: 0.3613\n",
            "Epoch 141/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5802 - accuracy: 0.7447 - precision: 0.7625 - recall: 0.7092 - val_loss: 2.7344 - val_accuracy: 0.3427 - val_precision: 0.3423 - val_recall: 0.3387\n",
            "Epoch 142/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5831 - accuracy: 0.7464 - precision: 0.7630 - recall: 0.7149 - val_loss: 2.2988 - val_accuracy: 0.3733 - val_precision: 0.3827 - val_recall: 0.3720\n",
            "Epoch 143/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5981 - accuracy: 0.7436 - precision: 0.7729 - recall: 0.7092 - val_loss: 2.3805 - val_accuracy: 0.3760 - val_precision: 0.3806 - val_recall: 0.3720\n",
            "Epoch 144/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5880 - accuracy: 0.7424 - precision: 0.7710 - recall: 0.7035 - val_loss: 2.3052 - val_accuracy: 0.3893 - val_precision: 0.3970 - val_recall: 0.3880\n",
            "Epoch 145/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5898 - accuracy: 0.7487 - precision: 0.7748 - recall: 0.7167 - val_loss: 2.3479 - val_accuracy: 0.3840 - val_precision: 0.3893 - val_recall: 0.3800\n",
            "Epoch 146/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5704 - accuracy: 0.7647 - precision: 0.7915 - recall: 0.7281 - val_loss: 2.1896 - val_accuracy: 0.3880 - val_precision: 0.3937 - val_recall: 0.3827\n",
            "Epoch 147/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5822 - accuracy: 0.7413 - precision: 0.7643 - recall: 0.6943 - val_loss: 2.2789 - val_accuracy: 0.3947 - val_precision: 0.3970 - val_recall: 0.3880\n",
            "Epoch 148/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5732 - accuracy: 0.7516 - precision: 0.7704 - recall: 0.7069 - val_loss: 2.5354 - val_accuracy: 0.3360 - val_precision: 0.3351 - val_recall: 0.3293\n",
            "Epoch 149/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5682 - accuracy: 0.7619 - precision: 0.7866 - recall: 0.7235 - val_loss: 2.5674 - val_accuracy: 0.3467 - val_precision: 0.3460 - val_recall: 0.3400\n",
            "Epoch 150/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5665 - accuracy: 0.7687 - precision: 0.7886 - recall: 0.7390 - val_loss: 2.4028 - val_accuracy: 0.3840 - val_precision: 0.3878 - val_recall: 0.3827\n",
            "Epoch 151/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5568 - accuracy: 0.7584 - precision: 0.7899 - recall: 0.7275 - val_loss: 2.2351 - val_accuracy: 0.4013 - val_precision: 0.4046 - val_recall: 0.3987\n",
            "Epoch 152/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5572 - accuracy: 0.7693 - precision: 0.7925 - recall: 0.7344 - val_loss: 2.4144 - val_accuracy: 0.3853 - val_precision: 0.3891 - val_recall: 0.3813\n",
            "Epoch 153/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5439 - accuracy: 0.7750 - precision: 0.7974 - recall: 0.7413 - val_loss: 2.5531 - val_accuracy: 0.3640 - val_precision: 0.3729 - val_recall: 0.3600\n",
            "Epoch 154/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5545 - accuracy: 0.7670 - precision: 0.7905 - recall: 0.7344 - val_loss: 2.5429 - val_accuracy: 0.3533 - val_precision: 0.3529 - val_recall: 0.3453\n",
            "Epoch 155/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5613 - accuracy: 0.7510 - precision: 0.7759 - recall: 0.7195 - val_loss: 2.2636 - val_accuracy: 0.3893 - val_precision: 0.3923 - val_recall: 0.3813\n",
            "Epoch 156/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5743 - accuracy: 0.7613 - precision: 0.7887 - recall: 0.7287 - val_loss: 2.3647 - val_accuracy: 0.3707 - val_precision: 0.3760 - val_recall: 0.3680\n",
            "Epoch 157/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5451 - accuracy: 0.7647 - precision: 0.7884 - recall: 0.7252 - val_loss: 2.2294 - val_accuracy: 0.3693 - val_precision: 0.3764 - val_recall: 0.3653\n",
            "Epoch 158/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.5854 - accuracy: 0.7481 - precision: 0.7706 - recall: 0.7058 - val_loss: 2.2237 - val_accuracy: 0.3600 - val_precision: 0.3689 - val_recall: 0.3547\n",
            "Epoch 159/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.5669 - accuracy: 0.7539 - precision: 0.7745 - recall: 0.7138 - val_loss: 2.2972 - val_accuracy: 0.3667 - val_precision: 0.3769 - val_recall: 0.3653\n",
            "Epoch 160/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.5572 - accuracy: 0.7544 - precision: 0.7819 - recall: 0.7201 - val_loss: 2.4290 - val_accuracy: 0.3680 - val_precision: 0.3730 - val_recall: 0.3640\n",
            "Epoch 161/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.5581 - accuracy: 0.7665 - precision: 0.7886 - recall: 0.7281 - val_loss: 2.4585 - val_accuracy: 0.3773 - val_precision: 0.3797 - val_recall: 0.3747\n",
            "Epoch 162/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5544 - accuracy: 0.7602 - precision: 0.7901 - recall: 0.7304 - val_loss: 2.4311 - val_accuracy: 0.3760 - val_precision: 0.3801 - val_recall: 0.3760\n",
            "Epoch 163/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5611 - accuracy: 0.7562 - precision: 0.7839 - recall: 0.7207 - val_loss: 2.4718 - val_accuracy: 0.3600 - val_precision: 0.3655 - val_recall: 0.3587\n",
            "Epoch 164/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5698 - accuracy: 0.7516 - precision: 0.7733 - recall: 0.7207 - val_loss: 2.2311 - val_accuracy: 0.4347 - val_precision: 0.4408 - val_recall: 0.4320\n",
            "Epoch 165/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5951 - accuracy: 0.7390 - precision: 0.7674 - recall: 0.6892 - val_loss: 2.2969 - val_accuracy: 0.3813 - val_precision: 0.3944 - val_recall: 0.3787\n",
            "Epoch 166/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5955 - accuracy: 0.7493 - precision: 0.7726 - recall: 0.7081 - val_loss: 2.5542 - val_accuracy: 0.3573 - val_precision: 0.3578 - val_recall: 0.3507\n",
            "Epoch 167/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5491 - accuracy: 0.7728 - precision: 0.8020 - recall: 0.7373 - val_loss: 2.6093 - val_accuracy: 0.3760 - val_precision: 0.3777 - val_recall: 0.3747\n",
            "Epoch 168/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5816 - accuracy: 0.7562 - precision: 0.7833 - recall: 0.7241 - val_loss: 2.2560 - val_accuracy: 0.3987 - val_precision: 0.3970 - val_recall: 0.3853\n",
            "Epoch 169/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5868 - accuracy: 0.7401 - precision: 0.7742 - recall: 0.7046 - val_loss: 2.1198 - val_accuracy: 0.3907 - val_precision: 0.3953 - val_recall: 0.3800\n",
            "Epoch 170/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.6105 - accuracy: 0.7378 - precision: 0.7610 - recall: 0.6943 - val_loss: 2.0549 - val_accuracy: 0.3813 - val_precision: 0.3966 - val_recall: 0.3680\n",
            "Epoch 171/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.6218 - accuracy: 0.7327 - precision: 0.7589 - recall: 0.6938 - val_loss: 2.1803 - val_accuracy: 0.3533 - val_precision: 0.3591 - val_recall: 0.3467\n",
            "Epoch 172/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5868 - accuracy: 0.7459 - precision: 0.7732 - recall: 0.7046 - val_loss: 2.2427 - val_accuracy: 0.4013 - val_precision: 0.4014 - val_recall: 0.3960\n",
            "Epoch 173/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5678 - accuracy: 0.7573 - precision: 0.7857 - recall: 0.7155 - val_loss: 2.3662 - val_accuracy: 0.3853 - val_precision: 0.3865 - val_recall: 0.3813\n",
            "Epoch 174/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5747 - accuracy: 0.7579 - precision: 0.7829 - recall: 0.7247 - val_loss: 2.6109 - val_accuracy: 0.3773 - val_precision: 0.3780 - val_recall: 0.3760\n",
            "Epoch 175/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5800 - accuracy: 0.7493 - precision: 0.7690 - recall: 0.7109 - val_loss: 2.4825 - val_accuracy: 0.3787 - val_precision: 0.3764 - val_recall: 0.3693\n",
            "Epoch 176/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5820 - accuracy: 0.7642 - precision: 0.7907 - recall: 0.7264 - val_loss: 2.2205 - val_accuracy: 0.4067 - val_precision: 0.4093 - val_recall: 0.4000\n",
            "Epoch 177/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5566 - accuracy: 0.7699 - precision: 0.7900 - recall: 0.7298 - val_loss: 2.2835 - val_accuracy: 0.3947 - val_precision: 0.4005 - val_recall: 0.3920\n",
            "Epoch 178/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5459 - accuracy: 0.7619 - precision: 0.7907 - recall: 0.7287 - val_loss: 2.0894 - val_accuracy: 0.4053 - val_precision: 0.4090 - val_recall: 0.3987\n",
            "Epoch 179/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5641 - accuracy: 0.7676 - precision: 0.7973 - recall: 0.7315 - val_loss: 2.4267 - val_accuracy: 0.4213 - val_precision: 0.4243 - val_recall: 0.4187\n",
            "Epoch 180/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5706 - accuracy: 0.7539 - precision: 0.7783 - recall: 0.7155 - val_loss: 2.1050 - val_accuracy: 0.3933 - val_precision: 0.4151 - val_recall: 0.3880\n",
            "Epoch 181/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5795 - accuracy: 0.7573 - precision: 0.7772 - recall: 0.7149 - val_loss: 2.2567 - val_accuracy: 0.3853 - val_precision: 0.3937 - val_recall: 0.3827\n",
            "Epoch 182/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5693 - accuracy: 0.7573 - precision: 0.7815 - recall: 0.7247 - val_loss: 2.3657 - val_accuracy: 0.3773 - val_precision: 0.3822 - val_recall: 0.3720\n",
            "Epoch 183/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5563 - accuracy: 0.7750 - precision: 0.7941 - recall: 0.7396 - val_loss: 2.4339 - val_accuracy: 0.3960 - val_precision: 0.4000 - val_recall: 0.3947\n",
            "Epoch 184/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5627 - accuracy: 0.7682 - precision: 0.7934 - recall: 0.7298 - val_loss: 2.4333 - val_accuracy: 0.3867 - val_precision: 0.3844 - val_recall: 0.3747\n",
            "Epoch 185/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5317 - accuracy: 0.7665 - precision: 0.7893 - recall: 0.7333 - val_loss: 2.3755 - val_accuracy: 0.3680 - val_precision: 0.3712 - val_recall: 0.3573\n",
            "Epoch 186/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5347 - accuracy: 0.7796 - precision: 0.8027 - recall: 0.7499 - val_loss: 2.5110 - val_accuracy: 0.3707 - val_precision: 0.3733 - val_recall: 0.3653\n",
            "Epoch 187/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5523 - accuracy: 0.7653 - precision: 0.7929 - recall: 0.7407 - val_loss: 2.2230 - val_accuracy: 0.4053 - val_precision: 0.4150 - val_recall: 0.3973\n",
            "Epoch 188/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.5739 - accuracy: 0.7544 - precision: 0.7787 - recall: 0.7230 - val_loss: 2.2611 - val_accuracy: 0.3840 - val_precision: 0.3893 - val_recall: 0.3800\n",
            "Epoch 189/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.5793 - accuracy: 0.7476 - precision: 0.7790 - recall: 0.7064 - val_loss: 2.3791 - val_accuracy: 0.3800 - val_precision: 0.3828 - val_recall: 0.3747\n",
            "Epoch 190/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.5681 - accuracy: 0.7602 - precision: 0.7757 - recall: 0.7287 - val_loss: 2.2061 - val_accuracy: 0.3960 - val_precision: 0.4033 - val_recall: 0.3893\n",
            "Epoch 191/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.5254 - accuracy: 0.7882 - precision: 0.8133 - recall: 0.7504 - val_loss: 2.3204 - val_accuracy: 0.4173 - val_precision: 0.4179 - val_recall: 0.4107\n",
            "Epoch 192/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5620 - accuracy: 0.7653 - precision: 0.7851 - recall: 0.7384 - val_loss: 2.4722 - val_accuracy: 0.3653 - val_precision: 0.3717 - val_recall: 0.3613\n",
            "Epoch 193/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5595 - accuracy: 0.7567 - precision: 0.7761 - recall: 0.7224 - val_loss: 2.4409 - val_accuracy: 0.3907 - val_precision: 0.3906 - val_recall: 0.3760\n",
            "Epoch 194/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5517 - accuracy: 0.7710 - precision: 0.7901 - recall: 0.7367 - val_loss: 2.2699 - val_accuracy: 0.4160 - val_precision: 0.4228 - val_recall: 0.4013\n",
            "Epoch 195/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5631 - accuracy: 0.7716 - precision: 0.7903 - recall: 0.7378 - val_loss: 2.3987 - val_accuracy: 0.3747 - val_precision: 0.3791 - val_recall: 0.3680\n",
            "Epoch 196/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5488 - accuracy: 0.7722 - precision: 0.7922 - recall: 0.7333 - val_loss: 2.2931 - val_accuracy: 0.3747 - val_precision: 0.3825 - val_recall: 0.3667\n",
            "Epoch 197/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5545 - accuracy: 0.7779 - precision: 0.7972 - recall: 0.7378 - val_loss: 2.5382 - val_accuracy: 0.3640 - val_precision: 0.3676 - val_recall: 0.3573\n",
            "Epoch 198/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5498 - accuracy: 0.7722 - precision: 0.7975 - recall: 0.7373 - val_loss: 2.4773 - val_accuracy: 0.3760 - val_precision: 0.3796 - val_recall: 0.3720\n",
            "Epoch 199/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5438 - accuracy: 0.7773 - precision: 0.8093 - recall: 0.7436 - val_loss: 2.5237 - val_accuracy: 0.3747 - val_precision: 0.3769 - val_recall: 0.3693\n",
            "Epoch 200/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5350 - accuracy: 0.7825 - precision: 0.8079 - recall: 0.7487 - val_loss: 2.3736 - val_accuracy: 0.4013 - val_precision: 0.4041 - val_recall: 0.3987\n",
            "Epoch 201/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5646 - accuracy: 0.7619 - precision: 0.7844 - recall: 0.7207 - val_loss: 2.3794 - val_accuracy: 0.3960 - val_precision: 0.3965 - val_recall: 0.3907\n",
            "Epoch 202/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5360 - accuracy: 0.7739 - precision: 0.8009 - recall: 0.7459 - val_loss: 2.2474 - val_accuracy: 0.4147 - val_precision: 0.4246 - val_recall: 0.4053\n",
            "Epoch 203/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5768 - accuracy: 0.7510 - precision: 0.7769 - recall: 0.7195 - val_loss: 2.2388 - val_accuracy: 0.3773 - val_precision: 0.3812 - val_recall: 0.3680\n",
            "Epoch 204/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5549 - accuracy: 0.7613 - precision: 0.7829 - recall: 0.7224 - val_loss: 2.0555 - val_accuracy: 0.4067 - val_precision: 0.4148 - val_recall: 0.4027\n",
            "Epoch 205/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5509 - accuracy: 0.7659 - precision: 0.7889 - recall: 0.7338 - val_loss: 2.3088 - val_accuracy: 0.3920 - val_precision: 0.3954 - val_recall: 0.3880\n",
            "Epoch 206/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5448 - accuracy: 0.7745 - precision: 0.7995 - recall: 0.7396 - val_loss: 2.4094 - val_accuracy: 0.3880 - val_precision: 0.3859 - val_recall: 0.3787\n",
            "Epoch 207/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5847 - accuracy: 0.7642 - precision: 0.7946 - recall: 0.7218 - val_loss: 2.4891 - val_accuracy: 0.3693 - val_precision: 0.3724 - val_recall: 0.3640\n",
            "Epoch 208/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.6045 - accuracy: 0.7436 - precision: 0.7618 - recall: 0.7046 - val_loss: 2.4601 - val_accuracy: 0.3693 - val_precision: 0.3697 - val_recall: 0.3573\n",
            "Epoch 209/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5601 - accuracy: 0.7687 - precision: 0.7938 - recall: 0.7361 - val_loss: 2.4510 - val_accuracy: 0.3747 - val_precision: 0.3740 - val_recall: 0.3680\n",
            "Epoch 210/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5682 - accuracy: 0.7584 - precision: 0.7846 - recall: 0.7172 - val_loss: 2.2132 - val_accuracy: 0.3880 - val_precision: 0.3904 - val_recall: 0.3800\n",
            "Epoch 211/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5791 - accuracy: 0.7602 - precision: 0.7888 - recall: 0.7270 - val_loss: 2.3411 - val_accuracy: 0.3840 - val_precision: 0.3865 - val_recall: 0.3813\n",
            "Epoch 212/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5574 - accuracy: 0.7676 - precision: 0.7866 - recall: 0.7344 - val_loss: 2.1530 - val_accuracy: 0.3947 - val_precision: 0.3959 - val_recall: 0.3880\n",
            "Epoch 213/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5434 - accuracy: 0.7790 - precision: 0.8012 - recall: 0.7407 - val_loss: 2.3376 - val_accuracy: 0.3907 - val_precision: 0.3915 - val_recall: 0.3827\n",
            "Epoch 214/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5366 - accuracy: 0.7745 - precision: 0.7977 - recall: 0.7447 - val_loss: 2.3024 - val_accuracy: 0.3933 - val_precision: 0.3953 - val_recall: 0.3853\n",
            "Epoch 215/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5481 - accuracy: 0.7728 - precision: 0.7938 - recall: 0.7338 - val_loss: 2.4778 - val_accuracy: 0.3720 - val_precision: 0.3759 - val_recall: 0.3653\n",
            "Epoch 216/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5355 - accuracy: 0.7728 - precision: 0.7970 - recall: 0.7396 - val_loss: 2.7234 - val_accuracy: 0.3520 - val_precision: 0.3528 - val_recall: 0.3467\n",
            "Epoch 217/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5496 - accuracy: 0.7687 - precision: 0.7958 - recall: 0.7384 - val_loss: 2.6273 - val_accuracy: 0.3613 - val_precision: 0.3633 - val_recall: 0.3560\n",
            "Epoch 218/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.5314 - accuracy: 0.7739 - precision: 0.7955 - recall: 0.7436 - val_loss: 2.5004 - val_accuracy: 0.3733 - val_precision: 0.3701 - val_recall: 0.3627\n",
            "Epoch 219/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.5438 - accuracy: 0.7745 - precision: 0.7928 - recall: 0.7361 - val_loss: 2.4235 - val_accuracy: 0.3867 - val_precision: 0.3926 - val_recall: 0.3827\n",
            "Epoch 220/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.5469 - accuracy: 0.7693 - precision: 0.7972 - recall: 0.7378 - val_loss: 2.3391 - val_accuracy: 0.3787 - val_precision: 0.3832 - val_recall: 0.3720\n",
            "Epoch 221/1000\n",
            "55/55 [==============================] - 1s 13ms/step - loss: 0.5698 - accuracy: 0.7590 - precision: 0.7843 - recall: 0.7287 - val_loss: 2.3766 - val_accuracy: 0.3707 - val_precision: 0.3681 - val_recall: 0.3573\n",
            "Epoch 222/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5572 - accuracy: 0.7579 - precision: 0.7791 - recall: 0.7270 - val_loss: 2.3808 - val_accuracy: 0.3520 - val_precision: 0.3499 - val_recall: 0.3373\n",
            "Epoch 223/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5779 - accuracy: 0.7584 - precision: 0.7795 - recall: 0.7184 - val_loss: 2.5706 - val_accuracy: 0.3533 - val_precision: 0.3549 - val_recall: 0.3440\n",
            "Epoch 224/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5713 - accuracy: 0.7493 - precision: 0.7794 - recall: 0.7218 - val_loss: 2.6079 - val_accuracy: 0.3653 - val_precision: 0.3639 - val_recall: 0.3547\n",
            "Epoch 225/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5737 - accuracy: 0.7562 - precision: 0.7758 - recall: 0.7189 - val_loss: 2.3907 - val_accuracy: 0.3973 - val_precision: 0.3995 - val_recall: 0.3893\n",
            "Epoch 226/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5656 - accuracy: 0.7521 - precision: 0.7796 - recall: 0.7086 - val_loss: 2.3645 - val_accuracy: 0.3987 - val_precision: 0.4025 - val_recall: 0.3907\n",
            "Epoch 227/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5632 - accuracy: 0.7573 - precision: 0.7842 - recall: 0.7258 - val_loss: 2.4510 - val_accuracy: 0.4027 - val_precision: 0.4113 - val_recall: 0.3987\n",
            "Epoch 228/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5514 - accuracy: 0.7682 - precision: 0.7949 - recall: 0.7344 - val_loss: 2.3041 - val_accuracy: 0.3973 - val_precision: 0.4063 - val_recall: 0.3933\n",
            "Epoch 229/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5846 - accuracy: 0.7556 - precision: 0.7816 - recall: 0.7189 - val_loss: 2.3184 - val_accuracy: 0.3920 - val_precision: 0.3967 - val_recall: 0.3813\n",
            "Epoch 230/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5338 - accuracy: 0.7802 - precision: 0.8036 - recall: 0.7401 - val_loss: 2.6343 - val_accuracy: 0.3947 - val_precision: 0.3986 - val_recall: 0.3880\n",
            "Epoch 231/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5606 - accuracy: 0.7539 - precision: 0.7776 - recall: 0.7224 - val_loss: 2.3577 - val_accuracy: 0.4000 - val_precision: 0.4030 - val_recall: 0.3880\n",
            "Epoch 232/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5525 - accuracy: 0.7762 - precision: 0.8005 - recall: 0.7418 - val_loss: 2.5053 - val_accuracy: 0.4013 - val_precision: 0.4030 - val_recall: 0.3960\n",
            "Epoch 233/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5488 - accuracy: 0.7693 - precision: 0.7940 - recall: 0.7367 - val_loss: 2.5083 - val_accuracy: 0.3853 - val_precision: 0.3845 - val_recall: 0.3773\n",
            "Epoch 234/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5414 - accuracy: 0.7613 - precision: 0.7904 - recall: 0.7275 - val_loss: 2.3978 - val_accuracy: 0.3827 - val_precision: 0.3885 - val_recall: 0.3693\n",
            "Epoch 235/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5212 - accuracy: 0.7853 - precision: 0.8065 - recall: 0.7516 - val_loss: 2.7241 - val_accuracy: 0.3627 - val_precision: 0.3633 - val_recall: 0.3507\n",
            "Epoch 236/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5483 - accuracy: 0.7693 - precision: 0.7908 - recall: 0.7401 - val_loss: 2.8417 - val_accuracy: 0.3613 - val_precision: 0.3653 - val_recall: 0.3560\n",
            "Epoch 237/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5390 - accuracy: 0.7773 - precision: 0.7977 - recall: 0.7470 - val_loss: 2.6935 - val_accuracy: 0.3640 - val_precision: 0.3676 - val_recall: 0.3573\n",
            "Epoch 238/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5309 - accuracy: 0.7785 - precision: 0.8027 - recall: 0.7521 - val_loss: 2.3939 - val_accuracy: 0.3893 - val_precision: 0.3936 - val_recall: 0.3800\n",
            "Epoch 239/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5477 - accuracy: 0.7710 - precision: 0.7977 - recall: 0.7424 - val_loss: 2.7575 - val_accuracy: 0.3600 - val_precision: 0.3633 - val_recall: 0.3560\n",
            "Epoch 240/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5206 - accuracy: 0.7808 - precision: 0.8060 - recall: 0.7562 - val_loss: 2.5272 - val_accuracy: 0.3893 - val_precision: 0.3899 - val_recall: 0.3800\n",
            "Epoch 241/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5309 - accuracy: 0.7802 - precision: 0.7975 - recall: 0.7527 - val_loss: 2.4265 - val_accuracy: 0.3947 - val_precision: 0.3981 - val_recall: 0.3827\n",
            "Epoch 242/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5433 - accuracy: 0.7785 - precision: 0.7955 - recall: 0.7504 - val_loss: 2.7388 - val_accuracy: 0.3747 - val_precision: 0.3769 - val_recall: 0.3693\n",
            "Epoch 243/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5370 - accuracy: 0.7796 - precision: 0.7998 - recall: 0.7499 - val_loss: 2.6234 - val_accuracy: 0.3773 - val_precision: 0.3794 - val_recall: 0.3733\n",
            "Epoch 244/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5257 - accuracy: 0.7756 - precision: 0.7996 - recall: 0.7424 - val_loss: 2.9071 - val_accuracy: 0.3653 - val_precision: 0.3652 - val_recall: 0.3613\n",
            "Epoch 245/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5141 - accuracy: 0.7945 - precision: 0.8130 - recall: 0.7590 - val_loss: 2.8248 - val_accuracy: 0.3720 - val_precision: 0.3720 - val_recall: 0.3680\n",
            "Epoch 246/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5181 - accuracy: 0.7894 - precision: 0.8102 - recall: 0.7573 - val_loss: 2.6390 - val_accuracy: 0.3893 - val_precision: 0.3878 - val_recall: 0.3827\n",
            "Epoch 247/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5063 - accuracy: 0.7853 - precision: 0.8089 - recall: 0.7510 - val_loss: 2.6775 - val_accuracy: 0.3933 - val_precision: 0.3957 - val_recall: 0.3920\n",
            "Epoch 248/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.5272 - accuracy: 0.7768 - precision: 0.8050 - recall: 0.7516 - val_loss: 2.6794 - val_accuracy: 0.3867 - val_precision: 0.3905 - val_recall: 0.3853\n",
            "Epoch 249/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.5425 - accuracy: 0.7768 - precision: 0.7932 - recall: 0.7464 - val_loss: 2.7007 - val_accuracy: 0.3813 - val_precision: 0.3787 - val_recall: 0.3747\n",
            "Epoch 250/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.5473 - accuracy: 0.7773 - precision: 0.8020 - recall: 0.7373 - val_loss: 2.6158 - val_accuracy: 0.3747 - val_precision: 0.3765 - val_recall: 0.3680\n",
            "Epoch 251/1000\n",
            "55/55 [==============================] - 1s 13ms/step - loss: 0.5666 - accuracy: 0.7647 - precision: 0.7866 - recall: 0.7281 - val_loss: 2.5636 - val_accuracy: 0.3867 - val_precision: 0.3878 - val_recall: 0.3800\n",
            "Epoch 252/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.5273 - accuracy: 0.7876 - precision: 0.8111 - recall: 0.7499 - val_loss: 2.4552 - val_accuracy: 0.3987 - val_precision: 0.4000 - val_recall: 0.3893\n",
            "Epoch 253/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5381 - accuracy: 0.7733 - precision: 0.7920 - recall: 0.7390 - val_loss: 2.6742 - val_accuracy: 0.3867 - val_precision: 0.3908 - val_recall: 0.3840\n",
            "Epoch 254/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5137 - accuracy: 0.7905 - precision: 0.8099 - recall: 0.7607 - val_loss: 2.5657 - val_accuracy: 0.4040 - val_precision: 0.4063 - val_recall: 0.3960\n",
            "Epoch 255/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5071 - accuracy: 0.7853 - precision: 0.8058 - recall: 0.7579 - val_loss: 2.7600 - val_accuracy: 0.3800 - val_precision: 0.3825 - val_recall: 0.3733\n",
            "Epoch 256/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5276 - accuracy: 0.7813 - precision: 0.8018 - recall: 0.7550 - val_loss: 2.4891 - val_accuracy: 0.4040 - val_precision: 0.4063 - val_recall: 0.3960\n",
            "Epoch 257/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5612 - accuracy: 0.7642 - precision: 0.7935 - recall: 0.7367 - val_loss: 2.3329 - val_accuracy: 0.4227 - val_precision: 0.4239 - val_recall: 0.4120\n",
            "Epoch 258/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5622 - accuracy: 0.7682 - precision: 0.7929 - recall: 0.7384 - val_loss: 2.2583 - val_accuracy: 0.4107 - val_precision: 0.4163 - val_recall: 0.4013\n",
            "Epoch 259/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5496 - accuracy: 0.7687 - precision: 0.7933 - recall: 0.7315 - val_loss: 2.5241 - val_accuracy: 0.4067 - val_precision: 0.4106 - val_recall: 0.4040\n",
            "Epoch 260/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5409 - accuracy: 0.7642 - precision: 0.7866 - recall: 0.7281 - val_loss: 2.5704 - val_accuracy: 0.4093 - val_precision: 0.4116 - val_recall: 0.4067\n",
            "Epoch 261/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5318 - accuracy: 0.7853 - precision: 0.8086 - recall: 0.7567 - val_loss: 2.8962 - val_accuracy: 0.3813 - val_precision: 0.3818 - val_recall: 0.3747\n",
            "Epoch 262/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5526 - accuracy: 0.7602 - precision: 0.7819 - recall: 0.7264 - val_loss: 2.6870 - val_accuracy: 0.3640 - val_precision: 0.3714 - val_recall: 0.3600\n",
            "Epoch 263/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5502 - accuracy: 0.7676 - precision: 0.7980 - recall: 0.7396 - val_loss: 2.6682 - val_accuracy: 0.3867 - val_precision: 0.3864 - val_recall: 0.3787\n",
            "Epoch 264/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5248 - accuracy: 0.7785 - precision: 0.7978 - recall: 0.7453 - val_loss: 2.8026 - val_accuracy: 0.3827 - val_precision: 0.3879 - val_recall: 0.3760\n",
            "Epoch 265/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5619 - accuracy: 0.7630 - precision: 0.7941 - recall: 0.7373 - val_loss: 2.6758 - val_accuracy: 0.4040 - val_precision: 0.4046 - val_recall: 0.3960\n",
            "Epoch 266/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5365 - accuracy: 0.7756 - precision: 0.7955 - recall: 0.7504 - val_loss: 2.5459 - val_accuracy: 0.3987 - val_precision: 0.4008 - val_recall: 0.3907\n",
            "Epoch 267/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5391 - accuracy: 0.7859 - precision: 0.8067 - recall: 0.7499 - val_loss: 2.6580 - val_accuracy: 0.3893 - val_precision: 0.3942 - val_recall: 0.3827\n",
            "Epoch 268/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5532 - accuracy: 0.7728 - precision: 0.7926 - recall: 0.7436 - val_loss: 2.7683 - val_accuracy: 0.3907 - val_precision: 0.3940 - val_recall: 0.3840\n",
            "Epoch 269/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5390 - accuracy: 0.7750 - precision: 0.8046 - recall: 0.7447 - val_loss: 2.5470 - val_accuracy: 0.3947 - val_precision: 0.3934 - val_recall: 0.3813\n",
            "Epoch 270/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5475 - accuracy: 0.7728 - precision: 0.7980 - recall: 0.7464 - val_loss: 2.5927 - val_accuracy: 0.4213 - val_precision: 0.4256 - val_recall: 0.4160\n",
            "Epoch 271/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5333 - accuracy: 0.7670 - precision: 0.7877 - recall: 0.7390 - val_loss: 2.3446 - val_accuracy: 0.4267 - val_precision: 0.4335 - val_recall: 0.4213\n",
            "Epoch 272/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5322 - accuracy: 0.7716 - precision: 0.7962 - recall: 0.7355 - val_loss: 2.4779 - val_accuracy: 0.4120 - val_precision: 0.4150 - val_recall: 0.4067\n",
            "Epoch 273/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5566 - accuracy: 0.7716 - precision: 0.7995 - recall: 0.7441 - val_loss: 2.4592 - val_accuracy: 0.4280 - val_precision: 0.4311 - val_recall: 0.4213\n",
            "Epoch 274/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5582 - accuracy: 0.7687 - precision: 0.7927 - recall: 0.7378 - val_loss: 2.4997 - val_accuracy: 0.4200 - val_precision: 0.4239 - val_recall: 0.4120\n",
            "Epoch 275/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5342 - accuracy: 0.7739 - precision: 0.7952 - recall: 0.7424 - val_loss: 2.4066 - val_accuracy: 0.4293 - val_precision: 0.4323 - val_recall: 0.4213\n",
            "Epoch 276/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5053 - accuracy: 0.7951 - precision: 0.8166 - recall: 0.7619 - val_loss: 2.5163 - val_accuracy: 0.4080 - val_precision: 0.4101 - val_recall: 0.4013\n",
            "Epoch 277/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.5317 - accuracy: 0.7785 - precision: 0.8039 - recall: 0.7510 - val_loss: 2.7748 - val_accuracy: 0.3960 - val_precision: 0.3978 - val_recall: 0.3893\n",
            "Epoch 278/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.5368 - accuracy: 0.7624 - precision: 0.7890 - recall: 0.7361 - val_loss: 3.0089 - val_accuracy: 0.3707 - val_precision: 0.3750 - val_recall: 0.3680\n",
            "Epoch 279/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.5287 - accuracy: 0.7682 - precision: 0.7907 - recall: 0.7396 - val_loss: 2.7773 - val_accuracy: 0.3733 - val_precision: 0.3784 - val_recall: 0.3693\n",
            "Epoch 280/1000\n",
            "55/55 [==============================] - 1s 13ms/step - loss: 0.5551 - accuracy: 0.7493 - precision: 0.7704 - recall: 0.7144 - val_loss: 2.7914 - val_accuracy: 0.3760 - val_precision: 0.3759 - val_recall: 0.3653\n",
            "Epoch 281/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5280 - accuracy: 0.7773 - precision: 0.8021 - recall: 0.7493 - val_loss: 2.6660 - val_accuracy: 0.3853 - val_precision: 0.3874 - val_recall: 0.3760\n",
            "Epoch 282/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5300 - accuracy: 0.7756 - precision: 0.7949 - recall: 0.7453 - val_loss: 2.7688 - val_accuracy: 0.3747 - val_precision: 0.3765 - val_recall: 0.3680\n",
            "Epoch 283/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5599 - accuracy: 0.7710 - precision: 0.7909 - recall: 0.7384 - val_loss: 2.9374 - val_accuracy: 0.3933 - val_precision: 0.3922 - val_recall: 0.3880\n",
            "Epoch 284/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5342 - accuracy: 0.7790 - precision: 0.7946 - recall: 0.7418 - val_loss: 2.8557 - val_accuracy: 0.4040 - val_precision: 0.4062 - val_recall: 0.3987\n",
            "Epoch 285/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5259 - accuracy: 0.7802 - precision: 0.7954 - recall: 0.7499 - val_loss: 2.4328 - val_accuracy: 0.4387 - val_precision: 0.4440 - val_recall: 0.4333\n",
            "Epoch 286/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5254 - accuracy: 0.7962 - precision: 0.8128 - recall: 0.7653 - val_loss: 2.6469 - val_accuracy: 0.4293 - val_precision: 0.4318 - val_recall: 0.4267\n",
            "Epoch 287/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5273 - accuracy: 0.7808 - precision: 0.7930 - recall: 0.7499 - val_loss: 2.5751 - val_accuracy: 0.4293 - val_precision: 0.4297 - val_recall: 0.4200\n",
            "Epoch 288/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5171 - accuracy: 0.7842 - precision: 0.8013 - recall: 0.7527 - val_loss: 2.6944 - val_accuracy: 0.3907 - val_precision: 0.3970 - val_recall: 0.3880\n",
            "Epoch 289/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5140 - accuracy: 0.7825 - precision: 0.7930 - recall: 0.7476 - val_loss: 2.5110 - val_accuracy: 0.4200 - val_precision: 0.4256 - val_recall: 0.4160\n",
            "Epoch 290/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5365 - accuracy: 0.7722 - precision: 0.7980 - recall: 0.7441 - val_loss: 2.3984 - val_accuracy: 0.4307 - val_precision: 0.4376 - val_recall: 0.4253\n",
            "Epoch 291/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5177 - accuracy: 0.7779 - precision: 0.7974 - recall: 0.7481 - val_loss: 2.4528 - val_accuracy: 0.4093 - val_precision: 0.4139 - val_recall: 0.3973\n",
            "Epoch 292/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5583 - accuracy: 0.7739 - precision: 0.7955 - recall: 0.7481 - val_loss: 2.7117 - val_accuracy: 0.3867 - val_precision: 0.3909 - val_recall: 0.3800\n",
            "Epoch 293/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5117 - accuracy: 0.8071 - precision: 0.8253 - recall: 0.7762 - val_loss: 2.7223 - val_accuracy: 0.4040 - val_precision: 0.4071 - val_recall: 0.4000\n",
            "Epoch 294/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5107 - accuracy: 0.7997 - precision: 0.8186 - recall: 0.7722 - val_loss: 2.4152 - val_accuracy: 0.4373 - val_precision: 0.4397 - val_recall: 0.4227\n",
            "Epoch 295/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5170 - accuracy: 0.7888 - precision: 0.8100 - recall: 0.7636 - val_loss: 2.5353 - val_accuracy: 0.4400 - val_precision: 0.4394 - val_recall: 0.4347\n",
            "Epoch 296/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5108 - accuracy: 0.7974 - precision: 0.8148 - recall: 0.7756 - val_loss: 2.4144 - val_accuracy: 0.4467 - val_precision: 0.4512 - val_recall: 0.4440\n",
            "Epoch 297/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5058 - accuracy: 0.7813 - precision: 0.8055 - recall: 0.7516 - val_loss: 2.5425 - val_accuracy: 0.4467 - val_precision: 0.4507 - val_recall: 0.4453\n",
            "Epoch 298/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5126 - accuracy: 0.7865 - precision: 0.8034 - recall: 0.7624 - val_loss: 2.8082 - val_accuracy: 0.4240 - val_precision: 0.4264 - val_recall: 0.4173\n",
            "Epoch 299/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5411 - accuracy: 0.7790 - precision: 0.7986 - recall: 0.7447 - val_loss: 2.7776 - val_accuracy: 0.4093 - val_precision: 0.4128 - val_recall: 0.4040\n",
            "Epoch 300/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5109 - accuracy: 0.7888 - precision: 0.8055 - recall: 0.7607 - val_loss: 2.5310 - val_accuracy: 0.4347 - val_precision: 0.4375 - val_recall: 0.4293\n",
            "Epoch 301/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5570 - accuracy: 0.7653 - precision: 0.7810 - recall: 0.7350 - val_loss: 2.3565 - val_accuracy: 0.4627 - val_precision: 0.4632 - val_recall: 0.4533\n",
            "Epoch 302/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5474 - accuracy: 0.7653 - precision: 0.7894 - recall: 0.7361 - val_loss: 2.7349 - val_accuracy: 0.4307 - val_precision: 0.4315 - val_recall: 0.4280\n",
            "Epoch 303/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5260 - accuracy: 0.7859 - precision: 0.8059 - recall: 0.7556 - val_loss: 2.7414 - val_accuracy: 0.4333 - val_precision: 0.4342 - val_recall: 0.4267\n",
            "Epoch 304/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5265 - accuracy: 0.7785 - precision: 0.8010 - recall: 0.7579 - val_loss: 2.7184 - val_accuracy: 0.4053 - val_precision: 0.4096 - val_recall: 0.3987\n",
            "Epoch 305/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5435 - accuracy: 0.7647 - precision: 0.7842 - recall: 0.7384 - val_loss: 2.3997 - val_accuracy: 0.4333 - val_precision: 0.4368 - val_recall: 0.4240\n",
            "Epoch 306/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.5162 - accuracy: 0.7682 - precision: 0.7929 - recall: 0.7453 - val_loss: 2.4759 - val_accuracy: 0.4133 - val_precision: 0.4175 - val_recall: 0.4080\n",
            "Epoch 307/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.5367 - accuracy: 0.7670 - precision: 0.7906 - recall: 0.7350 - val_loss: 2.4236 - val_accuracy: 0.4120 - val_precision: 0.4185 - val_recall: 0.4040\n",
            "Epoch 308/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.5306 - accuracy: 0.7865 - precision: 0.8066 - recall: 0.7544 - val_loss: 2.7790 - val_accuracy: 0.4133 - val_precision: 0.4145 - val_recall: 0.4107\n",
            "Epoch 309/1000\n",
            "55/55 [==============================] - 1s 13ms/step - loss: 0.5318 - accuracy: 0.7682 - precision: 0.7838 - recall: 0.7367 - val_loss: 2.4468 - val_accuracy: 0.4400 - val_precision: 0.4423 - val_recall: 0.4347\n",
            "Epoch 310/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5301 - accuracy: 0.7911 - precision: 0.8152 - recall: 0.7624 - val_loss: 2.2119 - val_accuracy: 0.4387 - val_precision: 0.4444 - val_recall: 0.4320\n",
            "Epoch 311/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4828 - accuracy: 0.8071 - precision: 0.8313 - recall: 0.7756 - val_loss: 2.5941 - val_accuracy: 0.4333 - val_precision: 0.4364 - val_recall: 0.4253\n",
            "Epoch 312/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5309 - accuracy: 0.7876 - precision: 0.8031 - recall: 0.7659 - val_loss: 2.8328 - val_accuracy: 0.3960 - val_precision: 0.4028 - val_recall: 0.3893\n",
            "Epoch 313/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5219 - accuracy: 0.7739 - precision: 0.7962 - recall: 0.7470 - val_loss: 2.8347 - val_accuracy: 0.3987 - val_precision: 0.4058 - val_recall: 0.3933\n",
            "Epoch 314/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.5442 - accuracy: 0.7836 - precision: 0.8019 - recall: 0.7556 - val_loss: 3.1186 - val_accuracy: 0.3733 - val_precision: 0.3793 - val_recall: 0.3707\n",
            "Epoch 315/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5222 - accuracy: 0.7733 - precision: 0.7979 - recall: 0.7459 - val_loss: 2.8163 - val_accuracy: 0.3947 - val_precision: 0.4000 - val_recall: 0.3893\n",
            "Epoch 316/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5084 - accuracy: 0.7859 - precision: 0.8088 - recall: 0.7653 - val_loss: 2.6174 - val_accuracy: 0.4013 - val_precision: 0.4030 - val_recall: 0.3907\n",
            "Epoch 317/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5062 - accuracy: 0.7962 - precision: 0.8159 - recall: 0.7710 - val_loss: 2.6550 - val_accuracy: 0.4013 - val_precision: 0.3981 - val_recall: 0.3827\n",
            "Epoch 318/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5305 - accuracy: 0.7785 - precision: 0.7966 - recall: 0.7533 - val_loss: 2.4451 - val_accuracy: 0.3960 - val_precision: 0.4011 - val_recall: 0.3867\n",
            "Epoch 319/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5327 - accuracy: 0.7785 - precision: 0.7996 - recall: 0.7562 - val_loss: 2.3155 - val_accuracy: 0.4120 - val_precision: 0.4214 - val_recall: 0.4040\n",
            "Epoch 320/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5439 - accuracy: 0.7722 - precision: 0.7946 - recall: 0.7396 - val_loss: 2.7370 - val_accuracy: 0.3733 - val_precision: 0.3745 - val_recall: 0.3680\n",
            "Epoch 321/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5256 - accuracy: 0.7848 - precision: 0.8021 - recall: 0.7516 - val_loss: 2.7802 - val_accuracy: 0.3853 - val_precision: 0.3851 - val_recall: 0.3800\n",
            "Epoch 322/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5456 - accuracy: 0.7699 - precision: 0.7943 - recall: 0.7361 - val_loss: 2.6857 - val_accuracy: 0.3840 - val_precision: 0.3890 - val_recall: 0.3787\n",
            "Epoch 323/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5600 - accuracy: 0.7710 - precision: 0.7958 - recall: 0.7453 - val_loss: 2.4143 - val_accuracy: 0.4173 - val_precision: 0.4244 - val_recall: 0.4080\n",
            "Epoch 324/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5437 - accuracy: 0.7779 - precision: 0.7968 - recall: 0.7453 - val_loss: 2.5569 - val_accuracy: 0.4093 - val_precision: 0.4126 - val_recall: 0.4027\n",
            "Epoch 325/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5515 - accuracy: 0.7808 - precision: 0.7991 - recall: 0.7493 - val_loss: 2.7157 - val_accuracy: 0.3813 - val_precision: 0.3799 - val_recall: 0.3733\n",
            "Epoch 326/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5082 - accuracy: 0.7859 - precision: 0.8072 - recall: 0.7619 - val_loss: 2.7751 - val_accuracy: 0.3733 - val_precision: 0.3730 - val_recall: 0.3680\n",
            "Epoch 327/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5399 - accuracy: 0.7756 - precision: 0.7940 - recall: 0.7413 - val_loss: 2.7458 - val_accuracy: 0.3773 - val_precision: 0.3797 - val_recall: 0.3747\n",
            "Epoch 328/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5676 - accuracy: 0.7647 - precision: 0.7911 - recall: 0.7241 - val_loss: 2.6722 - val_accuracy: 0.3853 - val_precision: 0.3870 - val_recall: 0.3813\n",
            "Epoch 329/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4916 - accuracy: 0.7905 - precision: 0.8076 - recall: 0.7590 - val_loss: 2.9924 - val_accuracy: 0.3827 - val_precision: 0.3896 - val_recall: 0.3813\n",
            "Epoch 330/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5376 - accuracy: 0.7853 - precision: 0.8053 - recall: 0.7481 - val_loss: 3.1925 - val_accuracy: 0.3787 - val_precision: 0.3808 - val_recall: 0.3747\n",
            "Epoch 331/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5496 - accuracy: 0.7710 - precision: 0.7957 - recall: 0.7401 - val_loss: 3.1218 - val_accuracy: 0.3827 - val_precision: 0.3862 - val_recall: 0.3733\n",
            "Epoch 332/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5244 - accuracy: 0.7916 - precision: 0.8150 - recall: 0.7567 - val_loss: 2.9036 - val_accuracy: 0.3853 - val_precision: 0.3882 - val_recall: 0.3773\n",
            "Epoch 333/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5148 - accuracy: 0.7653 - precision: 0.7885 - recall: 0.7361 - val_loss: 3.2012 - val_accuracy: 0.3613 - val_precision: 0.3604 - val_recall: 0.3547\n",
            "Epoch 334/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5596 - accuracy: 0.7630 - precision: 0.7843 - recall: 0.7327 - val_loss: 2.8384 - val_accuracy: 0.3773 - val_precision: 0.3823 - val_recall: 0.3747\n",
            "Epoch 335/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.5214 - accuracy: 0.7825 - precision: 0.8042 - recall: 0.7596 - val_loss: 2.5331 - val_accuracy: 0.3933 - val_precision: 0.3975 - val_recall: 0.3800\n",
            "Epoch 336/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.5295 - accuracy: 0.7716 - precision: 0.7934 - recall: 0.7453 - val_loss: 2.5197 - val_accuracy: 0.3613 - val_precision: 0.3682 - val_recall: 0.3520\n",
            "Epoch 337/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.5049 - accuracy: 0.7945 - precision: 0.8206 - recall: 0.7647 - val_loss: 2.3114 - val_accuracy: 0.4120 - val_precision: 0.4156 - val_recall: 0.4040\n",
            "Epoch 338/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4880 - accuracy: 0.7911 - precision: 0.8122 - recall: 0.7624 - val_loss: 2.6541 - val_accuracy: 0.3893 - val_precision: 0.3901 - val_recall: 0.3787\n",
            "Epoch 339/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5388 - accuracy: 0.7653 - precision: 0.7844 - recall: 0.7350 - val_loss: 2.7005 - val_accuracy: 0.3880 - val_precision: 0.3869 - val_recall: 0.3787\n",
            "Epoch 340/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5407 - accuracy: 0.7750 - precision: 0.7932 - recall: 0.7441 - val_loss: 2.8695 - val_accuracy: 0.3733 - val_precision: 0.3748 - val_recall: 0.3653\n",
            "Epoch 341/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5001 - accuracy: 0.7997 - precision: 0.8158 - recall: 0.7733 - val_loss: 2.7133 - val_accuracy: 0.3867 - val_precision: 0.3920 - val_recall: 0.3800\n",
            "Epoch 342/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5207 - accuracy: 0.7905 - precision: 0.8082 - recall: 0.7573 - val_loss: 2.7574 - val_accuracy: 0.3893 - val_precision: 0.3927 - val_recall: 0.3853\n",
            "Epoch 343/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5035 - accuracy: 0.7894 - precision: 0.8172 - recall: 0.7653 - val_loss: 2.8538 - val_accuracy: 0.3880 - val_precision: 0.3922 - val_recall: 0.3880\n",
            "Epoch 344/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5224 - accuracy: 0.7819 - precision: 0.8011 - recall: 0.7584 - val_loss: 2.9894 - val_accuracy: 0.4000 - val_precision: 0.4035 - val_recall: 0.3987\n",
            "Epoch 345/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5214 - accuracy: 0.7831 - precision: 0.8034 - recall: 0.7602 - val_loss: 2.7467 - val_accuracy: 0.4107 - val_precision: 0.4135 - val_recall: 0.4080\n",
            "Epoch 346/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4953 - accuracy: 0.7831 - precision: 0.8007 - recall: 0.7659 - val_loss: 2.8573 - val_accuracy: 0.4067 - val_precision: 0.4059 - val_recall: 0.4027\n",
            "Epoch 347/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5118 - accuracy: 0.7750 - precision: 0.7977 - recall: 0.7447 - val_loss: 3.0622 - val_accuracy: 0.3933 - val_precision: 0.3965 - val_recall: 0.3933\n",
            "Epoch 348/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5022 - accuracy: 0.7899 - precision: 0.8083 - recall: 0.7699 - val_loss: 2.5173 - val_accuracy: 0.4187 - val_precision: 0.4241 - val_recall: 0.4133\n",
            "Epoch 349/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4963 - accuracy: 0.7876 - precision: 0.8086 - recall: 0.7567 - val_loss: 2.6666 - val_accuracy: 0.3907 - val_precision: 0.3951 - val_recall: 0.3867\n",
            "Epoch 350/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5149 - accuracy: 0.7905 - precision: 0.8101 - recall: 0.7642 - val_loss: 2.7300 - val_accuracy: 0.3787 - val_precision: 0.3818 - val_recall: 0.3747\n",
            "Epoch 351/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5224 - accuracy: 0.7762 - precision: 0.8027 - recall: 0.7521 - val_loss: 2.4036 - val_accuracy: 0.3893 - val_precision: 0.3914 - val_recall: 0.3747\n",
            "Epoch 352/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5384 - accuracy: 0.7813 - precision: 0.8004 - recall: 0.7436 - val_loss: 2.5924 - val_accuracy: 0.3920 - val_precision: 0.3951 - val_recall: 0.3867\n",
            "Epoch 353/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5293 - accuracy: 0.7825 - precision: 0.8002 - recall: 0.7544 - val_loss: 3.0806 - val_accuracy: 0.3547 - val_precision: 0.3596 - val_recall: 0.3533\n",
            "Epoch 354/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5132 - accuracy: 0.7934 - precision: 0.8145 - recall: 0.7642 - val_loss: 2.7720 - val_accuracy: 0.3733 - val_precision: 0.3775 - val_recall: 0.3720\n",
            "Epoch 355/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5108 - accuracy: 0.7899 - precision: 0.8073 - recall: 0.7647 - val_loss: 2.5793 - val_accuracy: 0.3947 - val_precision: 0.3957 - val_recall: 0.3920\n",
            "Epoch 356/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5014 - accuracy: 0.7939 - precision: 0.8134 - recall: 0.7687 - val_loss: 2.6068 - val_accuracy: 0.3973 - val_precision: 0.3995 - val_recall: 0.3920\n",
            "Epoch 357/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5236 - accuracy: 0.7888 - precision: 0.8076 - recall: 0.7687 - val_loss: 2.4212 - val_accuracy: 0.4280 - val_precision: 0.4340 - val_recall: 0.4253\n",
            "Epoch 358/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5049 - accuracy: 0.7911 - precision: 0.8133 - recall: 0.7607 - val_loss: 2.3336 - val_accuracy: 0.4293 - val_precision: 0.4347 - val_recall: 0.4213\n",
            "Epoch 359/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5237 - accuracy: 0.7968 - precision: 0.8065 - recall: 0.7613 - val_loss: 2.7212 - val_accuracy: 0.3973 - val_precision: 0.4014 - val_recall: 0.3907\n",
            "Epoch 360/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5105 - accuracy: 0.7934 - precision: 0.8128 - recall: 0.7607 - val_loss: 2.9452 - val_accuracy: 0.3747 - val_precision: 0.3788 - val_recall: 0.3667\n",
            "Epoch 361/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5110 - accuracy: 0.7911 - precision: 0.8134 - recall: 0.7584 - val_loss: 3.0348 - val_accuracy: 0.3747 - val_precision: 0.3822 - val_recall: 0.3720\n",
            "Epoch 362/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5326 - accuracy: 0.7682 - precision: 0.7834 - recall: 0.7350 - val_loss: 2.7208 - val_accuracy: 0.3680 - val_precision: 0.3709 - val_recall: 0.3600\n",
            "Epoch 363/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5059 - accuracy: 0.7922 - precision: 0.8075 - recall: 0.7682 - val_loss: 2.6430 - val_accuracy: 0.3880 - val_precision: 0.3918 - val_recall: 0.3840\n",
            "Epoch 364/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.5129 - accuracy: 0.7836 - precision: 0.8054 - recall: 0.7533 - val_loss: 2.5011 - val_accuracy: 0.4160 - val_precision: 0.4144 - val_recall: 0.4067\n",
            "Epoch 365/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.5130 - accuracy: 0.7911 - precision: 0.8150 - recall: 0.7642 - val_loss: 2.3607 - val_accuracy: 0.4107 - val_precision: 0.4166 - val_recall: 0.4027\n",
            "Epoch 366/1000\n",
            "55/55 [==============================] - 1s 13ms/step - loss: 0.5099 - accuracy: 0.7882 - precision: 0.8050 - recall: 0.7630 - val_loss: 2.5843 - val_accuracy: 0.4147 - val_precision: 0.4196 - val_recall: 0.4107\n",
            "Epoch 367/1000\n",
            "55/55 [==============================] - 1s 13ms/step - loss: 0.5237 - accuracy: 0.7728 - precision: 0.7977 - recall: 0.7424 - val_loss: 2.8440 - val_accuracy: 0.3907 - val_precision: 0.3914 - val_recall: 0.3893\n",
            "Epoch 368/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5221 - accuracy: 0.7894 - precision: 0.8117 - recall: 0.7573 - val_loss: 2.3758 - val_accuracy: 0.4400 - val_precision: 0.4461 - val_recall: 0.4360\n",
            "Epoch 369/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5164 - accuracy: 0.7945 - precision: 0.8101 - recall: 0.7619 - val_loss: 2.5235 - val_accuracy: 0.3960 - val_precision: 0.4039 - val_recall: 0.3893\n",
            "Epoch 370/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5055 - accuracy: 0.7882 - precision: 0.8094 - recall: 0.7607 - val_loss: 2.7190 - val_accuracy: 0.3800 - val_precision: 0.3871 - val_recall: 0.3747\n",
            "Epoch 371/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5399 - accuracy: 0.7756 - precision: 0.7893 - recall: 0.7481 - val_loss: 2.7926 - val_accuracy: 0.3760 - val_precision: 0.3816 - val_recall: 0.3653\n",
            "Epoch 372/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4931 - accuracy: 0.8082 - precision: 0.8261 - recall: 0.7831 - val_loss: 2.8848 - val_accuracy: 0.3813 - val_precision: 0.3838 - val_recall: 0.3720\n",
            "Epoch 373/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4805 - accuracy: 0.8054 - precision: 0.8199 - recall: 0.7842 - val_loss: 2.6287 - val_accuracy: 0.4040 - val_precision: 0.4066 - val_recall: 0.3920\n",
            "Epoch 374/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4954 - accuracy: 0.8002 - precision: 0.8163 - recall: 0.7756 - val_loss: 3.1131 - val_accuracy: 0.3893 - val_precision: 0.3867 - val_recall: 0.3733\n",
            "Epoch 375/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4920 - accuracy: 0.7945 - precision: 0.8123 - recall: 0.7705 - val_loss: 3.1082 - val_accuracy: 0.3707 - val_precision: 0.3728 - val_recall: 0.3613\n",
            "Epoch 376/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5306 - accuracy: 0.7888 - precision: 0.8011 - recall: 0.7653 - val_loss: 3.0213 - val_accuracy: 0.3680 - val_precision: 0.3719 - val_recall: 0.3600\n",
            "Epoch 377/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4990 - accuracy: 0.7905 - precision: 0.8117 - recall: 0.7624 - val_loss: 2.8972 - val_accuracy: 0.3747 - val_precision: 0.3758 - val_recall: 0.3733\n",
            "Epoch 378/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5392 - accuracy: 0.7682 - precision: 0.7860 - recall: 0.7378 - val_loss: 2.7911 - val_accuracy: 0.3773 - val_precision: 0.3789 - val_recall: 0.3733\n",
            "Epoch 379/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5251 - accuracy: 0.7705 - precision: 0.7885 - recall: 0.7384 - val_loss: 2.9672 - val_accuracy: 0.3747 - val_precision: 0.3825 - val_recall: 0.3733\n",
            "Epoch 380/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5166 - accuracy: 0.7836 - precision: 0.8005 - recall: 0.7533 - val_loss: 3.0152 - val_accuracy: 0.3693 - val_precision: 0.3772 - val_recall: 0.3667\n",
            "Epoch 381/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5250 - accuracy: 0.7802 - precision: 0.7985 - recall: 0.7556 - val_loss: 2.4731 - val_accuracy: 0.3893 - val_precision: 0.3986 - val_recall: 0.3853\n",
            "Epoch 382/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5249 - accuracy: 0.7768 - precision: 0.7990 - recall: 0.7510 - val_loss: 2.8564 - val_accuracy: 0.3760 - val_precision: 0.3802 - val_recall: 0.3747\n",
            "Epoch 383/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5409 - accuracy: 0.7848 - precision: 0.8056 - recall: 0.7521 - val_loss: 2.6226 - val_accuracy: 0.4040 - val_precision: 0.4076 - val_recall: 0.4000\n",
            "Epoch 384/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4858 - accuracy: 0.7985 - precision: 0.8252 - recall: 0.7756 - val_loss: 2.8561 - val_accuracy: 0.3853 - val_precision: 0.3834 - val_recall: 0.3747\n",
            "Epoch 385/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5050 - accuracy: 0.7871 - precision: 0.8062 - recall: 0.7596 - val_loss: 2.7567 - val_accuracy: 0.3907 - val_precision: 0.3908 - val_recall: 0.3840\n",
            "Epoch 386/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5099 - accuracy: 0.7871 - precision: 0.8079 - recall: 0.7607 - val_loss: 2.5083 - val_accuracy: 0.3827 - val_precision: 0.3855 - val_recall: 0.3747\n",
            "Epoch 387/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5017 - accuracy: 0.7916 - precision: 0.8066 - recall: 0.7642 - val_loss: 3.2179 - val_accuracy: 0.3573 - val_precision: 0.3628 - val_recall: 0.3560\n",
            "Epoch 388/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5166 - accuracy: 0.7853 - precision: 0.8042 - recall: 0.7596 - val_loss: 3.1428 - val_accuracy: 0.3667 - val_precision: 0.3694 - val_recall: 0.3600\n",
            "Epoch 389/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4931 - accuracy: 0.8014 - precision: 0.8168 - recall: 0.7659 - val_loss: 2.8655 - val_accuracy: 0.3800 - val_precision: 0.3819 - val_recall: 0.3773\n",
            "Epoch 390/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5052 - accuracy: 0.7825 - precision: 0.8023 - recall: 0.7573 - val_loss: 2.7945 - val_accuracy: 0.3840 - val_precision: 0.3843 - val_recall: 0.3787\n",
            "Epoch 391/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4926 - accuracy: 0.8014 - precision: 0.8218 - recall: 0.7813 - val_loss: 2.9415 - val_accuracy: 0.4173 - val_precision: 0.4180 - val_recall: 0.4147\n",
            "Epoch 392/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5039 - accuracy: 0.7796 - precision: 0.7995 - recall: 0.7533 - val_loss: 2.8728 - val_accuracy: 0.3880 - val_precision: 0.3916 - val_recall: 0.3853\n",
            "Epoch 393/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.5208 - accuracy: 0.7894 - precision: 0.8031 - recall: 0.7682 - val_loss: 3.0311 - val_accuracy: 0.3840 - val_precision: 0.3860 - val_recall: 0.3813\n",
            "Epoch 394/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4926 - accuracy: 0.7905 - precision: 0.8115 - recall: 0.7613 - val_loss: 2.9680 - val_accuracy: 0.3773 - val_precision: 0.3786 - val_recall: 0.3720\n",
            "Epoch 395/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4875 - accuracy: 0.7939 - precision: 0.8131 - recall: 0.7745 - val_loss: 3.4082 - val_accuracy: 0.3613 - val_precision: 0.3649 - val_recall: 0.3600\n",
            "Epoch 396/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.5145 - accuracy: 0.7808 - precision: 0.8018 - recall: 0.7596 - val_loss: 3.1683 - val_accuracy: 0.3733 - val_precision: 0.3781 - val_recall: 0.3680\n",
            "Epoch 397/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4877 - accuracy: 0.8014 - precision: 0.8204 - recall: 0.7768 - val_loss: 2.9960 - val_accuracy: 0.3827 - val_precision: 0.3895 - val_recall: 0.3760\n",
            "Epoch 398/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5103 - accuracy: 0.7979 - precision: 0.8181 - recall: 0.7722 - val_loss: 2.9697 - val_accuracy: 0.3747 - val_precision: 0.3764 - val_recall: 0.3693\n",
            "Epoch 399/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5095 - accuracy: 0.7968 - precision: 0.8189 - recall: 0.7687 - val_loss: 2.7400 - val_accuracy: 0.3840 - val_precision: 0.3908 - val_recall: 0.3747\n",
            "Epoch 400/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5123 - accuracy: 0.7842 - precision: 0.8061 - recall: 0.7613 - val_loss: 2.7492 - val_accuracy: 0.3867 - val_precision: 0.3920 - val_recall: 0.3773\n",
            "Epoch 401/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5264 - accuracy: 0.7808 - precision: 0.8013 - recall: 0.7527 - val_loss: 2.8666 - val_accuracy: 0.3853 - val_precision: 0.3825 - val_recall: 0.3667\n",
            "Epoch 402/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5622 - accuracy: 0.7665 - precision: 0.7872 - recall: 0.7327 - val_loss: 2.6696 - val_accuracy: 0.3840 - val_precision: 0.3835 - val_recall: 0.3667\n",
            "Epoch 403/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5473 - accuracy: 0.7619 - precision: 0.7858 - recall: 0.7310 - val_loss: 2.4451 - val_accuracy: 0.4200 - val_precision: 0.4219 - val_recall: 0.4067\n",
            "Epoch 404/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5581 - accuracy: 0.7659 - precision: 0.7861 - recall: 0.7298 - val_loss: 2.6698 - val_accuracy: 0.3920 - val_precision: 0.3950 - val_recall: 0.3760\n",
            "Epoch 405/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5256 - accuracy: 0.7836 - precision: 0.8033 - recall: 0.7573 - val_loss: 2.6850 - val_accuracy: 0.4000 - val_precision: 0.4047 - val_recall: 0.3907\n",
            "Epoch 406/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5362 - accuracy: 0.7745 - precision: 0.7956 - recall: 0.7464 - val_loss: 2.5460 - val_accuracy: 0.4040 - val_precision: 0.4093 - val_recall: 0.4000\n",
            "Epoch 407/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5318 - accuracy: 0.7779 - precision: 0.7906 - recall: 0.7499 - val_loss: 2.4644 - val_accuracy: 0.4267 - val_precision: 0.4303 - val_recall: 0.4240\n",
            "Epoch 408/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5061 - accuracy: 0.7888 - precision: 0.8078 - recall: 0.7624 - val_loss: 2.7178 - val_accuracy: 0.3907 - val_precision: 0.3959 - val_recall: 0.3853\n",
            "Epoch 409/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5558 - accuracy: 0.7659 - precision: 0.7903 - recall: 0.7401 - val_loss: 2.4904 - val_accuracy: 0.3947 - val_precision: 0.4000 - val_recall: 0.3840\n",
            "Epoch 410/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5102 - accuracy: 0.7790 - precision: 0.7979 - recall: 0.7527 - val_loss: 2.5525 - val_accuracy: 0.4213 - val_precision: 0.4227 - val_recall: 0.4120\n",
            "Epoch 411/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4764 - accuracy: 0.8042 - precision: 0.8212 - recall: 0.7756 - val_loss: 2.7433 - val_accuracy: 0.3947 - val_precision: 0.3984 - val_recall: 0.3867\n",
            "Epoch 412/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4845 - accuracy: 0.7934 - precision: 0.8142 - recall: 0.7699 - val_loss: 3.0275 - val_accuracy: 0.3760 - val_precision: 0.3817 - val_recall: 0.3720\n",
            "Epoch 413/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5311 - accuracy: 0.7790 - precision: 0.8035 - recall: 0.7516 - val_loss: 2.8469 - val_accuracy: 0.3747 - val_precision: 0.3786 - val_recall: 0.3720\n",
            "Epoch 414/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.7888 - precision: 0.8096 - recall: 0.7642 - val_loss: 2.8578 - val_accuracy: 0.3933 - val_precision: 0.3903 - val_recall: 0.3867\n",
            "Epoch 415/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5186 - accuracy: 0.7682 - precision: 0.7888 - recall: 0.7441 - val_loss: 3.1365 - val_accuracy: 0.3667 - val_precision: 0.3655 - val_recall: 0.3587\n",
            "Epoch 416/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5200 - accuracy: 0.7825 - precision: 0.8065 - recall: 0.7584 - val_loss: 2.8896 - val_accuracy: 0.3747 - val_precision: 0.3731 - val_recall: 0.3667\n",
            "Epoch 417/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5208 - accuracy: 0.7745 - precision: 0.7950 - recall: 0.7481 - val_loss: 2.9304 - val_accuracy: 0.3747 - val_precision: 0.3753 - val_recall: 0.3653\n",
            "Epoch 418/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5171 - accuracy: 0.7848 - precision: 0.8070 - recall: 0.7562 - val_loss: 2.7561 - val_accuracy: 0.4133 - val_precision: 0.4114 - val_recall: 0.4053\n",
            "Epoch 419/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5289 - accuracy: 0.7773 - precision: 0.7939 - recall: 0.7539 - val_loss: 2.7348 - val_accuracy: 0.4067 - val_precision: 0.4095 - val_recall: 0.4040\n",
            "Epoch 420/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5159 - accuracy: 0.7728 - precision: 0.7952 - recall: 0.7447 - val_loss: 2.4334 - val_accuracy: 0.4200 - val_precision: 0.4231 - val_recall: 0.4147\n",
            "Epoch 421/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.5218 - accuracy: 0.7773 - precision: 0.8014 - recall: 0.7436 - val_loss: 2.7096 - val_accuracy: 0.3960 - val_precision: 0.3986 - val_recall: 0.3907\n",
            "Epoch 422/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.5146 - accuracy: 0.7888 - precision: 0.8048 - recall: 0.7624 - val_loss: 2.6338 - val_accuracy: 0.4120 - val_precision: 0.4138 - val_recall: 0.4067\n",
            "Epoch 423/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.5110 - accuracy: 0.7859 - precision: 0.8046 - recall: 0.7636 - val_loss: 2.7039 - val_accuracy: 0.4027 - val_precision: 0.4038 - val_recall: 0.3973\n",
            "Epoch 424/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4959 - accuracy: 0.7842 - precision: 0.8071 - recall: 0.7590 - val_loss: 2.6754 - val_accuracy: 0.4200 - val_precision: 0.4220 - val_recall: 0.4187\n",
            "Epoch 425/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4772 - accuracy: 0.7991 - precision: 0.8176 - recall: 0.7750 - val_loss: 2.6738 - val_accuracy: 0.4347 - val_precision: 0.4367 - val_recall: 0.4320\n",
            "Epoch 426/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4917 - accuracy: 0.7928 - precision: 0.8114 - recall: 0.7659 - val_loss: 2.6845 - val_accuracy: 0.4373 - val_precision: 0.4407 - val_recall: 0.4360\n",
            "Epoch 427/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4687 - accuracy: 0.8077 - precision: 0.8294 - recall: 0.7819 - val_loss: 2.5799 - val_accuracy: 0.4187 - val_precision: 0.4211 - val_recall: 0.4093\n",
            "Epoch 428/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5055 - accuracy: 0.7945 - precision: 0.8145 - recall: 0.7665 - val_loss: 2.9625 - val_accuracy: 0.3853 - val_precision: 0.3878 - val_recall: 0.3827\n",
            "Epoch 429/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5009 - accuracy: 0.7928 - precision: 0.8144 - recall: 0.7659 - val_loss: 2.8817 - val_accuracy: 0.3920 - val_precision: 0.3964 - val_recall: 0.3853\n",
            "Epoch 430/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4847 - accuracy: 0.8054 - precision: 0.8286 - recall: 0.7802 - val_loss: 2.8737 - val_accuracy: 0.3933 - val_precision: 0.3923 - val_recall: 0.3813\n",
            "Epoch 431/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4934 - accuracy: 0.7928 - precision: 0.8099 - recall: 0.7705 - val_loss: 2.6213 - val_accuracy: 0.4000 - val_precision: 0.4000 - val_recall: 0.3947\n",
            "Epoch 432/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5245 - accuracy: 0.7728 - precision: 0.7884 - recall: 0.7424 - val_loss: 2.7319 - val_accuracy: 0.3907 - val_precision: 0.3923 - val_recall: 0.3813\n",
            "Epoch 433/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4931 - accuracy: 0.7979 - precision: 0.8226 - recall: 0.7699 - val_loss: 2.6478 - val_accuracy: 0.4000 - val_precision: 0.3992 - val_recall: 0.3880\n",
            "Epoch 434/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4746 - accuracy: 0.8060 - precision: 0.8266 - recall: 0.7831 - val_loss: 2.7189 - val_accuracy: 0.4040 - val_precision: 0.4019 - val_recall: 0.3933\n",
            "Epoch 435/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4790 - accuracy: 0.8019 - precision: 0.8261 - recall: 0.7750 - val_loss: 3.0389 - val_accuracy: 0.3920 - val_precision: 0.3949 - val_recall: 0.3907\n",
            "Epoch 436/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4782 - accuracy: 0.8100 - precision: 0.8293 - recall: 0.7871 - val_loss: 2.8526 - val_accuracy: 0.3960 - val_precision: 0.4022 - val_recall: 0.3920\n",
            "Epoch 437/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4958 - accuracy: 0.8025 - precision: 0.8175 - recall: 0.7768 - val_loss: 2.7703 - val_accuracy: 0.3960 - val_precision: 0.3989 - val_recall: 0.3893\n",
            "Epoch 438/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5186 - accuracy: 0.7899 - precision: 0.8034 - recall: 0.7670 - val_loss: 2.8994 - val_accuracy: 0.3893 - val_precision: 0.3948 - val_recall: 0.3880\n",
            "Epoch 439/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4856 - accuracy: 0.8019 - precision: 0.8215 - recall: 0.7796 - val_loss: 2.8685 - val_accuracy: 0.3933 - val_precision: 0.3943 - val_recall: 0.3853\n",
            "Epoch 440/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5006 - accuracy: 0.7997 - precision: 0.8152 - recall: 0.7676 - val_loss: 2.4521 - val_accuracy: 0.4413 - val_precision: 0.4441 - val_recall: 0.4347\n",
            "Epoch 441/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5069 - accuracy: 0.7859 - precision: 0.8078 - recall: 0.7579 - val_loss: 2.4621 - val_accuracy: 0.4347 - val_precision: 0.4369 - val_recall: 0.4293\n",
            "Epoch 442/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5076 - accuracy: 0.7888 - precision: 0.8069 - recall: 0.7607 - val_loss: 2.6955 - val_accuracy: 0.4040 - val_precision: 0.4041 - val_recall: 0.3960\n",
            "Epoch 443/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4910 - accuracy: 0.8025 - precision: 0.8216 - recall: 0.7722 - val_loss: 3.0007 - val_accuracy: 0.3893 - val_precision: 0.3932 - val_recall: 0.3853\n",
            "Epoch 444/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4993 - accuracy: 0.7905 - precision: 0.8053 - recall: 0.7693 - val_loss: 2.6187 - val_accuracy: 0.4293 - val_precision: 0.4291 - val_recall: 0.4240\n",
            "Epoch 445/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4931 - accuracy: 0.7876 - precision: 0.8094 - recall: 0.7607 - val_loss: 2.4657 - val_accuracy: 0.4720 - val_precision: 0.4749 - val_recall: 0.4667\n",
            "Epoch 446/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5157 - accuracy: 0.7831 - precision: 0.7977 - recall: 0.7584 - val_loss: 2.4786 - val_accuracy: 0.4693 - val_precision: 0.4688 - val_recall: 0.4613\n",
            "Epoch 447/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4913 - accuracy: 0.7951 - precision: 0.8162 - recall: 0.7728 - val_loss: 2.6498 - val_accuracy: 0.4347 - val_precision: 0.4341 - val_recall: 0.4307\n",
            "Epoch 448/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4787 - accuracy: 0.8077 - precision: 0.8304 - recall: 0.7905 - val_loss: 2.6928 - val_accuracy: 0.4467 - val_precision: 0.4501 - val_recall: 0.4453\n",
            "Epoch 449/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4630 - accuracy: 0.7991 - precision: 0.8179 - recall: 0.7790 - val_loss: 2.4342 - val_accuracy: 0.4440 - val_precision: 0.4444 - val_recall: 0.4373\n",
            "Epoch 450/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4612 - accuracy: 0.8082 - precision: 0.8260 - recall: 0.7882 - val_loss: 2.7278 - val_accuracy: 0.3987 - val_precision: 0.4000 - val_recall: 0.3920\n",
            "Epoch 451/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4684 - accuracy: 0.8071 - precision: 0.8188 - recall: 0.7813 - val_loss: 2.5680 - val_accuracy: 0.4160 - val_precision: 0.4171 - val_recall: 0.4027\n",
            "Epoch 452/1000\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.4807 - accuracy: 0.8071 - precision: 0.8212 - recall: 0.7859 - val_loss: 2.5998 - val_accuracy: 0.4360 - val_precision: 0.4363 - val_recall: 0.4293\n",
            "Epoch 453/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5071 - accuracy: 0.7894 - precision: 0.8081 - recall: 0.7665 - val_loss: 2.7100 - val_accuracy: 0.4227 - val_precision: 0.4247 - val_recall: 0.4213\n",
            "Epoch 454/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5036 - accuracy: 0.8019 - precision: 0.8198 - recall: 0.7762 - val_loss: 2.7980 - val_accuracy: 0.4027 - val_precision: 0.3978 - val_recall: 0.3867\n",
            "Epoch 455/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4730 - accuracy: 0.8077 - precision: 0.8238 - recall: 0.7871 - val_loss: 2.6437 - val_accuracy: 0.4440 - val_precision: 0.4462 - val_recall: 0.4427\n",
            "Epoch 456/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4916 - accuracy: 0.8094 - precision: 0.8235 - recall: 0.7853 - val_loss: 2.6770 - val_accuracy: 0.4280 - val_precision: 0.4322 - val_recall: 0.4253\n",
            "Epoch 457/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4914 - accuracy: 0.7951 - precision: 0.8087 - recall: 0.7745 - val_loss: 2.9222 - val_accuracy: 0.3960 - val_precision: 0.3973 - val_recall: 0.3920\n",
            "Epoch 458/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4979 - accuracy: 0.7894 - precision: 0.8140 - recall: 0.7613 - val_loss: 2.7709 - val_accuracy: 0.4040 - val_precision: 0.4049 - val_recall: 0.4000\n",
            "Epoch 459/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5018 - accuracy: 0.7836 - precision: 0.8055 - recall: 0.7584 - val_loss: 2.7227 - val_accuracy: 0.4533 - val_precision: 0.4566 - val_recall: 0.4493\n",
            "Epoch 460/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4750 - accuracy: 0.8060 - precision: 0.8239 - recall: 0.7819 - val_loss: 2.8506 - val_accuracy: 0.4507 - val_precision: 0.4526 - val_recall: 0.4453\n",
            "Epoch 461/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4950 - accuracy: 0.7968 - precision: 0.8190 - recall: 0.7693 - val_loss: 3.1116 - val_accuracy: 0.4427 - val_precision: 0.4431 - val_recall: 0.4360\n",
            "Epoch 462/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4996 - accuracy: 0.7802 - precision: 0.8001 - recall: 0.7562 - val_loss: 3.4196 - val_accuracy: 0.3973 - val_precision: 0.3951 - val_recall: 0.3893\n",
            "Epoch 463/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4958 - accuracy: 0.7951 - precision: 0.8110 - recall: 0.7739 - val_loss: 3.1934 - val_accuracy: 0.4120 - val_precision: 0.4114 - val_recall: 0.4053\n",
            "Epoch 464/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4732 - accuracy: 0.8025 - precision: 0.8256 - recall: 0.7802 - val_loss: 3.2381 - val_accuracy: 0.4280 - val_precision: 0.4307 - val_recall: 0.4227\n",
            "Epoch 465/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5210 - accuracy: 0.7922 - precision: 0.8166 - recall: 0.7699 - val_loss: 3.2986 - val_accuracy: 0.4280 - val_precision: 0.4280 - val_recall: 0.4200\n",
            "Epoch 466/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4932 - accuracy: 0.7762 - precision: 0.7994 - recall: 0.7573 - val_loss: 3.1344 - val_accuracy: 0.4240 - val_precision: 0.4263 - val_recall: 0.4200\n",
            "Epoch 467/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5070 - accuracy: 0.7968 - precision: 0.8176 - recall: 0.7722 - val_loss: 3.4057 - val_accuracy: 0.3973 - val_precision: 0.3992 - val_recall: 0.3960\n",
            "Epoch 468/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4941 - accuracy: 0.7836 - precision: 0.8077 - recall: 0.7596 - val_loss: 3.7666 - val_accuracy: 0.3800 - val_precision: 0.3812 - val_recall: 0.3787\n",
            "Epoch 469/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5029 - accuracy: 0.7894 - precision: 0.8136 - recall: 0.7619 - val_loss: 3.6065 - val_accuracy: 0.3800 - val_precision: 0.3814 - val_recall: 0.3773\n",
            "Epoch 470/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4907 - accuracy: 0.7979 - precision: 0.8192 - recall: 0.7728 - val_loss: 3.5682 - val_accuracy: 0.3787 - val_precision: 0.3801 - val_recall: 0.3760\n",
            "Epoch 471/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5165 - accuracy: 0.7939 - precision: 0.8106 - recall: 0.7693 - val_loss: 3.0921 - val_accuracy: 0.4040 - val_precision: 0.4032 - val_recall: 0.4000\n",
            "Epoch 472/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5050 - accuracy: 0.7773 - precision: 0.7976 - recall: 0.7533 - val_loss: 3.2141 - val_accuracy: 0.3747 - val_precision: 0.3782 - val_recall: 0.3747\n",
            "Epoch 473/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4948 - accuracy: 0.8031 - precision: 0.8212 - recall: 0.7756 - val_loss: 3.5156 - val_accuracy: 0.3533 - val_precision: 0.3559 - val_recall: 0.3507\n",
            "Epoch 474/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4994 - accuracy: 0.7819 - precision: 0.7913 - recall: 0.7619 - val_loss: 3.4319 - val_accuracy: 0.3587 - val_precision: 0.3602 - val_recall: 0.3520\n",
            "Epoch 475/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5370 - accuracy: 0.7739 - precision: 0.7938 - recall: 0.7447 - val_loss: 3.3445 - val_accuracy: 0.3693 - val_precision: 0.3694 - val_recall: 0.3640\n",
            "Epoch 476/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.5340 - accuracy: 0.7808 - precision: 0.8067 - recall: 0.7573 - val_loss: 3.1682 - val_accuracy: 0.3680 - val_precision: 0.3721 - val_recall: 0.3587\n",
            "Epoch 477/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.5118 - accuracy: 0.7962 - precision: 0.8127 - recall: 0.7699 - val_loss: 2.6364 - val_accuracy: 0.3920 - val_precision: 0.3937 - val_recall: 0.3853\n",
            "Epoch 478/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.4752 - accuracy: 0.7985 - precision: 0.8165 - recall: 0.7768 - val_loss: 2.7521 - val_accuracy: 0.3933 - val_precision: 0.3978 - val_recall: 0.3893\n",
            "Epoch 479/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4915 - accuracy: 0.7991 - precision: 0.8170 - recall: 0.7768 - val_loss: 2.6191 - val_accuracy: 0.4147 - val_precision: 0.4154 - val_recall: 0.3960\n",
            "Epoch 480/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.5153 - accuracy: 0.7916 - precision: 0.8112 - recall: 0.7624 - val_loss: 2.9841 - val_accuracy: 0.3840 - val_precision: 0.3903 - val_recall: 0.3773\n",
            "Epoch 481/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4725 - accuracy: 0.8037 - precision: 0.8220 - recall: 0.7825 - val_loss: 2.8968 - val_accuracy: 0.4187 - val_precision: 0.4243 - val_recall: 0.4187\n",
            "Epoch 482/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4871 - accuracy: 0.7956 - precision: 0.8117 - recall: 0.7676 - val_loss: 2.7417 - val_accuracy: 0.4093 - val_precision: 0.4135 - val_recall: 0.4013\n",
            "Epoch 483/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4741 - accuracy: 0.7974 - precision: 0.8158 - recall: 0.7756 - val_loss: 2.8061 - val_accuracy: 0.4173 - val_precision: 0.4203 - val_recall: 0.4147\n",
            "Epoch 484/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4740 - accuracy: 0.8100 - precision: 0.8322 - recall: 0.7922 - val_loss: 2.7002 - val_accuracy: 0.4160 - val_precision: 0.4179 - val_recall: 0.4107\n",
            "Epoch 485/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4705 - accuracy: 0.8082 - precision: 0.8262 - recall: 0.7836 - val_loss: 2.9238 - val_accuracy: 0.3920 - val_precision: 0.3909 - val_recall: 0.3800\n",
            "Epoch 486/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4557 - accuracy: 0.8025 - precision: 0.8131 - recall: 0.7842 - val_loss: 3.0305 - val_accuracy: 0.3827 - val_precision: 0.3872 - val_recall: 0.3800\n",
            "Epoch 487/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4922 - accuracy: 0.8014 - precision: 0.8179 - recall: 0.7739 - val_loss: 3.1187 - val_accuracy: 0.3880 - val_precision: 0.3937 - val_recall: 0.3853\n",
            "Epoch 488/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4696 - accuracy: 0.7945 - precision: 0.8123 - recall: 0.7682 - val_loss: 3.0565 - val_accuracy: 0.4053 - val_precision: 0.4089 - val_recall: 0.4040\n",
            "Epoch 489/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4905 - accuracy: 0.8002 - precision: 0.8183 - recall: 0.7762 - val_loss: 3.0849 - val_accuracy: 0.4053 - val_precision: 0.4106 - val_recall: 0.4040\n",
            "Epoch 490/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5191 - accuracy: 0.7871 - precision: 0.8058 - recall: 0.7647 - val_loss: 2.7535 - val_accuracy: 0.4253 - val_precision: 0.4290 - val_recall: 0.4187\n",
            "Epoch 491/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4686 - accuracy: 0.8065 - precision: 0.8279 - recall: 0.7790 - val_loss: 2.8115 - val_accuracy: 0.4053 - val_precision: 0.4096 - val_recall: 0.3987\n",
            "Epoch 492/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4740 - accuracy: 0.8048 - precision: 0.8207 - recall: 0.7756 - val_loss: 2.8833 - val_accuracy: 0.4133 - val_precision: 0.4162 - val_recall: 0.4107\n",
            "Epoch 493/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4681 - accuracy: 0.7997 - precision: 0.8214 - recall: 0.7768 - val_loss: 2.9758 - val_accuracy: 0.4293 - val_precision: 0.4291 - val_recall: 0.4240\n",
            "Epoch 494/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4711 - accuracy: 0.8077 - precision: 0.8281 - recall: 0.7831 - val_loss: 2.8390 - val_accuracy: 0.4240 - val_precision: 0.4299 - val_recall: 0.4213\n",
            "Epoch 495/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4840 - accuracy: 0.7974 - precision: 0.8167 - recall: 0.7779 - val_loss: 3.1285 - val_accuracy: 0.3960 - val_precision: 0.4041 - val_recall: 0.3960\n",
            "Epoch 496/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4905 - accuracy: 0.7997 - precision: 0.8161 - recall: 0.7722 - val_loss: 3.3870 - val_accuracy: 0.3933 - val_precision: 0.3968 - val_recall: 0.3920\n",
            "Epoch 497/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4491 - accuracy: 0.8191 - precision: 0.8373 - recall: 0.7951 - val_loss: 2.8488 - val_accuracy: 0.4373 - val_precision: 0.4398 - val_recall: 0.4333\n",
            "Epoch 498/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4913 - accuracy: 0.7865 - precision: 0.8031 - recall: 0.7613 - val_loss: 2.9008 - val_accuracy: 0.4400 - val_precision: 0.4453 - val_recall: 0.4400\n",
            "Epoch 499/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4926 - accuracy: 0.7768 - precision: 0.7937 - recall: 0.7464 - val_loss: 3.0806 - val_accuracy: 0.4440 - val_precision: 0.4416 - val_recall: 0.4387\n",
            "Epoch 500/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4853 - accuracy: 0.8077 - precision: 0.8237 - recall: 0.7785 - val_loss: 3.4144 - val_accuracy: 0.3827 - val_precision: 0.3820 - val_recall: 0.3800\n",
            "Epoch 501/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4827 - accuracy: 0.8054 - precision: 0.8186 - recall: 0.7825 - val_loss: 3.2285 - val_accuracy: 0.4227 - val_precision: 0.4217 - val_recall: 0.4200\n",
            "Epoch 502/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4697 - accuracy: 0.8042 - precision: 0.8243 - recall: 0.7871 - val_loss: 3.1593 - val_accuracy: 0.4107 - val_precision: 0.4126 - val_recall: 0.4093\n",
            "Epoch 503/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4892 - accuracy: 0.7882 - precision: 0.8043 - recall: 0.7647 - val_loss: 3.3893 - val_accuracy: 0.3773 - val_precision: 0.3787 - val_recall: 0.3747\n",
            "Epoch 504/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4908 - accuracy: 0.7956 - precision: 0.8096 - recall: 0.7762 - val_loss: 3.6509 - val_accuracy: 0.3653 - val_precision: 0.3655 - val_recall: 0.3640\n",
            "Epoch 505/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4523 - accuracy: 0.8140 - precision: 0.8315 - recall: 0.7911 - val_loss: 3.4565 - val_accuracy: 0.3760 - val_precision: 0.3848 - val_recall: 0.3720\n",
            "Epoch 506/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4937 - accuracy: 0.7945 - precision: 0.8129 - recall: 0.7733 - val_loss: 3.2972 - val_accuracy: 0.3800 - val_precision: 0.3825 - val_recall: 0.3733\n",
            "Epoch 507/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4809 - accuracy: 0.7876 - precision: 0.8045 - recall: 0.7607 - val_loss: 3.2392 - val_accuracy: 0.3773 - val_precision: 0.3792 - val_recall: 0.3747\n",
            "Epoch 508/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4799 - accuracy: 0.8054 - precision: 0.8192 - recall: 0.7779 - val_loss: 3.1208 - val_accuracy: 0.3987 - val_precision: 0.4011 - val_recall: 0.3947\n",
            "Epoch 509/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4915 - accuracy: 0.7894 - precision: 0.8084 - recall: 0.7607 - val_loss: 3.2836 - val_accuracy: 0.3933 - val_precision: 0.3944 - val_recall: 0.3933\n",
            "Epoch 510/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5138 - accuracy: 0.7911 - precision: 0.8094 - recall: 0.7682 - val_loss: 3.3066 - val_accuracy: 0.3987 - val_precision: 0.4000 - val_recall: 0.3973\n",
            "Epoch 511/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4722 - accuracy: 0.8082 - precision: 0.8261 - recall: 0.7831 - val_loss: 3.3642 - val_accuracy: 0.3960 - val_precision: 0.3957 - val_recall: 0.3947\n",
            "Epoch 512/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4594 - accuracy: 0.8128 - precision: 0.8236 - recall: 0.7882 - val_loss: 3.3784 - val_accuracy: 0.3813 - val_precision: 0.3814 - val_recall: 0.3773\n",
            "Epoch 513/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4861 - accuracy: 0.8037 - precision: 0.8162 - recall: 0.7750 - val_loss: 2.9442 - val_accuracy: 0.4347 - val_precision: 0.4380 - val_recall: 0.4333\n",
            "Epoch 514/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4849 - accuracy: 0.8008 - precision: 0.8173 - recall: 0.7785 - val_loss: 3.5344 - val_accuracy: 0.3813 - val_precision: 0.3818 - val_recall: 0.3747\n",
            "Epoch 515/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4881 - accuracy: 0.7968 - precision: 0.8188 - recall: 0.7785 - val_loss: 3.3117 - val_accuracy: 0.3787 - val_precision: 0.3826 - val_recall: 0.3760\n",
            "Epoch 516/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4732 - accuracy: 0.8019 - precision: 0.8224 - recall: 0.7819 - val_loss: 2.8128 - val_accuracy: 0.4373 - val_precision: 0.4381 - val_recall: 0.4293\n",
            "Epoch 517/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5044 - accuracy: 0.7882 - precision: 0.8013 - recall: 0.7573 - val_loss: 3.0178 - val_accuracy: 0.4093 - val_precision: 0.4083 - val_recall: 0.4067\n",
            "Epoch 518/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5132 - accuracy: 0.8008 - precision: 0.8160 - recall: 0.7716 - val_loss: 3.0874 - val_accuracy: 0.3720 - val_precision: 0.3757 - val_recall: 0.3707\n",
            "Epoch 519/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5360 - accuracy: 0.7682 - precision: 0.7899 - recall: 0.7447 - val_loss: 3.3056 - val_accuracy: 0.3933 - val_precision: 0.3970 - val_recall: 0.3907\n",
            "Epoch 520/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5065 - accuracy: 0.7939 - precision: 0.8156 - recall: 0.7619 - val_loss: 3.0093 - val_accuracy: 0.4093 - val_precision: 0.4144 - val_recall: 0.4067\n",
            "Epoch 521/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5178 - accuracy: 0.7842 - precision: 0.8055 - recall: 0.7562 - val_loss: 2.8019 - val_accuracy: 0.4200 - val_precision: 0.4237 - val_recall: 0.4147\n",
            "Epoch 522/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5221 - accuracy: 0.7733 - precision: 0.7908 - recall: 0.7487 - val_loss: 3.2392 - val_accuracy: 0.3627 - val_precision: 0.3651 - val_recall: 0.3573\n",
            "Epoch 523/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5307 - accuracy: 0.7733 - precision: 0.7999 - recall: 0.7504 - val_loss: 3.3229 - val_accuracy: 0.3667 - val_precision: 0.3718 - val_recall: 0.3653\n",
            "Epoch 524/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5248 - accuracy: 0.7750 - precision: 0.7976 - recall: 0.7464 - val_loss: 2.8575 - val_accuracy: 0.3827 - val_precision: 0.3874 - val_recall: 0.3760\n",
            "Epoch 525/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5069 - accuracy: 0.7911 - precision: 0.8114 - recall: 0.7636 - val_loss: 3.1829 - val_accuracy: 0.3653 - val_precision: 0.3691 - val_recall: 0.3533\n",
            "Epoch 526/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5187 - accuracy: 0.7819 - precision: 0.7973 - recall: 0.7521 - val_loss: 2.9883 - val_accuracy: 0.3893 - val_precision: 0.3907 - val_recall: 0.3813\n",
            "Epoch 527/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.7951 - precision: 0.8114 - recall: 0.7710 - val_loss: 2.4888 - val_accuracy: 0.4373 - val_precision: 0.4410 - val_recall: 0.4333\n",
            "Epoch 528/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4901 - accuracy: 0.7974 - precision: 0.8136 - recall: 0.7693 - val_loss: 2.7442 - val_accuracy: 0.4320 - val_precision: 0.4355 - val_recall: 0.4320\n",
            "Epoch 529/1000\n",
            "55/55 [==============================] - 0s 6ms/step - loss: 0.5037 - accuracy: 0.7882 - precision: 0.8105 - recall: 0.7590 - val_loss: 2.6077 - val_accuracy: 0.4747 - val_precision: 0.4777 - val_recall: 0.4707\n",
            "Epoch 530/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5124 - accuracy: 0.7899 - precision: 0.8070 - recall: 0.7659 - val_loss: 2.9882 - val_accuracy: 0.4253 - val_precision: 0.4266 - val_recall: 0.4227\n",
            "Epoch 531/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4948 - accuracy: 0.7853 - precision: 0.8056 - recall: 0.7544 - val_loss: 2.5639 - val_accuracy: 0.4427 - val_precision: 0.4465 - val_recall: 0.4400\n",
            "Epoch 532/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.5259 - accuracy: 0.7888 - precision: 0.8099 - recall: 0.7562 - val_loss: 2.6098 - val_accuracy: 0.4360 - val_precision: 0.4441 - val_recall: 0.4347\n",
            "Epoch 533/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4798 - accuracy: 0.8111 - precision: 0.8257 - recall: 0.7894 - val_loss: 2.9459 - val_accuracy: 0.4413 - val_precision: 0.4438 - val_recall: 0.4373\n",
            "Epoch 534/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4703 - accuracy: 0.8100 - precision: 0.8268 - recall: 0.7842 - val_loss: 2.7129 - val_accuracy: 0.4640 - val_precision: 0.4687 - val_recall: 0.4587\n",
            "Epoch 535/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4602 - accuracy: 0.8071 - precision: 0.8272 - recall: 0.7836 - val_loss: 2.5178 - val_accuracy: 0.4760 - val_precision: 0.4809 - val_recall: 0.4707\n",
            "Epoch 536/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4950 - accuracy: 0.7956 - precision: 0.8152 - recall: 0.7699 - val_loss: 2.8800 - val_accuracy: 0.4520 - val_precision: 0.4527 - val_recall: 0.4467\n",
            "Epoch 537/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4856 - accuracy: 0.8008 - precision: 0.8227 - recall: 0.7785 - val_loss: 2.9864 - val_accuracy: 0.4093 - val_precision: 0.4100 - val_recall: 0.4040\n",
            "Epoch 538/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4673 - accuracy: 0.8071 - precision: 0.8268 - recall: 0.7899 - val_loss: 3.1905 - val_accuracy: 0.3880 - val_precision: 0.3870 - val_recall: 0.3813\n",
            "Epoch 539/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4813 - accuracy: 0.8157 - precision: 0.8351 - recall: 0.7853 - val_loss: 2.9415 - val_accuracy: 0.4267 - val_precision: 0.4290 - val_recall: 0.4227\n",
            "Epoch 540/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4828 - accuracy: 0.8042 - precision: 0.8179 - recall: 0.7790 - val_loss: 2.9597 - val_accuracy: 0.4360 - val_precision: 0.4398 - val_recall: 0.4333\n",
            "Epoch 541/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4790 - accuracy: 0.7882 - precision: 0.8053 - recall: 0.7647 - val_loss: 3.0484 - val_accuracy: 0.4133 - val_precision: 0.4174 - val_recall: 0.4040\n",
            "Epoch 542/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5182 - accuracy: 0.7859 - precision: 0.8019 - recall: 0.7579 - val_loss: 3.0990 - val_accuracy: 0.4080 - val_precision: 0.4082 - val_recall: 0.3973\n",
            "Epoch 543/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5015 - accuracy: 0.7962 - precision: 0.8135 - recall: 0.7642 - val_loss: 2.9564 - val_accuracy: 0.4067 - val_precision: 0.4074 - val_recall: 0.3960\n",
            "Epoch 544/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4956 - accuracy: 0.8048 - precision: 0.8206 - recall: 0.7802 - val_loss: 2.9947 - val_accuracy: 0.4120 - val_precision: 0.4100 - val_recall: 0.4040\n",
            "Epoch 545/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4839 - accuracy: 0.8031 - precision: 0.8211 - recall: 0.7750 - val_loss: 3.1514 - val_accuracy: 0.4067 - val_precision: 0.4082 - val_recall: 0.4000\n",
            "Epoch 546/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4976 - accuracy: 0.7974 - precision: 0.8194 - recall: 0.7768 - val_loss: 2.8943 - val_accuracy: 0.4307 - val_precision: 0.4344 - val_recall: 0.4240\n",
            "Epoch 547/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4552 - accuracy: 0.8105 - precision: 0.8282 - recall: 0.7922 - val_loss: 2.6855 - val_accuracy: 0.4653 - val_precision: 0.4702 - val_recall: 0.4627\n",
            "Epoch 548/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4528 - accuracy: 0.8203 - precision: 0.8353 - recall: 0.7956 - val_loss: 2.7395 - val_accuracy: 0.4587 - val_precision: 0.4623 - val_recall: 0.4573\n",
            "Epoch 549/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4927 - accuracy: 0.7899 - precision: 0.8112 - recall: 0.7647 - val_loss: 2.7518 - val_accuracy: 0.4187 - val_precision: 0.4231 - val_recall: 0.4147\n",
            "Epoch 550/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4904 - accuracy: 0.7928 - precision: 0.8133 - recall: 0.7756 - val_loss: 2.5895 - val_accuracy: 0.4640 - val_precision: 0.4674 - val_recall: 0.4587\n",
            "Epoch 551/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4501 - accuracy: 0.8065 - precision: 0.8265 - recall: 0.7853 - val_loss: 2.7682 - val_accuracy: 0.4467 - val_precision: 0.4514 - val_recall: 0.4453\n",
            "Epoch 552/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5005 - accuracy: 0.8031 - precision: 0.8239 - recall: 0.7819 - val_loss: 2.4331 - val_accuracy: 0.4840 - val_precision: 0.4918 - val_recall: 0.4813\n",
            "Epoch 553/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4738 - accuracy: 0.8002 - precision: 0.8194 - recall: 0.7739 - val_loss: 2.5597 - val_accuracy: 0.4667 - val_precision: 0.4681 - val_recall: 0.4600\n",
            "Epoch 554/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4626 - accuracy: 0.8105 - precision: 0.8277 - recall: 0.7894 - val_loss: 2.6532 - val_accuracy: 0.4600 - val_precision: 0.4627 - val_recall: 0.4547\n",
            "Epoch 555/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4657 - accuracy: 0.8060 - precision: 0.8177 - recall: 0.7859 - val_loss: 2.8121 - val_accuracy: 0.4693 - val_precision: 0.4711 - val_recall: 0.4680\n",
            "Epoch 556/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4608 - accuracy: 0.7997 - precision: 0.8192 - recall: 0.7808 - val_loss: 2.8612 - val_accuracy: 0.4907 - val_precision: 0.4933 - val_recall: 0.4893\n",
            "Epoch 557/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4913 - accuracy: 0.7905 - precision: 0.8098 - recall: 0.7750 - val_loss: 2.7062 - val_accuracy: 0.4800 - val_precision: 0.4837 - val_recall: 0.4760\n",
            "Epoch 558/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4822 - accuracy: 0.8077 - precision: 0.8226 - recall: 0.7779 - val_loss: 2.8113 - val_accuracy: 0.4413 - val_precision: 0.4475 - val_recall: 0.4373\n",
            "Epoch 559/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4738 - accuracy: 0.8008 - precision: 0.8189 - recall: 0.7768 - val_loss: 3.1514 - val_accuracy: 0.4560 - val_precision: 0.4577 - val_recall: 0.4547\n",
            "Epoch 560/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4691 - accuracy: 0.7945 - precision: 0.8150 - recall: 0.7819 - val_loss: 2.7449 - val_accuracy: 0.4427 - val_precision: 0.4453 - val_recall: 0.4400\n",
            "Epoch 561/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4712 - accuracy: 0.8100 - precision: 0.8258 - recall: 0.7813 - val_loss: 2.4619 - val_accuracy: 0.4840 - val_precision: 0.4871 - val_recall: 0.4800\n",
            "Epoch 562/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4742 - accuracy: 0.8180 - precision: 0.8324 - recall: 0.7962 - val_loss: 2.5178 - val_accuracy: 0.4640 - val_precision: 0.4719 - val_recall: 0.4587\n",
            "Epoch 563/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4464 - accuracy: 0.8163 - precision: 0.8339 - recall: 0.7962 - val_loss: 2.5351 - val_accuracy: 0.4680 - val_precision: 0.4715 - val_recall: 0.4627\n",
            "Epoch 564/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.5000 - accuracy: 0.7951 - precision: 0.8143 - recall: 0.7733 - val_loss: 2.6856 - val_accuracy: 0.4653 - val_precision: 0.4665 - val_recall: 0.4640\n",
            "Epoch 565/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5190 - accuracy: 0.7956 - precision: 0.8109 - recall: 0.7636 - val_loss: 2.4754 - val_accuracy: 0.4773 - val_precision: 0.4784 - val_recall: 0.4733\n",
            "Epoch 566/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4493 - accuracy: 0.8100 - precision: 0.8278 - recall: 0.7813 - val_loss: 2.6062 - val_accuracy: 0.4653 - val_precision: 0.4685 - val_recall: 0.4653\n",
            "Epoch 567/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4776 - accuracy: 0.7991 - precision: 0.8177 - recall: 0.7831 - val_loss: 2.5423 - val_accuracy: 0.4667 - val_precision: 0.4722 - val_recall: 0.4640\n",
            "Epoch 568/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4652 - accuracy: 0.8008 - precision: 0.8241 - recall: 0.7802 - val_loss: 2.5884 - val_accuracy: 0.4800 - val_precision: 0.4831 - val_recall: 0.4760\n",
            "Epoch 569/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4926 - accuracy: 0.7871 - precision: 0.8053 - recall: 0.7624 - val_loss: 2.5001 - val_accuracy: 0.4787 - val_precision: 0.4837 - val_recall: 0.4760\n",
            "Epoch 570/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4677 - accuracy: 0.8071 - precision: 0.8223 - recall: 0.7865 - val_loss: 2.5018 - val_accuracy: 0.4853 - val_precision: 0.4885 - val_recall: 0.4800\n",
            "Epoch 571/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4645 - accuracy: 0.8168 - precision: 0.8345 - recall: 0.7968 - val_loss: 2.6985 - val_accuracy: 0.4880 - val_precision: 0.4879 - val_recall: 0.4827\n",
            "Epoch 572/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4952 - accuracy: 0.8100 - precision: 0.8293 - recall: 0.7899 - val_loss: 2.5627 - val_accuracy: 0.4760 - val_precision: 0.4764 - val_recall: 0.4720\n",
            "Epoch 573/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4630 - accuracy: 0.8048 - precision: 0.8225 - recall: 0.7773 - val_loss: 2.7453 - val_accuracy: 0.4907 - val_precision: 0.4892 - val_recall: 0.4853\n",
            "Epoch 574/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4781 - accuracy: 0.8134 - precision: 0.8297 - recall: 0.7894 - val_loss: 2.6103 - val_accuracy: 0.4827 - val_precision: 0.4826 - val_recall: 0.4800\n",
            "Epoch 575/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4519 - accuracy: 0.8105 - precision: 0.8280 - recall: 0.7825 - val_loss: 2.6955 - val_accuracy: 0.4747 - val_precision: 0.4785 - val_recall: 0.4747\n",
            "Epoch 576/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4958 - accuracy: 0.7905 - precision: 0.8099 - recall: 0.7659 - val_loss: 2.7395 - val_accuracy: 0.4600 - val_precision: 0.4611 - val_recall: 0.4587\n",
            "Epoch 577/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4859 - accuracy: 0.8071 - precision: 0.8261 - recall: 0.7831 - val_loss: 2.9419 - val_accuracy: 0.4720 - val_precision: 0.4726 - val_recall: 0.4707\n",
            "Epoch 578/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4899 - accuracy: 0.7905 - precision: 0.8120 - recall: 0.7716 - val_loss: 2.6847 - val_accuracy: 0.4667 - val_precision: 0.4714 - val_recall: 0.4613\n",
            "Epoch 579/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4788 - accuracy: 0.8054 - precision: 0.8238 - recall: 0.7762 - val_loss: 2.7496 - val_accuracy: 0.4840 - val_precision: 0.4866 - val_recall: 0.4840\n",
            "Epoch 580/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4695 - accuracy: 0.8037 - precision: 0.8186 - recall: 0.7876 - val_loss: 2.7028 - val_accuracy: 0.4773 - val_precision: 0.4759 - val_recall: 0.4733\n",
            "Epoch 581/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4533 - accuracy: 0.8157 - precision: 0.8333 - recall: 0.7928 - val_loss: 2.7000 - val_accuracy: 0.4733 - val_precision: 0.4738 - val_recall: 0.4707\n",
            "Epoch 582/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4680 - accuracy: 0.8128 - precision: 0.8344 - recall: 0.7962 - val_loss: 2.7141 - val_accuracy: 0.4827 - val_precision: 0.4832 - val_recall: 0.4800\n",
            "Epoch 583/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4875 - accuracy: 0.7991 - precision: 0.8107 - recall: 0.7722 - val_loss: 2.6429 - val_accuracy: 0.4893 - val_precision: 0.4919 - val_recall: 0.4880\n",
            "Epoch 584/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4683 - accuracy: 0.8122 - precision: 0.8280 - recall: 0.7934 - val_loss: 2.6592 - val_accuracy: 0.4720 - val_precision: 0.4744 - val_recall: 0.4693\n",
            "Epoch 585/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4712 - accuracy: 0.7997 - precision: 0.8187 - recall: 0.7831 - val_loss: 2.7621 - val_accuracy: 0.4480 - val_precision: 0.4497 - val_recall: 0.4467\n",
            "Epoch 586/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4605 - accuracy: 0.8128 - precision: 0.8305 - recall: 0.7939 - val_loss: 2.6168 - val_accuracy: 0.4760 - val_precision: 0.4791 - val_recall: 0.4733\n",
            "Epoch 587/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4720 - accuracy: 0.8054 - precision: 0.8201 - recall: 0.7802 - val_loss: 2.4360 - val_accuracy: 0.4680 - val_precision: 0.4728 - val_recall: 0.4627\n",
            "Epoch 588/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4673 - accuracy: 0.8105 - precision: 0.8287 - recall: 0.7865 - val_loss: 2.5338 - val_accuracy: 0.4787 - val_precision: 0.4791 - val_recall: 0.4747\n",
            "Epoch 589/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4757 - accuracy: 0.8008 - precision: 0.8167 - recall: 0.7831 - val_loss: 2.5512 - val_accuracy: 0.4800 - val_precision: 0.4793 - val_recall: 0.4773\n",
            "Epoch 590/1000\n",
            "55/55 [==============================] - 1s 13ms/step - loss: 0.4925 - accuracy: 0.7813 - precision: 0.8013 - recall: 0.7619 - val_loss: 2.4426 - val_accuracy: 0.4773 - val_precision: 0.4798 - val_recall: 0.4760\n",
            "Epoch 591/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4759 - accuracy: 0.7956 - precision: 0.8114 - recall: 0.7733 - val_loss: 2.5171 - val_accuracy: 0.4787 - val_precision: 0.4798 - val_recall: 0.4747\n",
            "Epoch 592/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4883 - accuracy: 0.7882 - precision: 0.8052 - recall: 0.7665 - val_loss: 2.6369 - val_accuracy: 0.4693 - val_precision: 0.4736 - val_recall: 0.4667\n",
            "Epoch 593/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4557 - accuracy: 0.8071 - precision: 0.8242 - recall: 0.7865 - val_loss: 2.4220 - val_accuracy: 0.4693 - val_precision: 0.4714 - val_recall: 0.4613\n",
            "Epoch 594/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4723 - accuracy: 0.8082 - precision: 0.8255 - recall: 0.7853 - val_loss: 2.5326 - val_accuracy: 0.4733 - val_precision: 0.4788 - val_recall: 0.4667\n",
            "Epoch 595/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4953 - accuracy: 0.7968 - precision: 0.8091 - recall: 0.7762 - val_loss: 2.9818 - val_accuracy: 0.4467 - val_precision: 0.4486 - val_recall: 0.4427\n",
            "Epoch 596/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.5043 - accuracy: 0.7831 - precision: 0.7994 - recall: 0.7573 - val_loss: 2.9573 - val_accuracy: 0.4653 - val_precision: 0.4663 - val_recall: 0.4613\n",
            "Epoch 597/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.5187 - accuracy: 0.7865 - precision: 0.8056 - recall: 0.7544 - val_loss: 2.7962 - val_accuracy: 0.4533 - val_precision: 0.4555 - val_recall: 0.4507\n",
            "Epoch 598/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4767 - accuracy: 0.8082 - precision: 0.8226 - recall: 0.7882 - val_loss: 2.8129 - val_accuracy: 0.4493 - val_precision: 0.4509 - val_recall: 0.4467\n",
            "Epoch 599/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4915 - accuracy: 0.7945 - precision: 0.8119 - recall: 0.7710 - val_loss: 2.8934 - val_accuracy: 0.4653 - val_precision: 0.4639 - val_recall: 0.4627\n",
            "Epoch 600/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4766 - accuracy: 0.8105 - precision: 0.8306 - recall: 0.7916 - val_loss: 2.8880 - val_accuracy: 0.4573 - val_precision: 0.4558 - val_recall: 0.4533\n",
            "Epoch 601/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4756 - accuracy: 0.8042 - precision: 0.8166 - recall: 0.7848 - val_loss: 2.6514 - val_accuracy: 0.4560 - val_precision: 0.4615 - val_recall: 0.4560\n",
            "Epoch 602/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4808 - accuracy: 0.8014 - precision: 0.8230 - recall: 0.7773 - val_loss: 2.3339 - val_accuracy: 0.4933 - val_precision: 0.4946 - val_recall: 0.4893\n",
            "Epoch 603/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5169 - accuracy: 0.7762 - precision: 0.7971 - recall: 0.7487 - val_loss: 2.3108 - val_accuracy: 0.4867 - val_precision: 0.4858 - val_recall: 0.4787\n",
            "Epoch 604/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5346 - accuracy: 0.7705 - precision: 0.7893 - recall: 0.7418 - val_loss: 2.1841 - val_accuracy: 0.4907 - val_precision: 0.4959 - val_recall: 0.4893\n",
            "Epoch 605/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5263 - accuracy: 0.7762 - precision: 0.7950 - recall: 0.7481 - val_loss: 2.4641 - val_accuracy: 0.4707 - val_precision: 0.4744 - val_recall: 0.4693\n",
            "Epoch 606/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5078 - accuracy: 0.7819 - precision: 0.8031 - recall: 0.7636 - val_loss: 2.4407 - val_accuracy: 0.5000 - val_precision: 0.5027 - val_recall: 0.4987\n",
            "Epoch 607/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4727 - accuracy: 0.8037 - precision: 0.8264 - recall: 0.7768 - val_loss: 2.6412 - val_accuracy: 0.4373 - val_precision: 0.4404 - val_recall: 0.4333\n",
            "Epoch 608/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4925 - accuracy: 0.7997 - precision: 0.8178 - recall: 0.7836 - val_loss: 2.3079 - val_accuracy: 0.4640 - val_precision: 0.4688 - val_recall: 0.4600\n",
            "Epoch 609/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5062 - accuracy: 0.7894 - precision: 0.8045 - recall: 0.7630 - val_loss: 2.2587 - val_accuracy: 0.4773 - val_precision: 0.4796 - val_recall: 0.4693\n",
            "Epoch 610/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4902 - accuracy: 0.8094 - precision: 0.8221 - recall: 0.7831 - val_loss: 2.4142 - val_accuracy: 0.4733 - val_precision: 0.4771 - val_recall: 0.4720\n",
            "Epoch 611/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5017 - accuracy: 0.7894 - precision: 0.8100 - recall: 0.7665 - val_loss: 2.4967 - val_accuracy: 0.4640 - val_precision: 0.4670 - val_recall: 0.4627\n",
            "Epoch 612/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4933 - accuracy: 0.8037 - precision: 0.8239 - recall: 0.7848 - val_loss: 2.3351 - val_accuracy: 0.4667 - val_precision: 0.4690 - val_recall: 0.4640\n",
            "Epoch 613/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4630 - accuracy: 0.8054 - precision: 0.8220 - recall: 0.7825 - val_loss: 2.4511 - val_accuracy: 0.4787 - val_precision: 0.4792 - val_recall: 0.4760\n",
            "Epoch 614/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4640 - accuracy: 0.8082 - precision: 0.8261 - recall: 0.7831 - val_loss: 2.4124 - val_accuracy: 0.4773 - val_precision: 0.4791 - val_recall: 0.4747\n",
            "Epoch 615/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4793 - accuracy: 0.8060 - precision: 0.8228 - recall: 0.7842 - val_loss: 2.4441 - val_accuracy: 0.4613 - val_precision: 0.4642 - val_recall: 0.4587\n",
            "Epoch 616/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4323 - accuracy: 0.8168 - precision: 0.8310 - recall: 0.7991 - val_loss: 2.6000 - val_accuracy: 0.4560 - val_precision: 0.4625 - val_recall: 0.4520\n",
            "Epoch 617/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4554 - accuracy: 0.8088 - precision: 0.8228 - recall: 0.7842 - val_loss: 2.9119 - val_accuracy: 0.4120 - val_precision: 0.4178 - val_recall: 0.4067\n",
            "Epoch 618/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4527 - accuracy: 0.8157 - precision: 0.8302 - recall: 0.7922 - val_loss: 2.7309 - val_accuracy: 0.4347 - val_precision: 0.4399 - val_recall: 0.4293\n",
            "Epoch 619/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4628 - accuracy: 0.8100 - precision: 0.8253 - recall: 0.7842 - val_loss: 2.9633 - val_accuracy: 0.4040 - val_precision: 0.4065 - val_recall: 0.4000\n",
            "Epoch 620/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4500 - accuracy: 0.8231 - precision: 0.8384 - recall: 0.8019 - val_loss: 2.8139 - val_accuracy: 0.4253 - val_precision: 0.4356 - val_recall: 0.4240\n",
            "Epoch 621/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4546 - accuracy: 0.8145 - precision: 0.8359 - recall: 0.7934 - val_loss: 2.7689 - val_accuracy: 0.4373 - val_precision: 0.4448 - val_recall: 0.4293\n",
            "Epoch 622/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4816 - accuracy: 0.8134 - precision: 0.8299 - recall: 0.7934 - val_loss: 2.5411 - val_accuracy: 0.4387 - val_precision: 0.4465 - val_recall: 0.4227\n",
            "Epoch 623/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4736 - accuracy: 0.7968 - precision: 0.8117 - recall: 0.7796 - val_loss: 2.4774 - val_accuracy: 0.4547 - val_precision: 0.4550 - val_recall: 0.4520\n",
            "Epoch 624/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4542 - accuracy: 0.8226 - precision: 0.8398 - recall: 0.7979 - val_loss: 2.6795 - val_accuracy: 0.4360 - val_precision: 0.4399 - val_recall: 0.4347\n",
            "Epoch 625/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4557 - accuracy: 0.8122 - precision: 0.8268 - recall: 0.7899 - val_loss: 2.8617 - val_accuracy: 0.4160 - val_precision: 0.4213 - val_recall: 0.4107\n",
            "Epoch 626/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4876 - accuracy: 0.8014 - precision: 0.8185 - recall: 0.7819 - val_loss: 2.9078 - val_accuracy: 0.4067 - val_precision: 0.4082 - val_recall: 0.4000\n",
            "Epoch 627/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4575 - accuracy: 0.8237 - precision: 0.8403 - recall: 0.8014 - val_loss: 2.6219 - val_accuracy: 0.4547 - val_precision: 0.4593 - val_recall: 0.4520\n",
            "Epoch 628/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4250 - accuracy: 0.8237 - precision: 0.8410 - recall: 0.8054 - val_loss: 2.7502 - val_accuracy: 0.4560 - val_precision: 0.4570 - val_recall: 0.4533\n",
            "Epoch 629/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.4453 - accuracy: 0.8163 - precision: 0.8382 - recall: 0.7945 - val_loss: 2.7507 - val_accuracy: 0.4480 - val_precision: 0.4493 - val_recall: 0.4427\n",
            "Epoch 630/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4710 - accuracy: 0.8077 - precision: 0.8207 - recall: 0.7859 - val_loss: 2.6383 - val_accuracy: 0.4493 - val_precision: 0.4501 - val_recall: 0.4387\n",
            "Epoch 631/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4663 - accuracy: 0.8002 - precision: 0.8159 - recall: 0.7836 - val_loss: 2.6332 - val_accuracy: 0.4733 - val_precision: 0.4777 - val_recall: 0.4720\n",
            "Epoch 632/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4615 - accuracy: 0.8111 - precision: 0.8239 - recall: 0.7899 - val_loss: 2.6272 - val_accuracy: 0.4747 - val_precision: 0.4777 - val_recall: 0.4720\n",
            "Epoch 633/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4475 - accuracy: 0.8145 - precision: 0.8289 - recall: 0.7876 - val_loss: 2.7182 - val_accuracy: 0.4653 - val_precision: 0.4708 - val_recall: 0.4627\n",
            "Epoch 634/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4745 - accuracy: 0.8042 - precision: 0.8216 - recall: 0.7779 - val_loss: 2.6130 - val_accuracy: 0.4507 - val_precision: 0.4564 - val_recall: 0.4467\n",
            "Epoch 635/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4756 - accuracy: 0.8065 - precision: 0.8259 - recall: 0.7899 - val_loss: 2.5148 - val_accuracy: 0.4547 - val_precision: 0.4643 - val_recall: 0.4507\n",
            "Epoch 636/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4646 - accuracy: 0.8060 - precision: 0.8183 - recall: 0.7888 - val_loss: 3.0165 - val_accuracy: 0.4160 - val_precision: 0.4209 - val_recall: 0.4080\n",
            "Epoch 637/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4676 - accuracy: 0.7911 - precision: 0.8099 - recall: 0.7682 - val_loss: 2.7536 - val_accuracy: 0.4160 - val_precision: 0.4237 - val_recall: 0.4107\n",
            "Epoch 638/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5167 - accuracy: 0.7956 - precision: 0.8107 - recall: 0.7722 - val_loss: 2.9363 - val_accuracy: 0.4387 - val_precision: 0.4410 - val_recall: 0.4387\n",
            "Epoch 639/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4890 - accuracy: 0.7979 - precision: 0.8152 - recall: 0.7728 - val_loss: 3.0504 - val_accuracy: 0.4507 - val_precision: 0.4505 - val_recall: 0.4493\n",
            "Epoch 640/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4845 - accuracy: 0.8014 - precision: 0.8206 - recall: 0.7831 - val_loss: 2.6752 - val_accuracy: 0.4627 - val_precision: 0.4677 - val_recall: 0.4627\n",
            "Epoch 641/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4761 - accuracy: 0.7974 - precision: 0.8168 - recall: 0.7756 - val_loss: 2.7321 - val_accuracy: 0.4480 - val_precision: 0.4509 - val_recall: 0.4467\n",
            "Epoch 642/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4941 - accuracy: 0.7939 - precision: 0.8122 - recall: 0.7676 - val_loss: 2.6881 - val_accuracy: 0.4507 - val_precision: 0.4559 - val_recall: 0.4480\n",
            "Epoch 643/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4544 - accuracy: 0.8082 - precision: 0.8271 - recall: 0.7831 - val_loss: 2.7994 - val_accuracy: 0.4587 - val_precision: 0.4616 - val_recall: 0.4573\n",
            "Epoch 644/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4755 - accuracy: 0.8060 - precision: 0.8253 - recall: 0.7842 - val_loss: 2.6014 - val_accuracy: 0.4720 - val_precision: 0.4738 - val_recall: 0.4707\n",
            "Epoch 645/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4534 - accuracy: 0.8111 - precision: 0.8292 - recall: 0.7865 - val_loss: 2.6113 - val_accuracy: 0.4800 - val_precision: 0.4793 - val_recall: 0.4773\n",
            "Epoch 646/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4492 - accuracy: 0.8082 - precision: 0.8190 - recall: 0.7848 - val_loss: 2.4868 - val_accuracy: 0.4520 - val_precision: 0.4594 - val_recall: 0.4453\n",
            "Epoch 647/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4836 - accuracy: 0.8002 - precision: 0.8161 - recall: 0.7773 - val_loss: 3.1447 - val_accuracy: 0.4120 - val_precision: 0.4120 - val_recall: 0.4027\n",
            "Epoch 648/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4734 - accuracy: 0.8019 - precision: 0.8175 - recall: 0.7745 - val_loss: 2.9821 - val_accuracy: 0.4027 - val_precision: 0.4099 - val_recall: 0.3973\n",
            "Epoch 649/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4830 - accuracy: 0.7974 - precision: 0.8143 - recall: 0.7779 - val_loss: 2.8297 - val_accuracy: 0.4187 - val_precision: 0.4233 - val_recall: 0.4160\n",
            "Epoch 650/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4663 - accuracy: 0.8117 - precision: 0.8263 - recall: 0.7842 - val_loss: 2.9841 - val_accuracy: 0.4200 - val_precision: 0.4224 - val_recall: 0.4173\n",
            "Epoch 651/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5047 - accuracy: 0.7853 - precision: 0.8069 - recall: 0.7607 - val_loss: 2.7833 - val_accuracy: 0.4000 - val_precision: 0.4076 - val_recall: 0.4000\n",
            "Epoch 652/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4885 - accuracy: 0.7951 - precision: 0.8161 - recall: 0.7699 - val_loss: 2.7119 - val_accuracy: 0.4440 - val_precision: 0.4494 - val_recall: 0.4440\n",
            "Epoch 653/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5000 - accuracy: 0.7899 - precision: 0.8097 - recall: 0.7550 - val_loss: 2.6460 - val_accuracy: 0.4493 - val_precision: 0.4536 - val_recall: 0.4493\n",
            "Epoch 654/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5142 - accuracy: 0.7859 - precision: 0.7992 - recall: 0.7562 - val_loss: 2.6493 - val_accuracy: 0.4453 - val_precision: 0.4494 - val_recall: 0.4440\n",
            "Epoch 655/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5001 - accuracy: 0.7916 - precision: 0.8141 - recall: 0.7745 - val_loss: 2.7966 - val_accuracy: 0.4480 - val_precision: 0.4516 - val_recall: 0.4480\n",
            "Epoch 656/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5060 - accuracy: 0.7865 - precision: 0.8055 - recall: 0.7584 - val_loss: 2.8358 - val_accuracy: 0.4387 - val_precision: 0.4409 - val_recall: 0.4373\n",
            "Epoch 657/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4846 - accuracy: 0.7945 - precision: 0.8114 - recall: 0.7636 - val_loss: 3.0588 - val_accuracy: 0.4507 - val_precision: 0.4525 - val_recall: 0.4507\n",
            "Epoch 658/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4957 - accuracy: 0.7853 - precision: 0.8049 - recall: 0.7579 - val_loss: 2.9298 - val_accuracy: 0.4600 - val_precision: 0.4599 - val_recall: 0.4587\n",
            "Epoch 659/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4811 - accuracy: 0.8002 - precision: 0.8170 - recall: 0.7819 - val_loss: 2.6299 - val_accuracy: 0.4800 - val_precision: 0.4826 - val_recall: 0.4800\n",
            "Epoch 660/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5068 - accuracy: 0.7934 - precision: 0.8135 - recall: 0.7642 - val_loss: 2.6395 - val_accuracy: 0.4893 - val_precision: 0.4893 - val_recall: 0.4880\n",
            "Epoch 661/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4732 - accuracy: 0.8037 - precision: 0.8188 - recall: 0.7762 - val_loss: 2.7261 - val_accuracy: 0.4707 - val_precision: 0.4725 - val_recall: 0.4693\n",
            "Epoch 662/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5221 - accuracy: 0.7876 - precision: 0.8011 - recall: 0.7653 - val_loss: 2.6388 - val_accuracy: 0.4653 - val_precision: 0.4684 - val_recall: 0.4640\n",
            "Epoch 663/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4742 - accuracy: 0.7865 - precision: 0.8073 - recall: 0.7676 - val_loss: 2.7540 - val_accuracy: 0.4493 - val_precision: 0.4517 - val_recall: 0.4493\n",
            "Epoch 664/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4854 - accuracy: 0.7928 - precision: 0.8113 - recall: 0.7705 - val_loss: 2.8182 - val_accuracy: 0.4333 - val_precision: 0.4349 - val_recall: 0.4320\n",
            "Epoch 665/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4760 - accuracy: 0.7956 - precision: 0.8153 - recall: 0.7705 - val_loss: 2.6996 - val_accuracy: 0.4453 - val_precision: 0.4494 - val_recall: 0.4440\n",
            "Epoch 666/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4790 - accuracy: 0.7962 - precision: 0.8141 - recall: 0.7796 - val_loss: 2.8047 - val_accuracy: 0.4453 - val_precision: 0.4462 - val_recall: 0.4427\n",
            "Epoch 667/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4527 - accuracy: 0.8208 - precision: 0.8433 - recall: 0.8008 - val_loss: 2.9927 - val_accuracy: 0.4547 - val_precision: 0.4570 - val_recall: 0.4533\n",
            "Epoch 668/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4821 - accuracy: 0.8008 - precision: 0.8136 - recall: 0.7848 - val_loss: 2.8480 - val_accuracy: 0.4600 - val_precision: 0.4584 - val_recall: 0.4560\n",
            "Epoch 669/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4626 - accuracy: 0.8094 - precision: 0.8309 - recall: 0.7876 - val_loss: 2.9828 - val_accuracy: 0.4280 - val_precision: 0.4344 - val_recall: 0.4280\n",
            "Epoch 670/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4371 - accuracy: 0.8151 - precision: 0.8274 - recall: 0.7928 - val_loss: 3.0636 - val_accuracy: 0.4293 - val_precision: 0.4309 - val_recall: 0.4240\n",
            "Epoch 671/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4580 - accuracy: 0.8180 - precision: 0.8323 - recall: 0.8042 - val_loss: 2.8375 - val_accuracy: 0.4467 - val_precision: 0.4477 - val_recall: 0.4453\n",
            "Epoch 672/1000\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.4580 - accuracy: 0.8048 - precision: 0.8244 - recall: 0.7876 - val_loss: 2.9863 - val_accuracy: 0.4400 - val_precision: 0.4398 - val_recall: 0.4387\n",
            "Epoch 673/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4633 - accuracy: 0.8094 - precision: 0.8317 - recall: 0.7894 - val_loss: 2.9473 - val_accuracy: 0.4373 - val_precision: 0.4383 - val_recall: 0.4360\n",
            "Epoch 674/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4671 - accuracy: 0.8174 - precision: 0.8299 - recall: 0.7905 - val_loss: 2.9525 - val_accuracy: 0.4733 - val_precision: 0.4738 - val_recall: 0.4693\n",
            "Epoch 675/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4717 - accuracy: 0.8100 - precision: 0.8285 - recall: 0.7882 - val_loss: 3.2420 - val_accuracy: 0.4320 - val_precision: 0.4349 - val_recall: 0.4320\n",
            "Epoch 676/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4701 - accuracy: 0.8019 - precision: 0.8200 - recall: 0.7825 - val_loss: 3.1235 - val_accuracy: 0.4480 - val_precision: 0.4498 - val_recall: 0.4480\n",
            "Epoch 677/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4442 - accuracy: 0.8145 - precision: 0.8301 - recall: 0.7945 - val_loss: 3.2047 - val_accuracy: 0.4253 - val_precision: 0.4246 - val_recall: 0.4240\n",
            "Epoch 678/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4769 - accuracy: 0.8094 - precision: 0.8259 - recall: 0.7876 - val_loss: 3.3169 - val_accuracy: 0.4160 - val_precision: 0.4158 - val_recall: 0.4147\n",
            "Epoch 679/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4526 - accuracy: 0.8065 - precision: 0.8251 - recall: 0.7888 - val_loss: 3.1501 - val_accuracy: 0.4213 - val_precision: 0.4249 - val_recall: 0.4187\n",
            "Epoch 680/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4394 - accuracy: 0.8168 - precision: 0.8344 - recall: 0.7962 - val_loss: 3.2583 - val_accuracy: 0.4173 - val_precision: 0.4224 - val_recall: 0.4173\n",
            "Epoch 681/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4693 - accuracy: 0.8071 - precision: 0.8258 - recall: 0.7871 - val_loss: 3.2951 - val_accuracy: 0.4213 - val_precision: 0.4234 - val_recall: 0.4200\n",
            "Epoch 682/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4327 - accuracy: 0.8191 - precision: 0.8366 - recall: 0.8002 - val_loss: 3.5047 - val_accuracy: 0.4107 - val_precision: 0.4135 - val_recall: 0.4080\n",
            "Epoch 683/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4486 - accuracy: 0.8180 - precision: 0.8323 - recall: 0.8042 - val_loss: 3.1533 - val_accuracy: 0.4093 - val_precision: 0.4190 - val_recall: 0.4067\n",
            "Epoch 684/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4506 - accuracy: 0.8185 - precision: 0.8334 - recall: 0.7991 - val_loss: 3.6566 - val_accuracy: 0.4027 - val_precision: 0.4065 - val_recall: 0.3973\n",
            "Epoch 685/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4497 - accuracy: 0.8117 - precision: 0.8305 - recall: 0.7939 - val_loss: 3.1313 - val_accuracy: 0.4160 - val_precision: 0.4196 - val_recall: 0.4107\n",
            "Epoch 686/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4758 - accuracy: 0.8077 - precision: 0.8259 - recall: 0.7819 - val_loss: 3.0284 - val_accuracy: 0.4200 - val_precision: 0.4216 - val_recall: 0.4160\n",
            "Epoch 687/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4701 - accuracy: 0.8071 - precision: 0.8204 - recall: 0.7871 - val_loss: 2.7878 - val_accuracy: 0.4400 - val_precision: 0.4478 - val_recall: 0.4400\n",
            "Epoch 688/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4755 - accuracy: 0.8088 - precision: 0.8282 - recall: 0.7894 - val_loss: 2.8903 - val_accuracy: 0.4427 - val_precision: 0.4450 - val_recall: 0.4373\n",
            "Epoch 689/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.5027 - accuracy: 0.7916 - precision: 0.8069 - recall: 0.7653 - val_loss: 3.1034 - val_accuracy: 0.4507 - val_precision: 0.4542 - val_recall: 0.4493\n",
            "Epoch 690/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4606 - accuracy: 0.8214 - precision: 0.8386 - recall: 0.8002 - val_loss: 2.7183 - val_accuracy: 0.4667 - val_precision: 0.4658 - val_recall: 0.4627\n",
            "Epoch 691/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4612 - accuracy: 0.8054 - precision: 0.8261 - recall: 0.7859 - val_loss: 2.6368 - val_accuracy: 0.4493 - val_precision: 0.4479 - val_recall: 0.4413\n",
            "Epoch 692/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4457 - accuracy: 0.8134 - precision: 0.8315 - recall: 0.7968 - val_loss: 2.9261 - val_accuracy: 0.4320 - val_precision: 0.4375 - val_recall: 0.4293\n",
            "Epoch 693/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4772 - accuracy: 0.8002 - precision: 0.8170 - recall: 0.7848 - val_loss: 3.0032 - val_accuracy: 0.4320 - val_precision: 0.4359 - val_recall: 0.4307\n",
            "Epoch 694/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4519 - accuracy: 0.8060 - precision: 0.8213 - recall: 0.7813 - val_loss: 3.1703 - val_accuracy: 0.4307 - val_precision: 0.4324 - val_recall: 0.4307\n",
            "Epoch 695/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4794 - accuracy: 0.8019 - precision: 0.8175 - recall: 0.7848 - val_loss: 2.9125 - val_accuracy: 0.4547 - val_precision: 0.4588 - val_recall: 0.4533\n",
            "Epoch 696/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4593 - accuracy: 0.8088 - precision: 0.8254 - recall: 0.7928 - val_loss: 3.2714 - val_accuracy: 0.4267 - val_precision: 0.4301 - val_recall: 0.4227\n",
            "Epoch 697/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4446 - accuracy: 0.8254 - precision: 0.8404 - recall: 0.8048 - val_loss: 3.1370 - val_accuracy: 0.4387 - val_precision: 0.4404 - val_recall: 0.4333\n",
            "Epoch 698/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4829 - accuracy: 0.8100 - precision: 0.8257 - recall: 0.7865 - val_loss: 3.3272 - val_accuracy: 0.4067 - val_precision: 0.4110 - val_recall: 0.4000\n",
            "Epoch 699/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4594 - accuracy: 0.8180 - precision: 0.8288 - recall: 0.7928 - val_loss: 3.2024 - val_accuracy: 0.3987 - val_precision: 0.4003 - val_recall: 0.3933\n",
            "Epoch 700/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4771 - accuracy: 0.8065 - precision: 0.8274 - recall: 0.7790 - val_loss: 3.0407 - val_accuracy: 0.4320 - val_precision: 0.4342 - val_recall: 0.4267\n",
            "Epoch 701/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4918 - accuracy: 0.7997 - precision: 0.8182 - recall: 0.7779 - val_loss: 3.0197 - val_accuracy: 0.4213 - val_precision: 0.4282 - val_recall: 0.4093\n",
            "Epoch 702/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4646 - accuracy: 0.8065 - precision: 0.8313 - recall: 0.7785 - val_loss: 2.5895 - val_accuracy: 0.4493 - val_precision: 0.4645 - val_recall: 0.4453\n",
            "Epoch 703/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4737 - accuracy: 0.8014 - precision: 0.8183 - recall: 0.7813 - val_loss: 2.6975 - val_accuracy: 0.4733 - val_precision: 0.4743 - val_recall: 0.4667\n",
            "Epoch 704/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4456 - accuracy: 0.8157 - precision: 0.8310 - recall: 0.7968 - val_loss: 2.9908 - val_accuracy: 0.4480 - val_precision: 0.4541 - val_recall: 0.4480\n",
            "Epoch 705/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4484 - accuracy: 0.8117 - precision: 0.8312 - recall: 0.7922 - val_loss: 3.3500 - val_accuracy: 0.4373 - val_precision: 0.4409 - val_recall: 0.4373\n",
            "Epoch 706/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4787 - accuracy: 0.8014 - precision: 0.8228 - recall: 0.7813 - val_loss: 3.7893 - val_accuracy: 0.4040 - val_precision: 0.4111 - val_recall: 0.4040\n",
            "Epoch 707/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4815 - accuracy: 0.7876 - precision: 0.8085 - recall: 0.7687 - val_loss: 3.6767 - val_accuracy: 0.4120 - val_precision: 0.4153 - val_recall: 0.4120\n",
            "Epoch 708/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4855 - accuracy: 0.8042 - precision: 0.8218 - recall: 0.7785 - val_loss: 3.2401 - val_accuracy: 0.4453 - val_precision: 0.4464 - val_recall: 0.4440\n",
            "Epoch 709/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4896 - accuracy: 0.7894 - precision: 0.8041 - recall: 0.7682 - val_loss: 2.8297 - val_accuracy: 0.4613 - val_precision: 0.4617 - val_recall: 0.4587\n",
            "Epoch 710/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4925 - accuracy: 0.7951 - precision: 0.8118 - recall: 0.7750 - val_loss: 2.8939 - val_accuracy: 0.4520 - val_precision: 0.4548 - val_recall: 0.4493\n",
            "Epoch 711/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4675 - accuracy: 0.8019 - precision: 0.8228 - recall: 0.7813 - val_loss: 2.8715 - val_accuracy: 0.4547 - val_precision: 0.4608 - val_recall: 0.4547\n",
            "Epoch 712/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4868 - accuracy: 0.8002 - precision: 0.8174 - recall: 0.7790 - val_loss: 2.9576 - val_accuracy: 0.4427 - val_precision: 0.4486 - val_recall: 0.4427\n",
            "Epoch 713/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4783 - accuracy: 0.8054 - precision: 0.8255 - recall: 0.7773 - val_loss: 2.7390 - val_accuracy: 0.4533 - val_precision: 0.4573 - val_recall: 0.4493\n",
            "Epoch 714/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5064 - accuracy: 0.7865 - precision: 0.8047 - recall: 0.7596 - val_loss: 2.8108 - val_accuracy: 0.4533 - val_precision: 0.4520 - val_recall: 0.4453\n",
            "Epoch 715/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4870 - accuracy: 0.7911 - precision: 0.8100 - recall: 0.7665 - val_loss: 3.0320 - val_accuracy: 0.4387 - val_precision: 0.4457 - val_recall: 0.4373\n",
            "Epoch 716/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4846 - accuracy: 0.8048 - precision: 0.8143 - recall: 0.7779 - val_loss: 2.9415 - val_accuracy: 0.4427 - val_precision: 0.4449 - val_recall: 0.4413\n",
            "Epoch 717/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4766 - accuracy: 0.7894 - precision: 0.8078 - recall: 0.7722 - val_loss: 3.2936 - val_accuracy: 0.4013 - val_precision: 0.4021 - val_recall: 0.4000\n",
            "Epoch 718/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4700 - accuracy: 0.8094 - precision: 0.8235 - recall: 0.7876 - val_loss: 3.3007 - val_accuracy: 0.4053 - val_precision: 0.4142 - val_recall: 0.4053\n",
            "Epoch 719/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4591 - accuracy: 0.8088 - precision: 0.8223 - recall: 0.7922 - val_loss: 3.2904 - val_accuracy: 0.3947 - val_precision: 0.3997 - val_recall: 0.3907\n",
            "Epoch 720/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.5010 - accuracy: 0.7962 - precision: 0.8151 - recall: 0.7722 - val_loss: 2.7458 - val_accuracy: 0.4333 - val_precision: 0.4399 - val_recall: 0.4293\n",
            "Epoch 721/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4877 - accuracy: 0.8122 - precision: 0.8281 - recall: 0.7888 - val_loss: 2.9806 - val_accuracy: 0.4227 - val_precision: 0.4286 - val_recall: 0.4200\n",
            "Epoch 722/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4745 - accuracy: 0.8094 - precision: 0.8188 - recall: 0.7813 - val_loss: 2.7574 - val_accuracy: 0.4373 - val_precision: 0.4432 - val_recall: 0.4320\n",
            "Epoch 723/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4803 - accuracy: 0.8065 - precision: 0.8270 - recall: 0.7825 - val_loss: 2.4586 - val_accuracy: 0.4440 - val_precision: 0.4499 - val_recall: 0.4427\n",
            "Epoch 724/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4781 - accuracy: 0.8014 - precision: 0.8174 - recall: 0.7790 - val_loss: 2.6550 - val_accuracy: 0.4573 - val_precision: 0.4641 - val_recall: 0.4573\n",
            "Epoch 725/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4619 - accuracy: 0.8151 - precision: 0.8305 - recall: 0.7911 - val_loss: 2.6697 - val_accuracy: 0.4667 - val_precision: 0.4692 - val_recall: 0.4667\n",
            "Epoch 726/1000\n",
            "55/55 [==============================] - 1s 13ms/step - loss: 0.4983 - accuracy: 0.7968 - precision: 0.8092 - recall: 0.7722 - val_loss: 2.6555 - val_accuracy: 0.4947 - val_precision: 0.4987 - val_recall: 0.4947\n",
            "Epoch 727/1000\n",
            "55/55 [==============================] - 1s 13ms/step - loss: 0.5074 - accuracy: 0.7945 - precision: 0.8114 - recall: 0.7682 - val_loss: 2.8325 - val_accuracy: 0.4653 - val_precision: 0.4704 - val_recall: 0.4653\n",
            "Epoch 728/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4956 - accuracy: 0.7876 - precision: 0.8061 - recall: 0.7590 - val_loss: 3.0131 - val_accuracy: 0.4627 - val_precision: 0.4677 - val_recall: 0.4627\n",
            "Epoch 729/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4913 - accuracy: 0.8111 - precision: 0.8239 - recall: 0.7819 - val_loss: 3.1360 - val_accuracy: 0.4413 - val_precision: 0.4458 - val_recall: 0.4387\n",
            "Epoch 730/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.5003 - accuracy: 0.7979 - precision: 0.8149 - recall: 0.7739 - val_loss: 3.0309 - val_accuracy: 0.4387 - val_precision: 0.4446 - val_recall: 0.4387\n",
            "Epoch 731/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4841 - accuracy: 0.7968 - precision: 0.8123 - recall: 0.7682 - val_loss: 3.2732 - val_accuracy: 0.4333 - val_precision: 0.4355 - val_recall: 0.4280\n",
            "Epoch 732/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4613 - accuracy: 0.8157 - precision: 0.8311 - recall: 0.7888 - val_loss: 3.6498 - val_accuracy: 0.4160 - val_precision: 0.4226 - val_recall: 0.4147\n",
            "Epoch 733/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4628 - accuracy: 0.8065 - precision: 0.8188 - recall: 0.7813 - val_loss: 3.5048 - val_accuracy: 0.4267 - val_precision: 0.4286 - val_recall: 0.4200\n",
            "Epoch 734/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4782 - accuracy: 0.8048 - precision: 0.8289 - recall: 0.7848 - val_loss: 3.7320 - val_accuracy: 0.4147 - val_precision: 0.4203 - val_recall: 0.4147\n",
            "Epoch 735/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4800 - accuracy: 0.7997 - precision: 0.8180 - recall: 0.7768 - val_loss: 3.4970 - val_accuracy: 0.4240 - val_precision: 0.4239 - val_recall: 0.4160\n",
            "Epoch 736/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4682 - accuracy: 0.8088 - precision: 0.8228 - recall: 0.7922 - val_loss: 4.0473 - val_accuracy: 0.3947 - val_precision: 0.3978 - val_recall: 0.3920\n",
            "Epoch 737/1000\n",
            "55/55 [==============================] - 0s 7ms/step - loss: 0.4552 - accuracy: 0.8243 - precision: 0.8404 - recall: 0.7985 - val_loss: 4.7408 - val_accuracy: 0.3813 - val_precision: 0.3856 - val_recall: 0.3773\n",
            "Epoch 738/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4680 - accuracy: 0.8054 - precision: 0.8236 - recall: 0.7779 - val_loss: 3.8601 - val_accuracy: 0.4053 - val_precision: 0.4087 - val_recall: 0.4027\n",
            "Epoch 739/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4720 - accuracy: 0.8025 - precision: 0.8215 - recall: 0.7796 - val_loss: 3.5829 - val_accuracy: 0.4147 - val_precision: 0.4177 - val_recall: 0.4093\n",
            "Epoch 740/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4469 - accuracy: 0.8145 - precision: 0.8313 - recall: 0.7899 - val_loss: 3.8229 - val_accuracy: 0.4147 - val_precision: 0.4154 - val_recall: 0.4093\n",
            "Epoch 741/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4632 - accuracy: 0.8191 - precision: 0.8296 - recall: 0.7888 - val_loss: 3.4336 - val_accuracy: 0.4293 - val_precision: 0.4301 - val_recall: 0.4227\n",
            "Epoch 742/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4646 - accuracy: 0.8060 - precision: 0.8244 - recall: 0.7876 - val_loss: 3.4923 - val_accuracy: 0.4267 - val_precision: 0.4299 - val_recall: 0.4253\n",
            "Epoch 743/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4647 - accuracy: 0.8037 - precision: 0.8204 - recall: 0.7842 - val_loss: 3.7136 - val_accuracy: 0.4173 - val_precision: 0.4191 - val_recall: 0.4147\n",
            "Epoch 744/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.4536 - accuracy: 0.8243 - precision: 0.8434 - recall: 0.8077 - val_loss: 3.8396 - val_accuracy: 0.4147 - val_precision: 0.4162 - val_recall: 0.4107\n",
            "Epoch 745/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4616 - accuracy: 0.8157 - precision: 0.8379 - recall: 0.7899 - val_loss: 3.9806 - val_accuracy: 0.4093 - val_precision: 0.4127 - val_recall: 0.4067\n",
            "Epoch 746/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4539 - accuracy: 0.8071 - precision: 0.8274 - recall: 0.7848 - val_loss: 4.1066 - val_accuracy: 0.4120 - val_precision: 0.4148 - val_recall: 0.4120\n",
            "Epoch 747/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4587 - accuracy: 0.8145 - precision: 0.8248 - recall: 0.7894 - val_loss: 4.3849 - val_accuracy: 0.4187 - val_precision: 0.4207 - val_recall: 0.4173\n",
            "Epoch 748/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4911 - accuracy: 0.7962 - precision: 0.8179 - recall: 0.7687 - val_loss: 4.3572 - val_accuracy: 0.4013 - val_precision: 0.4011 - val_recall: 0.4000\n",
            "Epoch 749/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.5053 - accuracy: 0.7928 - precision: 0.8175 - recall: 0.7562 - val_loss: 4.0722 - val_accuracy: 0.4013 - val_precision: 0.4032 - val_recall: 0.4000\n",
            "Epoch 750/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4543 - accuracy: 0.8082 - precision: 0.8273 - recall: 0.7842 - val_loss: 3.8497 - val_accuracy: 0.4107 - val_precision: 0.4173 - val_recall: 0.4107\n",
            "Epoch 751/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4620 - accuracy: 0.8151 - precision: 0.8316 - recall: 0.7859 - val_loss: 3.4124 - val_accuracy: 0.4067 - val_precision: 0.4099 - val_recall: 0.4067\n",
            "Epoch 752/1000\n",
            "55/55 [==============================] - 1s 13ms/step - loss: 0.4551 - accuracy: 0.8117 - precision: 0.8277 - recall: 0.7865 - val_loss: 3.3500 - val_accuracy: 0.4120 - val_precision: 0.4151 - val_recall: 0.4107\n",
            "Epoch 753/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4426 - accuracy: 0.8237 - precision: 0.8381 - recall: 0.7939 - val_loss: 3.2863 - val_accuracy: 0.4227 - val_precision: 0.4227 - val_recall: 0.4227\n",
            "Epoch 754/1000\n",
            "55/55 [==============================] - 1s 13ms/step - loss: 0.4849 - accuracy: 0.7974 - precision: 0.8139 - recall: 0.7785 - val_loss: 3.1481 - val_accuracy: 0.4440 - val_precision: 0.4444 - val_recall: 0.4427\n",
            "Epoch 755/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4738 - accuracy: 0.8060 - precision: 0.8208 - recall: 0.7865 - val_loss: 3.4072 - val_accuracy: 0.4240 - val_precision: 0.4244 - val_recall: 0.4227\n",
            "Epoch 756/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4632 - accuracy: 0.8008 - precision: 0.8234 - recall: 0.7768 - val_loss: 2.8702 - val_accuracy: 0.4347 - val_precision: 0.4368 - val_recall: 0.4333\n",
            "Epoch 757/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4610 - accuracy: 0.8180 - precision: 0.8338 - recall: 0.8014 - val_loss: 2.5970 - val_accuracy: 0.4480 - val_precision: 0.4547 - val_recall: 0.4480\n",
            "Epoch 758/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4634 - accuracy: 0.8122 - precision: 0.8330 - recall: 0.7911 - val_loss: 2.7854 - val_accuracy: 0.4240 - val_precision: 0.4295 - val_recall: 0.4227\n",
            "Epoch 759/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4693 - accuracy: 0.7985 - precision: 0.8165 - recall: 0.7819 - val_loss: 2.7192 - val_accuracy: 0.4400 - val_precision: 0.4416 - val_recall: 0.4387\n",
            "Epoch 760/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.5400 - accuracy: 0.7756 - precision: 0.7938 - recall: 0.7470 - val_loss: 2.5599 - val_accuracy: 0.4467 - val_precision: 0.4516 - val_recall: 0.4413\n",
            "Epoch 761/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.5076 - accuracy: 0.7968 - precision: 0.8202 - recall: 0.7756 - val_loss: 2.5083 - val_accuracy: 0.4373 - val_precision: 0.4438 - val_recall: 0.4320\n",
            "Epoch 762/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.5143 - accuracy: 0.7853 - precision: 0.7984 - recall: 0.7596 - val_loss: 2.4751 - val_accuracy: 0.4413 - val_precision: 0.4441 - val_recall: 0.4347\n",
            "Epoch 763/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.4882 - accuracy: 0.8060 - precision: 0.8303 - recall: 0.7842 - val_loss: 2.5428 - val_accuracy: 0.4387 - val_precision: 0.4449 - val_recall: 0.4360\n",
            "Epoch 764/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.4852 - accuracy: 0.8037 - precision: 0.8138 - recall: 0.7808 - val_loss: 2.7397 - val_accuracy: 0.4187 - val_precision: 0.4264 - val_recall: 0.4173\n",
            "Epoch 765/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4578 - accuracy: 0.8168 - precision: 0.8318 - recall: 0.7985 - val_loss: 2.9350 - val_accuracy: 0.4173 - val_precision: 0.4233 - val_recall: 0.4160\n",
            "Epoch 766/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4917 - accuracy: 0.7951 - precision: 0.8134 - recall: 0.7733 - val_loss: 3.0361 - val_accuracy: 0.4120 - val_precision: 0.4144 - val_recall: 0.4067\n",
            "Epoch 767/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4509 - accuracy: 0.8100 - precision: 0.8324 - recall: 0.7848 - val_loss: 2.9344 - val_accuracy: 0.4120 - val_precision: 0.4152 - val_recall: 0.4080\n",
            "Epoch 768/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4641 - accuracy: 0.8128 - precision: 0.8298 - recall: 0.7899 - val_loss: 2.8409 - val_accuracy: 0.4227 - val_precision: 0.4263 - val_recall: 0.4200\n",
            "Epoch 769/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4551 - accuracy: 0.8214 - precision: 0.8365 - recall: 0.7968 - val_loss: 2.6515 - val_accuracy: 0.4400 - val_precision: 0.4420 - val_recall: 0.4320\n",
            "Epoch 770/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4461 - accuracy: 0.8254 - precision: 0.8367 - recall: 0.7951 - val_loss: 2.7502 - val_accuracy: 0.4267 - val_precision: 0.4294 - val_recall: 0.4173\n",
            "Epoch 771/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4471 - accuracy: 0.8174 - precision: 0.8317 - recall: 0.8008 - val_loss: 2.6251 - val_accuracy: 0.4413 - val_precision: 0.4458 - val_recall: 0.4387\n",
            "Epoch 772/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4529 - accuracy: 0.8145 - precision: 0.8301 - recall: 0.7888 - val_loss: 2.5663 - val_accuracy: 0.4467 - val_precision: 0.4529 - val_recall: 0.4360\n",
            "Epoch 773/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4718 - accuracy: 0.8008 - precision: 0.8146 - recall: 0.7796 - val_loss: 2.6065 - val_accuracy: 0.4507 - val_precision: 0.4601 - val_recall: 0.4453\n",
            "Epoch 774/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4554 - accuracy: 0.8191 - precision: 0.8350 - recall: 0.7968 - val_loss: 2.7931 - val_accuracy: 0.4573 - val_precision: 0.4623 - val_recall: 0.4573\n",
            "Epoch 775/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4469 - accuracy: 0.8203 - precision: 0.8411 - recall: 0.7997 - val_loss: 2.7758 - val_accuracy: 0.4640 - val_precision: 0.4643 - val_recall: 0.4600\n",
            "Epoch 776/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.4413 - accuracy: 0.8254 - precision: 0.8411 - recall: 0.8031 - val_loss: 3.0689 - val_accuracy: 0.4293 - val_precision: 0.4373 - val_recall: 0.4280\n",
            "Epoch 777/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4463 - accuracy: 0.8157 - precision: 0.8372 - recall: 0.8008 - val_loss: 2.8826 - val_accuracy: 0.4560 - val_precision: 0.4590 - val_recall: 0.4547\n",
            "Epoch 778/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4444 - accuracy: 0.8266 - precision: 0.8411 - recall: 0.8122 - val_loss: 2.8165 - val_accuracy: 0.4600 - val_precision: 0.4610 - val_recall: 0.4573\n",
            "Epoch 779/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4523 - accuracy: 0.8185 - precision: 0.8373 - recall: 0.7985 - val_loss: 2.6110 - val_accuracy: 0.4760 - val_precision: 0.4791 - val_recall: 0.4733\n",
            "Epoch 780/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4313 - accuracy: 0.8237 - precision: 0.8377 - recall: 0.8037 - val_loss: 2.6392 - val_accuracy: 0.4693 - val_precision: 0.4802 - val_recall: 0.4680\n",
            "Epoch 781/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4407 - accuracy: 0.8214 - precision: 0.8386 - recall: 0.8002 - val_loss: 2.4893 - val_accuracy: 0.4827 - val_precision: 0.4890 - val_recall: 0.4760\n",
            "Epoch 782/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4627 - accuracy: 0.8071 - precision: 0.8226 - recall: 0.7911 - val_loss: 3.0089 - val_accuracy: 0.4347 - val_precision: 0.4411 - val_recall: 0.4347\n",
            "Epoch 783/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4501 - accuracy: 0.8100 - precision: 0.8330 - recall: 0.7911 - val_loss: 3.0874 - val_accuracy: 0.4387 - val_precision: 0.4434 - val_recall: 0.4333\n",
            "Epoch 784/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4536 - accuracy: 0.8105 - precision: 0.8274 - recall: 0.7956 - val_loss: 2.9774 - val_accuracy: 0.4413 - val_precision: 0.4440 - val_recall: 0.4387\n",
            "Epoch 785/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4605 - accuracy: 0.8122 - precision: 0.8303 - recall: 0.7899 - val_loss: 2.9896 - val_accuracy: 0.4467 - val_precision: 0.4489 - val_recall: 0.4453\n",
            "Epoch 786/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4433 - accuracy: 0.8077 - precision: 0.8249 - recall: 0.7876 - val_loss: 2.6682 - val_accuracy: 0.4640 - val_precision: 0.4664 - val_recall: 0.4627\n",
            "Epoch 787/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4450 - accuracy: 0.8151 - precision: 0.8364 - recall: 0.7962 - val_loss: 2.9312 - val_accuracy: 0.4573 - val_precision: 0.4603 - val_recall: 0.4560\n",
            "Epoch 788/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4664 - accuracy: 0.8094 - precision: 0.8296 - recall: 0.7888 - val_loss: 2.6901 - val_accuracy: 0.4587 - val_precision: 0.4648 - val_recall: 0.4573\n",
            "Epoch 789/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4350 - accuracy: 0.8277 - precision: 0.8406 - recall: 0.8122 - val_loss: 2.4973 - val_accuracy: 0.4773 - val_precision: 0.4823 - val_recall: 0.4733\n",
            "Epoch 790/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4746 - accuracy: 0.8054 - precision: 0.8219 - recall: 0.7819 - val_loss: 2.7310 - val_accuracy: 0.4600 - val_precision: 0.4617 - val_recall: 0.4587\n",
            "Epoch 791/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4631 - accuracy: 0.8117 - precision: 0.8277 - recall: 0.7865 - val_loss: 2.9163 - val_accuracy: 0.4280 - val_precision: 0.4348 - val_recall: 0.4267\n",
            "Epoch 792/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4197 - accuracy: 0.8300 - precision: 0.8483 - recall: 0.8128 - val_loss: 2.7146 - val_accuracy: 0.4560 - val_precision: 0.4577 - val_recall: 0.4547\n",
            "Epoch 793/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4326 - accuracy: 0.8283 - precision: 0.8454 - recall: 0.8140 - val_loss: 2.6655 - val_accuracy: 0.4560 - val_precision: 0.4596 - val_recall: 0.4547\n",
            "Epoch 794/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4485 - accuracy: 0.8134 - precision: 0.8317 - recall: 0.7951 - val_loss: 2.8531 - val_accuracy: 0.4387 - val_precision: 0.4385 - val_recall: 0.4373\n",
            "Epoch 795/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4293 - accuracy: 0.8157 - precision: 0.8320 - recall: 0.7997 - val_loss: 2.8413 - val_accuracy: 0.4587 - val_precision: 0.4604 - val_recall: 0.4573\n",
            "Epoch 796/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4316 - accuracy: 0.8317 - precision: 0.8475 - recall: 0.8111 - val_loss: 2.8025 - val_accuracy: 0.4507 - val_precision: 0.4519 - val_recall: 0.4507\n",
            "Epoch 797/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4494 - accuracy: 0.8157 - precision: 0.8304 - recall: 0.8014 - val_loss: 2.5224 - val_accuracy: 0.4627 - val_precision: 0.4663 - val_recall: 0.4613\n",
            "Epoch 798/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4596 - accuracy: 0.8111 - precision: 0.8267 - recall: 0.7916 - val_loss: 2.5547 - val_accuracy: 0.4307 - val_precision: 0.4411 - val_recall: 0.4293\n",
            "Epoch 799/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4324 - accuracy: 0.8231 - precision: 0.8388 - recall: 0.8014 - val_loss: 2.6329 - val_accuracy: 0.4600 - val_precision: 0.4631 - val_recall: 0.4600\n",
            "Epoch 800/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4319 - accuracy: 0.8288 - precision: 0.8440 - recall: 0.8145 - val_loss: 2.6772 - val_accuracy: 0.4613 - val_precision: 0.4597 - val_recall: 0.4560\n",
            "Epoch 801/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4695 - accuracy: 0.8100 - precision: 0.8183 - recall: 0.7865 - val_loss: 2.6824 - val_accuracy: 0.4547 - val_precision: 0.4595 - val_recall: 0.4533\n",
            "Epoch 802/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4570 - accuracy: 0.7985 - precision: 0.8163 - recall: 0.7836 - val_loss: 2.8024 - val_accuracy: 0.4307 - val_precision: 0.4345 - val_recall: 0.4293\n",
            "Epoch 803/1000\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.4300 - accuracy: 0.8214 - precision: 0.8382 - recall: 0.8065 - val_loss: 2.9216 - val_accuracy: 0.4320 - val_precision: 0.4336 - val_recall: 0.4267\n",
            "Epoch 804/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4832 - accuracy: 0.8065 - precision: 0.8226 - recall: 0.7859 - val_loss: 2.8195 - val_accuracy: 0.4507 - val_precision: 0.4541 - val_recall: 0.4480\n",
            "Epoch 805/1000\n",
            "55/55 [==============================] - 1s 13ms/step - loss: 0.4697 - accuracy: 0.8008 - precision: 0.8192 - recall: 0.7808 - val_loss: 2.9373 - val_accuracy: 0.4280 - val_precision: 0.4301 - val_recall: 0.4227\n",
            "Epoch 806/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4370 - accuracy: 0.8163 - precision: 0.8343 - recall: 0.7928 - val_loss: 3.1873 - val_accuracy: 0.4120 - val_precision: 0.4171 - val_recall: 0.4093\n",
            "Epoch 807/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4576 - accuracy: 0.8180 - precision: 0.8371 - recall: 0.7974 - val_loss: 2.8391 - val_accuracy: 0.4360 - val_precision: 0.4435 - val_recall: 0.4347\n",
            "Epoch 808/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4504 - accuracy: 0.8163 - precision: 0.8346 - recall: 0.7974 - val_loss: 2.6700 - val_accuracy: 0.4347 - val_precision: 0.4399 - val_recall: 0.4293\n",
            "Epoch 809/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4485 - accuracy: 0.8168 - precision: 0.8351 - recall: 0.8031 - val_loss: 2.8324 - val_accuracy: 0.4240 - val_precision: 0.4315 - val_recall: 0.4200\n",
            "Epoch 810/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4651 - accuracy: 0.8071 - precision: 0.8255 - recall: 0.7853 - val_loss: 2.6347 - val_accuracy: 0.4480 - val_precision: 0.4531 - val_recall: 0.4440\n",
            "Epoch 811/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4512 - accuracy: 0.8226 - precision: 0.8391 - recall: 0.8031 - val_loss: 2.7197 - val_accuracy: 0.4347 - val_precision: 0.4404 - val_recall: 0.4333\n",
            "Epoch 812/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4737 - accuracy: 0.8077 - precision: 0.8284 - recall: 0.7876 - val_loss: 3.1825 - val_accuracy: 0.4093 - val_precision: 0.4177 - val_recall: 0.4093\n",
            "Epoch 813/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4502 - accuracy: 0.8231 - precision: 0.8431 - recall: 0.7968 - val_loss: 3.5364 - val_accuracy: 0.4040 - val_precision: 0.4131 - val_recall: 0.4027\n",
            "Epoch 814/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4566 - accuracy: 0.8082 - precision: 0.8259 - recall: 0.7899 - val_loss: 3.2588 - val_accuracy: 0.3987 - val_precision: 0.4071 - val_recall: 0.3973\n",
            "Epoch 815/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4715 - accuracy: 0.8145 - precision: 0.8338 - recall: 0.7928 - val_loss: 2.9278 - val_accuracy: 0.4187 - val_precision: 0.4218 - val_recall: 0.4133\n",
            "Epoch 816/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.4208 - accuracy: 0.8294 - precision: 0.8409 - recall: 0.8077 - val_loss: 3.0828 - val_accuracy: 0.4267 - val_precision: 0.4301 - val_recall: 0.4267\n",
            "Epoch 817/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4524 - accuracy: 0.8122 - precision: 0.8279 - recall: 0.7905 - val_loss: 3.0636 - val_accuracy: 0.4320 - val_precision: 0.4324 - val_recall: 0.4267\n",
            "Epoch 818/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4484 - accuracy: 0.8231 - precision: 0.8378 - recall: 0.8042 - val_loss: 3.2103 - val_accuracy: 0.4133 - val_precision: 0.4151 - val_recall: 0.4107\n",
            "Epoch 819/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4367 - accuracy: 0.8283 - precision: 0.8435 - recall: 0.8111 - val_loss: 3.3917 - val_accuracy: 0.4107 - val_precision: 0.4110 - val_recall: 0.4093\n",
            "Epoch 820/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.4319 - accuracy: 0.8094 - precision: 0.8255 - recall: 0.7905 - val_loss: 3.3548 - val_accuracy: 0.4040 - val_precision: 0.4062 - val_recall: 0.4040\n",
            "Epoch 821/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4299 - accuracy: 0.8329 - precision: 0.8473 - recall: 0.8065 - val_loss: 3.2021 - val_accuracy: 0.4107 - val_precision: 0.4144 - val_recall: 0.4067\n",
            "Epoch 822/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.4603 - accuracy: 0.8174 - precision: 0.8325 - recall: 0.7997 - val_loss: 2.8883 - val_accuracy: 0.4360 - val_precision: 0.4377 - val_recall: 0.4307\n",
            "Epoch 823/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4198 - accuracy: 0.8363 - precision: 0.8495 - recall: 0.8174 - val_loss: 3.1173 - val_accuracy: 0.4240 - val_precision: 0.4290 - val_recall: 0.4227\n",
            "Epoch 824/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4343 - accuracy: 0.8174 - precision: 0.8328 - recall: 0.8042 - val_loss: 3.1901 - val_accuracy: 0.4240 - val_precision: 0.4265 - val_recall: 0.4213\n",
            "Epoch 825/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4475 - accuracy: 0.8277 - precision: 0.8397 - recall: 0.8065 - val_loss: 3.2116 - val_accuracy: 0.4133 - val_precision: 0.4157 - val_recall: 0.4107\n",
            "Epoch 826/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4586 - accuracy: 0.8042 - precision: 0.8221 - recall: 0.7831 - val_loss: 2.9895 - val_accuracy: 0.4133 - val_precision: 0.4176 - val_recall: 0.4120\n",
            "Epoch 827/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.5040 - accuracy: 0.7922 - precision: 0.8082 - recall: 0.7693 - val_loss: 3.1859 - val_accuracy: 0.4200 - val_precision: 0.4218 - val_recall: 0.4173\n",
            "Epoch 828/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4535 - accuracy: 0.8100 - precision: 0.8304 - recall: 0.7876 - val_loss: 3.3236 - val_accuracy: 0.4120 - val_precision: 0.4179 - val_recall: 0.4107\n",
            "Epoch 829/1000\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.4912 - accuracy: 0.7911 - precision: 0.8153 - recall: 0.7705 - val_loss: 3.3337 - val_accuracy: 0.4133 - val_precision: 0.4193 - val_recall: 0.4120\n",
            "Epoch 830/1000\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.4859 - accuracy: 0.8048 - precision: 0.8188 - recall: 0.7836 - val_loss: 3.2959 - val_accuracy: 0.4133 - val_precision: 0.4212 - val_recall: 0.4133\n",
            "Epoch 831/1000\n",
            "55/55 [==============================] - 1s 16ms/step - loss: 0.4678 - accuracy: 0.8008 - precision: 0.8249 - recall: 0.7819 - val_loss: 3.2695 - val_accuracy: 0.4160 - val_precision: 0.4245 - val_recall: 0.4160\n",
            "Epoch 832/1000\n",
            "55/55 [==============================] - 1s 16ms/step - loss: 0.4811 - accuracy: 0.8060 - precision: 0.8232 - recall: 0.7728 - val_loss: 3.1524 - val_accuracy: 0.4147 - val_precision: 0.4198 - val_recall: 0.4120\n",
            "Epoch 833/1000\n",
            "55/55 [==============================] - 1s 16ms/step - loss: 0.4395 - accuracy: 0.8117 - precision: 0.8276 - recall: 0.7939 - val_loss: 3.2442 - val_accuracy: 0.4347 - val_precision: 0.4386 - val_recall: 0.4333\n",
            "Epoch 834/1000\n",
            "55/55 [==============================] - 1s 13ms/step - loss: 0.4332 - accuracy: 0.8231 - precision: 0.8428 - recall: 0.8071 - val_loss: 3.4225 - val_accuracy: 0.4253 - val_precision: 0.4251 - val_recall: 0.4240\n",
            "Epoch 835/1000\n",
            "55/55 [==============================] - 1s 13ms/step - loss: 0.4560 - accuracy: 0.8071 - precision: 0.8282 - recall: 0.7922 - val_loss: 3.4294 - val_accuracy: 0.4133 - val_precision: 0.4129 - val_recall: 0.4107\n",
            "Epoch 836/1000\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.4643 - accuracy: 0.8163 - precision: 0.8260 - recall: 0.7882 - val_loss: 3.2508 - val_accuracy: 0.4160 - val_precision: 0.4194 - val_recall: 0.4160\n",
            "Epoch 837/1000\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.4935 - accuracy: 0.7916 - precision: 0.8090 - recall: 0.7733 - val_loss: 3.2471 - val_accuracy: 0.4267 - val_precision: 0.4259 - val_recall: 0.4213\n",
            "Epoch 838/1000\n",
            "55/55 [==============================] - 1s 17ms/step - loss: 0.4421 - accuracy: 0.8231 - precision: 0.8385 - recall: 0.8025 - val_loss: 3.2057 - val_accuracy: 0.4253 - val_precision: 0.4293 - val_recall: 0.4253\n",
            "Epoch 839/1000\n",
            "55/55 [==============================] - 1s 13ms/step - loss: 0.4583 - accuracy: 0.8077 - precision: 0.8243 - recall: 0.7894 - val_loss: 3.0355 - val_accuracy: 0.4413 - val_precision: 0.4447 - val_recall: 0.4400\n",
            "Epoch 840/1000\n",
            "55/55 [==============================] - 1s 15ms/step - loss: 0.4675 - accuracy: 0.8117 - precision: 0.8275 - recall: 0.7882 - val_loss: 3.0103 - val_accuracy: 0.4387 - val_precision: 0.4413 - val_recall: 0.4360\n",
            "Epoch 841/1000\n",
            "55/55 [==============================] - 1s 16ms/step - loss: 0.4413 - accuracy: 0.8294 - precision: 0.8413 - recall: 0.8071 - val_loss: 2.7735 - val_accuracy: 0.4680 - val_precision: 0.4716 - val_recall: 0.4653\n",
            "Epoch 842/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4313 - accuracy: 0.8243 - precision: 0.8441 - recall: 0.8025 - val_loss: 2.9031 - val_accuracy: 0.4533 - val_precision: 0.4571 - val_recall: 0.4480\n",
            "Epoch 843/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4440 - accuracy: 0.8151 - precision: 0.8312 - recall: 0.7951 - val_loss: 2.8697 - val_accuracy: 0.4427 - val_precision: 0.4472 - val_recall: 0.4400\n",
            "Epoch 844/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4413 - accuracy: 0.8237 - precision: 0.8360 - recall: 0.8025 - val_loss: 2.7227 - val_accuracy: 0.4467 - val_precision: 0.4518 - val_recall: 0.4440\n",
            "Epoch 845/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4498 - accuracy: 0.8140 - precision: 0.8295 - recall: 0.7962 - val_loss: 2.8540 - val_accuracy: 0.4360 - val_precision: 0.4364 - val_recall: 0.4253\n",
            "Epoch 846/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4449 - accuracy: 0.8254 - precision: 0.8396 - recall: 0.8031 - val_loss: 2.6149 - val_accuracy: 0.4360 - val_precision: 0.4370 - val_recall: 0.4253\n",
            "Epoch 847/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4712 - accuracy: 0.8094 - precision: 0.8337 - recall: 0.7894 - val_loss: 2.7343 - val_accuracy: 0.4347 - val_precision: 0.4386 - val_recall: 0.4333\n",
            "Epoch 848/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4722 - accuracy: 0.7979 - precision: 0.8129 - recall: 0.7762 - val_loss: 2.8902 - val_accuracy: 0.4200 - val_precision: 0.4238 - val_recall: 0.4187\n",
            "Epoch 849/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.4453 - accuracy: 0.8203 - precision: 0.8403 - recall: 0.7979 - val_loss: 3.1504 - val_accuracy: 0.4160 - val_precision: 0.4171 - val_recall: 0.4093\n",
            "Epoch 850/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4664 - accuracy: 0.8071 - precision: 0.8226 - recall: 0.7911 - val_loss: 3.1292 - val_accuracy: 0.4120 - val_precision: 0.4142 - val_recall: 0.4053\n",
            "Epoch 851/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4573 - accuracy: 0.8094 - precision: 0.8284 - recall: 0.7876 - val_loss: 2.6653 - val_accuracy: 0.4453 - val_precision: 0.4467 - val_recall: 0.4413\n",
            "Epoch 852/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4516 - accuracy: 0.8077 - precision: 0.8227 - recall: 0.7836 - val_loss: 2.7297 - val_accuracy: 0.4360 - val_precision: 0.4380 - val_recall: 0.4333\n",
            "Epoch 853/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4819 - accuracy: 0.8111 - precision: 0.8262 - recall: 0.7808 - val_loss: 2.8868 - val_accuracy: 0.4067 - val_precision: 0.4088 - val_recall: 0.3973\n",
            "Epoch 854/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4537 - accuracy: 0.8094 - precision: 0.8327 - recall: 0.7865 - val_loss: 2.7496 - val_accuracy: 0.4373 - val_precision: 0.4413 - val_recall: 0.4360\n",
            "Epoch 855/1000\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.4718 - accuracy: 0.8077 - precision: 0.8233 - recall: 0.7922 - val_loss: 2.5826 - val_accuracy: 0.4560 - val_precision: 0.4658 - val_recall: 0.4547\n",
            "Epoch 856/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4333 - accuracy: 0.8220 - precision: 0.8340 - recall: 0.7968 - val_loss: 2.7812 - val_accuracy: 0.4347 - val_precision: 0.4364 - val_recall: 0.4253\n",
            "Epoch 857/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4249 - accuracy: 0.8271 - precision: 0.8435 - recall: 0.8111 - val_loss: 2.7449 - val_accuracy: 0.4547 - val_precision: 0.4590 - val_recall: 0.4547\n",
            "Epoch 858/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4367 - accuracy: 0.8243 - precision: 0.8382 - recall: 0.8037 - val_loss: 2.9099 - val_accuracy: 0.4413 - val_precision: 0.4428 - val_recall: 0.4387\n",
            "Epoch 859/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4940 - accuracy: 0.7991 - precision: 0.8195 - recall: 0.7848 - val_loss: 2.5597 - val_accuracy: 0.4573 - val_precision: 0.4601 - val_recall: 0.4533\n",
            "Epoch 860/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4731 - accuracy: 0.8025 - precision: 0.8241 - recall: 0.7831 - val_loss: 2.7034 - val_accuracy: 0.4547 - val_precision: 0.4587 - val_recall: 0.4520\n",
            "Epoch 861/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4888 - accuracy: 0.8031 - precision: 0.8243 - recall: 0.7762 - val_loss: 2.6841 - val_accuracy: 0.4533 - val_precision: 0.4568 - val_recall: 0.4507\n",
            "Epoch 862/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4933 - accuracy: 0.7859 - precision: 0.8080 - recall: 0.7613 - val_loss: 2.6737 - val_accuracy: 0.4693 - val_precision: 0.4723 - val_recall: 0.4667\n",
            "Epoch 863/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.4861 - accuracy: 0.8100 - precision: 0.8277 - recall: 0.7808 - val_loss: 2.6489 - val_accuracy: 0.4733 - val_precision: 0.4763 - val_recall: 0.4680\n",
            "Epoch 864/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4796 - accuracy: 0.8014 - precision: 0.8192 - recall: 0.7831 - val_loss: 2.6540 - val_accuracy: 0.4640 - val_precision: 0.4675 - val_recall: 0.4600\n",
            "Epoch 865/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.4521 - accuracy: 0.8185 - precision: 0.8382 - recall: 0.7945 - val_loss: 2.6789 - val_accuracy: 0.4653 - val_precision: 0.4683 - val_recall: 0.4627\n",
            "Epoch 866/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4602 - accuracy: 0.8260 - precision: 0.8368 - recall: 0.8071 - val_loss: 2.5713 - val_accuracy: 0.4640 - val_precision: 0.4669 - val_recall: 0.4613\n",
            "Epoch 867/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4411 - accuracy: 0.8266 - precision: 0.8440 - recall: 0.8054 - val_loss: 2.5520 - val_accuracy: 0.4707 - val_precision: 0.4737 - val_recall: 0.4680\n",
            "Epoch 868/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4615 - accuracy: 0.8134 - precision: 0.8305 - recall: 0.7968 - val_loss: 2.8476 - val_accuracy: 0.4200 - val_precision: 0.4292 - val_recall: 0.4160\n",
            "Epoch 869/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4646 - accuracy: 0.8134 - precision: 0.8292 - recall: 0.7922 - val_loss: 2.7223 - val_accuracy: 0.4467 - val_precision: 0.4514 - val_recall: 0.4453\n",
            "Epoch 870/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4638 - accuracy: 0.8134 - precision: 0.8294 - recall: 0.7876 - val_loss: 2.6519 - val_accuracy: 0.4533 - val_precision: 0.4534 - val_recall: 0.4480\n",
            "Epoch 871/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4584 - accuracy: 0.8180 - precision: 0.8344 - recall: 0.7962 - val_loss: 2.5511 - val_accuracy: 0.4653 - val_precision: 0.4641 - val_recall: 0.4573\n",
            "Epoch 872/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4318 - accuracy: 0.8237 - precision: 0.8390 - recall: 0.8025 - val_loss: 2.7437 - val_accuracy: 0.4547 - val_precision: 0.4556 - val_recall: 0.4520\n",
            "Epoch 873/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4787 - accuracy: 0.7997 - precision: 0.8140 - recall: 0.7842 - val_loss: 2.7995 - val_accuracy: 0.4320 - val_precision: 0.4363 - val_recall: 0.4293\n",
            "Epoch 874/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.4429 - accuracy: 0.8271 - precision: 0.8467 - recall: 0.8094 - val_loss: 2.9550 - val_accuracy: 0.4053 - val_precision: 0.4106 - val_recall: 0.4040\n",
            "Epoch 875/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4422 - accuracy: 0.8266 - precision: 0.8420 - recall: 0.8117 - val_loss: 2.7638 - val_accuracy: 0.4253 - val_precision: 0.4297 - val_recall: 0.4200\n",
            "Epoch 876/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4671 - accuracy: 0.8168 - precision: 0.8330 - recall: 0.7939 - val_loss: 2.7003 - val_accuracy: 0.4347 - val_precision: 0.4371 - val_recall: 0.4307\n",
            "Epoch 877/1000\n",
            "55/55 [==============================] - 1s 13ms/step - loss: 0.4456 - accuracy: 0.8071 - precision: 0.8240 - recall: 0.7934 - val_loss: 2.8024 - val_accuracy: 0.4187 - val_precision: 0.4228 - val_recall: 0.4160\n",
            "Epoch 878/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4205 - accuracy: 0.8243 - precision: 0.8373 - recall: 0.8042 - val_loss: 2.9755 - val_accuracy: 0.4107 - val_precision: 0.4146 - val_recall: 0.4080\n",
            "Epoch 879/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4634 - accuracy: 0.8151 - precision: 0.8324 - recall: 0.7962 - val_loss: 2.9143 - val_accuracy: 0.4240 - val_precision: 0.4266 - val_recall: 0.4227\n",
            "Epoch 880/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4707 - accuracy: 0.8094 - precision: 0.8324 - recall: 0.7848 - val_loss: 3.1821 - val_accuracy: 0.4027 - val_precision: 0.4090 - val_recall: 0.4013\n",
            "Epoch 881/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.4490 - accuracy: 0.8088 - precision: 0.8323 - recall: 0.7899 - val_loss: 2.7399 - val_accuracy: 0.4440 - val_precision: 0.4461 - val_recall: 0.4413\n",
            "Epoch 882/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4605 - accuracy: 0.8151 - precision: 0.8314 - recall: 0.7962 - val_loss: 2.8455 - val_accuracy: 0.4427 - val_precision: 0.4431 - val_recall: 0.4413\n",
            "Epoch 883/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4544 - accuracy: 0.8077 - precision: 0.8215 - recall: 0.7796 - val_loss: 2.6599 - val_accuracy: 0.4493 - val_precision: 0.4510 - val_recall: 0.4413\n",
            "Epoch 884/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4255 - accuracy: 0.8306 - precision: 0.8435 - recall: 0.8082 - val_loss: 2.7781 - val_accuracy: 0.4400 - val_precision: 0.4441 - val_recall: 0.4400\n",
            "Epoch 885/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4729 - accuracy: 0.8042 - precision: 0.8149 - recall: 0.7739 - val_loss: 2.7965 - val_accuracy: 0.4413 - val_precision: 0.4425 - val_recall: 0.4360\n",
            "Epoch 886/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4536 - accuracy: 0.8197 - precision: 0.8405 - recall: 0.8025 - val_loss: 2.7241 - val_accuracy: 0.4480 - val_precision: 0.4479 - val_recall: 0.4467\n",
            "Epoch 887/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4350 - accuracy: 0.8226 - precision: 0.8399 - recall: 0.8019 - val_loss: 2.6831 - val_accuracy: 0.4533 - val_precision: 0.4545 - val_recall: 0.4533\n",
            "Epoch 888/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4382 - accuracy: 0.8237 - precision: 0.8376 - recall: 0.8031 - val_loss: 2.7239 - val_accuracy: 0.4533 - val_precision: 0.4539 - val_recall: 0.4533\n",
            "Epoch 889/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4352 - accuracy: 0.8168 - precision: 0.8311 - recall: 0.7945 - val_loss: 2.8046 - val_accuracy: 0.4587 - val_precision: 0.4611 - val_recall: 0.4587\n",
            "Epoch 890/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.4220 - accuracy: 0.8300 - precision: 0.8479 - recall: 0.8105 - val_loss: 2.7567 - val_accuracy: 0.4573 - val_precision: 0.4578 - val_recall: 0.4560\n",
            "Epoch 891/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4328 - accuracy: 0.8243 - precision: 0.8409 - recall: 0.8048 - val_loss: 2.6900 - val_accuracy: 0.4547 - val_precision: 0.4547 - val_recall: 0.4480\n",
            "Epoch 892/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4288 - accuracy: 0.8208 - precision: 0.8379 - recall: 0.8019 - val_loss: 2.7472 - val_accuracy: 0.4533 - val_precision: 0.4538 - val_recall: 0.4520\n",
            "Epoch 893/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.4494 - accuracy: 0.8140 - precision: 0.8288 - recall: 0.7928 - val_loss: 2.8003 - val_accuracy: 0.4507 - val_precision: 0.4516 - val_recall: 0.4480\n",
            "Epoch 894/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4189 - accuracy: 0.8248 - precision: 0.8399 - recall: 0.8048 - val_loss: 2.7413 - val_accuracy: 0.4627 - val_precision: 0.4632 - val_recall: 0.4613\n",
            "Epoch 895/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4175 - accuracy: 0.8266 - precision: 0.8375 - recall: 0.8111 - val_loss: 2.9254 - val_accuracy: 0.4440 - val_precision: 0.4446 - val_recall: 0.4387\n",
            "Epoch 896/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4579 - accuracy: 0.8145 - precision: 0.8278 - recall: 0.7951 - val_loss: 2.9179 - val_accuracy: 0.4400 - val_precision: 0.4444 - val_recall: 0.4373\n",
            "Epoch 897/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4310 - accuracy: 0.8254 - precision: 0.8418 - recall: 0.8042 - val_loss: 2.8454 - val_accuracy: 0.4387 - val_precision: 0.4383 - val_recall: 0.4360\n",
            "Epoch 898/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.4235 - accuracy: 0.8351 - precision: 0.8458 - recall: 0.8134 - val_loss: 2.9176 - val_accuracy: 0.4360 - val_precision: 0.4383 - val_recall: 0.4360\n",
            "Epoch 899/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4393 - accuracy: 0.8214 - precision: 0.8315 - recall: 0.7997 - val_loss: 2.9740 - val_accuracy: 0.4387 - val_precision: 0.4404 - val_recall: 0.4387\n",
            "Epoch 900/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4217 - accuracy: 0.8260 - precision: 0.8486 - recall: 0.8088 - val_loss: 2.7385 - val_accuracy: 0.4653 - val_precision: 0.4677 - val_recall: 0.4627\n",
            "Epoch 901/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4051 - accuracy: 0.8374 - precision: 0.8542 - recall: 0.8117 - val_loss: 2.9305 - val_accuracy: 0.4467 - val_precision: 0.4520 - val_recall: 0.4453\n",
            "Epoch 902/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4141 - accuracy: 0.8334 - precision: 0.8485 - recall: 0.8174 - val_loss: 2.6950 - val_accuracy: 0.4707 - val_precision: 0.4738 - val_recall: 0.4693\n",
            "Epoch 903/1000\n",
            "55/55 [==============================] - 1s 13ms/step - loss: 0.4783 - accuracy: 0.8048 - precision: 0.8204 - recall: 0.7871 - val_loss: 2.5856 - val_accuracy: 0.4613 - val_precision: 0.4658 - val_recall: 0.4547\n",
            "Epoch 904/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4983 - accuracy: 0.7859 - precision: 0.8064 - recall: 0.7699 - val_loss: 2.9817 - val_accuracy: 0.4213 - val_precision: 0.4255 - val_recall: 0.4187\n",
            "Epoch 905/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4604 - accuracy: 0.8082 - precision: 0.8250 - recall: 0.7853 - val_loss: 2.7893 - val_accuracy: 0.4253 - val_precision: 0.4301 - val_recall: 0.4187\n",
            "Epoch 906/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4834 - accuracy: 0.7928 - precision: 0.8161 - recall: 0.7722 - val_loss: 2.5384 - val_accuracy: 0.4573 - val_precision: 0.4606 - val_recall: 0.4520\n",
            "Epoch 907/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4602 - accuracy: 0.8185 - precision: 0.8381 - recall: 0.7939 - val_loss: 2.8919 - val_accuracy: 0.4533 - val_precision: 0.4533 - val_recall: 0.4467\n",
            "Epoch 908/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.4511 - accuracy: 0.7991 - precision: 0.8171 - recall: 0.7773 - val_loss: 3.1570 - val_accuracy: 0.4507 - val_precision: 0.4510 - val_recall: 0.4480\n",
            "Epoch 909/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4764 - accuracy: 0.7939 - precision: 0.8051 - recall: 0.7710 - val_loss: 3.2812 - val_accuracy: 0.4187 - val_precision: 0.4211 - val_recall: 0.4160\n",
            "Epoch 910/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4940 - accuracy: 0.7951 - precision: 0.8109 - recall: 0.7756 - val_loss: 2.9666 - val_accuracy: 0.4493 - val_precision: 0.4553 - val_recall: 0.4480\n",
            "Epoch 911/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4779 - accuracy: 0.7974 - precision: 0.8156 - recall: 0.7796 - val_loss: 3.1858 - val_accuracy: 0.4267 - val_precision: 0.4307 - val_recall: 0.4267\n",
            "Epoch 912/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4735 - accuracy: 0.8065 - precision: 0.8234 - recall: 0.7768 - val_loss: 2.7515 - val_accuracy: 0.4520 - val_precision: 0.4574 - val_recall: 0.4507\n",
            "Epoch 913/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4881 - accuracy: 0.7991 - precision: 0.8160 - recall: 0.7768 - val_loss: 2.9613 - val_accuracy: 0.4440 - val_precision: 0.4470 - val_recall: 0.4440\n",
            "Epoch 914/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4840 - accuracy: 0.8060 - precision: 0.8258 - recall: 0.7871 - val_loss: 2.8698 - val_accuracy: 0.4440 - val_precision: 0.4480 - val_recall: 0.4427\n",
            "Epoch 915/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4562 - accuracy: 0.8094 - precision: 0.8308 - recall: 0.7785 - val_loss: 2.8328 - val_accuracy: 0.4480 - val_precision: 0.4528 - val_recall: 0.4480\n",
            "Epoch 916/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4520 - accuracy: 0.8128 - precision: 0.8297 - recall: 0.7922 - val_loss: 2.7823 - val_accuracy: 0.4480 - val_precision: 0.4507 - val_recall: 0.4453\n",
            "Epoch 917/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4601 - accuracy: 0.8060 - precision: 0.8238 - recall: 0.7894 - val_loss: 2.7242 - val_accuracy: 0.4547 - val_precision: 0.4582 - val_recall: 0.4533\n",
            "Epoch 918/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4823 - accuracy: 0.8094 - precision: 0.8270 - recall: 0.7796 - val_loss: 2.5855 - val_accuracy: 0.4493 - val_precision: 0.4549 - val_recall: 0.4440\n",
            "Epoch 919/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.5396 - accuracy: 0.7842 - precision: 0.8028 - recall: 0.7527 - val_loss: 2.3566 - val_accuracy: 0.4773 - val_precision: 0.4802 - val_recall: 0.4693\n",
            "Epoch 920/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4761 - accuracy: 0.8008 - precision: 0.8162 - recall: 0.7728 - val_loss: 2.3428 - val_accuracy: 0.4893 - val_precision: 0.4993 - val_recall: 0.4880\n",
            "Epoch 921/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4760 - accuracy: 0.8002 - precision: 0.8171 - recall: 0.7722 - val_loss: 2.6671 - val_accuracy: 0.4773 - val_precision: 0.4745 - val_recall: 0.4720\n",
            "Epoch 922/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4699 - accuracy: 0.8088 - precision: 0.8265 - recall: 0.7882 - val_loss: 2.4616 - val_accuracy: 0.4627 - val_precision: 0.4700 - val_recall: 0.4600\n",
            "Epoch 923/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4567 - accuracy: 0.8145 - precision: 0.8307 - recall: 0.7951 - val_loss: 2.3802 - val_accuracy: 0.4853 - val_precision: 0.4918 - val_recall: 0.4813\n",
            "Epoch 924/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4475 - accuracy: 0.8111 - precision: 0.8290 - recall: 0.7882 - val_loss: 2.3148 - val_accuracy: 0.4893 - val_precision: 0.4905 - val_recall: 0.4827\n",
            "Epoch 925/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4451 - accuracy: 0.8100 - precision: 0.8266 - recall: 0.7888 - val_loss: 2.3156 - val_accuracy: 0.4800 - val_precision: 0.4871 - val_recall: 0.4773\n",
            "Epoch 926/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4682 - accuracy: 0.8071 - precision: 0.8258 - recall: 0.7813 - val_loss: 2.4536 - val_accuracy: 0.4667 - val_precision: 0.4716 - val_recall: 0.4653\n",
            "Epoch 927/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4545 - accuracy: 0.8071 - precision: 0.8254 - recall: 0.7848 - val_loss: 2.5176 - val_accuracy: 0.4627 - val_precision: 0.4694 - val_recall: 0.4600\n",
            "Epoch 928/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4543 - accuracy: 0.8180 - precision: 0.8339 - recall: 0.7991 - val_loss: 2.3281 - val_accuracy: 0.4733 - val_precision: 0.4759 - val_recall: 0.4733\n",
            "Epoch 929/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4582 - accuracy: 0.8197 - precision: 0.8302 - recall: 0.7951 - val_loss: 2.3933 - val_accuracy: 0.4707 - val_precision: 0.4750 - val_recall: 0.4680\n",
            "Epoch 930/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4545 - accuracy: 0.8094 - precision: 0.8289 - recall: 0.7876 - val_loss: 2.4045 - val_accuracy: 0.4640 - val_precision: 0.4696 - val_recall: 0.4640\n",
            "Epoch 931/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4372 - accuracy: 0.8288 - precision: 0.8497 - recall: 0.8060 - val_loss: 2.5339 - val_accuracy: 0.4627 - val_precision: 0.4720 - val_recall: 0.4613\n",
            "Epoch 932/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4425 - accuracy: 0.8266 - precision: 0.8370 - recall: 0.8025 - val_loss: 2.5689 - val_accuracy: 0.4560 - val_precision: 0.4603 - val_recall: 0.4560\n",
            "Epoch 933/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4379 - accuracy: 0.8185 - precision: 0.8361 - recall: 0.7974 - val_loss: 2.6528 - val_accuracy: 0.4480 - val_precision: 0.4532 - val_recall: 0.4453\n",
            "Epoch 934/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4418 - accuracy: 0.8174 - precision: 0.8364 - recall: 0.8019 - val_loss: 2.6527 - val_accuracy: 0.4573 - val_precision: 0.4629 - val_recall: 0.4573\n",
            "Epoch 935/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4149 - accuracy: 0.8403 - precision: 0.8525 - recall: 0.8203 - val_loss: 2.5128 - val_accuracy: 0.4640 - val_precision: 0.4684 - val_recall: 0.4640\n",
            "Epoch 936/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4180 - accuracy: 0.8203 - precision: 0.8403 - recall: 0.8071 - val_loss: 2.6490 - val_accuracy: 0.4600 - val_precision: 0.4617 - val_recall: 0.4587\n",
            "Epoch 937/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4432 - accuracy: 0.8306 - precision: 0.8427 - recall: 0.8094 - val_loss: 2.9400 - val_accuracy: 0.4587 - val_precision: 0.4604 - val_recall: 0.4573\n",
            "Epoch 938/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4558 - accuracy: 0.8128 - precision: 0.8268 - recall: 0.7979 - val_loss: 2.9077 - val_accuracy: 0.4653 - val_precision: 0.4670 - val_recall: 0.4627\n",
            "Epoch 939/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4125 - accuracy: 0.8300 - precision: 0.8449 - recall: 0.8105 - val_loss: 2.9182 - val_accuracy: 0.4613 - val_precision: 0.4617 - val_recall: 0.4587\n",
            "Epoch 940/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8460 - precision: 0.8599 - recall: 0.8329 - val_loss: 2.8588 - val_accuracy: 0.4640 - val_precision: 0.4652 - val_recall: 0.4640\n",
            "Epoch 941/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4340 - accuracy: 0.8208 - precision: 0.8410 - recall: 0.8054 - val_loss: 2.9206 - val_accuracy: 0.4600 - val_precision: 0.4624 - val_recall: 0.4587\n",
            "Epoch 942/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4493 - accuracy: 0.8168 - precision: 0.8331 - recall: 0.8002 - val_loss: 2.7884 - val_accuracy: 0.4627 - val_precision: 0.4651 - val_recall: 0.4627\n",
            "Epoch 943/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4380 - accuracy: 0.8117 - precision: 0.8272 - recall: 0.7865 - val_loss: 2.9970 - val_accuracy: 0.4680 - val_precision: 0.4692 - val_recall: 0.4667\n",
            "Epoch 944/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4609 - accuracy: 0.8140 - precision: 0.8321 - recall: 0.7888 - val_loss: 2.9218 - val_accuracy: 0.4733 - val_precision: 0.4758 - val_recall: 0.4720\n",
            "Epoch 945/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4473 - accuracy: 0.8248 - precision: 0.8394 - recall: 0.7991 - val_loss: 2.8396 - val_accuracy: 0.4640 - val_precision: 0.4645 - val_recall: 0.4627\n",
            "Epoch 946/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4484 - accuracy: 0.8122 - precision: 0.8237 - recall: 0.7888 - val_loss: 2.7219 - val_accuracy: 0.4667 - val_precision: 0.4664 - val_recall: 0.4627\n",
            "Epoch 947/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4648 - accuracy: 0.8151 - precision: 0.8269 - recall: 0.7905 - val_loss: 3.0329 - val_accuracy: 0.4533 - val_precision: 0.4552 - val_recall: 0.4533\n",
            "Epoch 948/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.5017 - accuracy: 0.7876 - precision: 0.8068 - recall: 0.7624 - val_loss: 3.0076 - val_accuracy: 0.4427 - val_precision: 0.4444 - val_recall: 0.4427\n",
            "Epoch 949/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4801 - accuracy: 0.7916 - precision: 0.8074 - recall: 0.7653 - val_loss: 2.8437 - val_accuracy: 0.4547 - val_precision: 0.4583 - val_recall: 0.4547\n",
            "Epoch 950/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4920 - accuracy: 0.7962 - precision: 0.8113 - recall: 0.7676 - val_loss: 3.1290 - val_accuracy: 0.4360 - val_precision: 0.4351 - val_recall: 0.4333\n",
            "Epoch 951/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4895 - accuracy: 0.7916 - precision: 0.8081 - recall: 0.7665 - val_loss: 3.1045 - val_accuracy: 0.4213 - val_precision: 0.4240 - val_recall: 0.4200\n",
            "Epoch 952/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4726 - accuracy: 0.8014 - precision: 0.8211 - recall: 0.7779 - val_loss: 3.2695 - val_accuracy: 0.4200 - val_precision: 0.4209 - val_recall: 0.4187\n",
            "Epoch 953/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4590 - accuracy: 0.8140 - precision: 0.8320 - recall: 0.7911 - val_loss: 3.0117 - val_accuracy: 0.4347 - val_precision: 0.4357 - val_recall: 0.4293\n",
            "Epoch 954/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4436 - accuracy: 0.8226 - precision: 0.8433 - recall: 0.8008 - val_loss: 2.8929 - val_accuracy: 0.4347 - val_precision: 0.4390 - val_recall: 0.4320\n",
            "Epoch 955/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4741 - accuracy: 0.8168 - precision: 0.8271 - recall: 0.7968 - val_loss: 2.8372 - val_accuracy: 0.4453 - val_precision: 0.4438 - val_recall: 0.4373\n",
            "Epoch 956/1000\n",
            "55/55 [==============================] - 1s 13ms/step - loss: 0.4564 - accuracy: 0.8122 - precision: 0.8246 - recall: 0.7911 - val_loss: 2.8457 - val_accuracy: 0.4533 - val_precision: 0.4555 - val_recall: 0.4507\n",
            "Epoch 957/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4516 - accuracy: 0.8266 - precision: 0.8392 - recall: 0.8065 - val_loss: 2.8631 - val_accuracy: 0.4600 - val_precision: 0.4597 - val_recall: 0.4560\n",
            "Epoch 958/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4488 - accuracy: 0.8128 - precision: 0.8345 - recall: 0.7911 - val_loss: 2.9609 - val_accuracy: 0.4480 - val_precision: 0.4485 - val_recall: 0.4467\n",
            "Epoch 959/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4713 - accuracy: 0.8134 - precision: 0.8284 - recall: 0.7876 - val_loss: 2.9718 - val_accuracy: 0.4520 - val_precision: 0.4525 - val_recall: 0.4507\n",
            "Epoch 960/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4490 - accuracy: 0.8088 - precision: 0.8274 - recall: 0.7876 - val_loss: 2.9065 - val_accuracy: 0.4600 - val_precision: 0.4625 - val_recall: 0.4600\n",
            "Epoch 961/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4469 - accuracy: 0.8128 - precision: 0.8292 - recall: 0.7922 - val_loss: 2.9116 - val_accuracy: 0.4613 - val_precision: 0.4631 - val_recall: 0.4600\n",
            "Epoch 962/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4384 - accuracy: 0.8185 - precision: 0.8339 - recall: 0.8019 - val_loss: 3.0406 - val_accuracy: 0.4613 - val_precision: 0.4625 - val_recall: 0.4600\n",
            "Epoch 963/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4257 - accuracy: 0.8317 - precision: 0.8462 - recall: 0.8094 - val_loss: 2.9333 - val_accuracy: 0.4587 - val_precision: 0.4604 - val_recall: 0.4573\n",
            "Epoch 964/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4396 - accuracy: 0.8220 - precision: 0.8393 - recall: 0.8100 - val_loss: 2.7531 - val_accuracy: 0.4760 - val_precision: 0.4773 - val_recall: 0.4760\n",
            "Epoch 965/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4809 - accuracy: 0.7997 - precision: 0.8109 - recall: 0.7779 - val_loss: 2.9305 - val_accuracy: 0.4653 - val_precision: 0.4658 - val_recall: 0.4627\n",
            "Epoch 966/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4483 - accuracy: 0.8197 - precision: 0.8298 - recall: 0.7979 - val_loss: 2.5081 - val_accuracy: 0.4760 - val_precision: 0.4798 - val_recall: 0.4747\n",
            "Epoch 967/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4429 - accuracy: 0.8082 - precision: 0.8270 - recall: 0.7853 - val_loss: 2.6081 - val_accuracy: 0.4693 - val_precision: 0.4749 - val_recall: 0.4667\n",
            "Epoch 968/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4435 - accuracy: 0.8208 - precision: 0.8309 - recall: 0.7985 - val_loss: 2.6273 - val_accuracy: 0.4720 - val_precision: 0.4757 - val_recall: 0.4707\n",
            "Epoch 969/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4433 - accuracy: 0.8214 - precision: 0.8334 - recall: 0.7962 - val_loss: 2.6189 - val_accuracy: 0.4693 - val_precision: 0.4744 - val_recall: 0.4693\n",
            "Epoch 970/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4521 - accuracy: 0.8151 - precision: 0.8226 - recall: 0.7911 - val_loss: 2.5624 - val_accuracy: 0.4747 - val_precision: 0.4745 - val_recall: 0.4720\n",
            "Epoch 971/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4678 - accuracy: 0.7991 - precision: 0.8153 - recall: 0.7756 - val_loss: 2.5340 - val_accuracy: 0.4747 - val_precision: 0.4759 - val_recall: 0.4733\n",
            "Epoch 972/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.4627 - accuracy: 0.8185 - precision: 0.8362 - recall: 0.8037 - val_loss: 2.5206 - val_accuracy: 0.4787 - val_precision: 0.4798 - val_recall: 0.4760\n",
            "Epoch 973/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4275 - accuracy: 0.8231 - precision: 0.8436 - recall: 0.8025 - val_loss: 2.7322 - val_accuracy: 0.4653 - val_precision: 0.4665 - val_recall: 0.4640\n",
            "Epoch 974/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.4515 - accuracy: 0.8185 - precision: 0.8355 - recall: 0.7997 - val_loss: 2.6350 - val_accuracy: 0.4667 - val_precision: 0.4665 - val_recall: 0.4640\n",
            "Epoch 975/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.4267 - accuracy: 0.8374 - precision: 0.8516 - recall: 0.8180 - val_loss: 2.6880 - val_accuracy: 0.4613 - val_precision: 0.4651 - val_recall: 0.4613\n",
            "Epoch 976/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.4421 - accuracy: 0.8088 - precision: 0.8275 - recall: 0.7882 - val_loss: 2.6535 - val_accuracy: 0.4693 - val_precision: 0.4706 - val_recall: 0.4693\n",
            "Epoch 977/1000\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.4224 - accuracy: 0.8329 - precision: 0.8493 - recall: 0.8128 - val_loss: 2.6480 - val_accuracy: 0.4733 - val_precision: 0.4752 - val_recall: 0.4733\n",
            "Epoch 978/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4631 - accuracy: 0.8060 - precision: 0.8276 - recall: 0.7939 - val_loss: 2.5484 - val_accuracy: 0.4760 - val_precision: 0.4763 - val_recall: 0.4693\n",
            "Epoch 979/1000\n",
            "55/55 [==============================] - 1s 13ms/step - loss: 0.4476 - accuracy: 0.8174 - precision: 0.8333 - recall: 0.7985 - val_loss: 2.6744 - val_accuracy: 0.4747 - val_precision: 0.4771 - val_recall: 0.4720\n",
            "Epoch 980/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4741 - accuracy: 0.8100 - precision: 0.8262 - recall: 0.7894 - val_loss: 2.8676 - val_accuracy: 0.4773 - val_precision: 0.4792 - val_recall: 0.4760\n",
            "Epoch 981/1000\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.4170 - accuracy: 0.8300 - precision: 0.8443 - recall: 0.8100 - val_loss: 3.1519 - val_accuracy: 0.4893 - val_precision: 0.4920 - val_recall: 0.4893\n",
            "Epoch 982/1000\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.4400 - accuracy: 0.8208 - precision: 0.8355 - recall: 0.8025 - val_loss: 3.1503 - val_accuracy: 0.4827 - val_precision: 0.4833 - val_recall: 0.4813\n",
            "Epoch 983/1000\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4791 - accuracy: 0.8019 - precision: 0.8151 - recall: 0.7796 - val_loss: 3.1431 - val_accuracy: 0.4787 - val_precision: 0.4793 - val_recall: 0.4773\n",
            "Epoch 984/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4408 - accuracy: 0.8237 - precision: 0.8395 - recall: 0.8054 - val_loss: 2.9398 - val_accuracy: 0.4667 - val_precision: 0.4690 - val_recall: 0.4640\n",
            "Epoch 985/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4179 - accuracy: 0.8363 - precision: 0.8528 - recall: 0.8157 - val_loss: 2.7717 - val_accuracy: 0.4747 - val_precision: 0.4772 - val_recall: 0.4747\n",
            "Epoch 986/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4631 - accuracy: 0.8082 - precision: 0.8261 - recall: 0.7888 - val_loss: 2.9168 - val_accuracy: 0.4613 - val_precision: 0.4618 - val_recall: 0.4600\n",
            "Epoch 987/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4432 - accuracy: 0.8203 - precision: 0.8352 - recall: 0.8008 - val_loss: 2.8256 - val_accuracy: 0.4520 - val_precision: 0.4569 - val_recall: 0.4520\n",
            "Epoch 988/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4504 - accuracy: 0.8203 - precision: 0.8348 - recall: 0.7928 - val_loss: 2.6683 - val_accuracy: 0.4640 - val_precision: 0.4696 - val_recall: 0.4640\n",
            "Epoch 989/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4663 - accuracy: 0.8094 - precision: 0.8276 - recall: 0.7939 - val_loss: 2.7885 - val_accuracy: 0.4573 - val_precision: 0.4590 - val_recall: 0.4547\n",
            "Epoch 990/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4415 - accuracy: 0.8145 - precision: 0.8281 - recall: 0.7968 - val_loss: 2.9290 - val_accuracy: 0.4653 - val_precision: 0.4669 - val_recall: 0.4613\n",
            "Epoch 991/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4394 - accuracy: 0.8220 - precision: 0.8404 - recall: 0.8048 - val_loss: 2.7760 - val_accuracy: 0.4707 - val_precision: 0.4719 - val_recall: 0.4707\n",
            "Epoch 992/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4229 - accuracy: 0.8392 - precision: 0.8483 - recall: 0.8197 - val_loss: 2.6198 - val_accuracy: 0.4680 - val_precision: 0.4696 - val_recall: 0.4640\n",
            "Epoch 993/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4466 - accuracy: 0.8306 - precision: 0.8451 - recall: 0.8117 - val_loss: 2.7623 - val_accuracy: 0.4653 - val_precision: 0.4671 - val_recall: 0.4640\n",
            "Epoch 994/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4383 - accuracy: 0.8168 - precision: 0.8316 - recall: 0.7974 - val_loss: 2.7211 - val_accuracy: 0.4547 - val_precision: 0.4587 - val_recall: 0.4520\n",
            "Epoch 995/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4137 - accuracy: 0.8329 - precision: 0.8475 - recall: 0.8145 - val_loss: 2.7079 - val_accuracy: 0.4693 - val_precision: 0.4717 - val_recall: 0.4667\n",
            "Epoch 996/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4111 - accuracy: 0.8243 - precision: 0.8386 - recall: 0.8031 - val_loss: 2.8575 - val_accuracy: 0.4600 - val_precision: 0.4598 - val_recall: 0.4573\n",
            "Epoch 997/1000\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4241 - accuracy: 0.8300 - precision: 0.8420 - recall: 0.8117 - val_loss: 2.9470 - val_accuracy: 0.4547 - val_precision: 0.4571 - val_recall: 0.4547\n",
            "Epoch 998/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4372 - accuracy: 0.8300 - precision: 0.8414 - recall: 0.8140 - val_loss: 3.0256 - val_accuracy: 0.4533 - val_precision: 0.4550 - val_recall: 0.4520\n",
            "Epoch 999/1000\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4399 - accuracy: 0.8283 - precision: 0.8419 - recall: 0.8111 - val_loss: 2.9008 - val_accuracy: 0.4600 - val_precision: 0.4611 - val_recall: 0.4587\n",
            "Epoch 1000/1000\n",
            "55/55 [==============================] - 0s 8ms/step - loss: 0.4260 - accuracy: 0.8191 - precision: 0.8417 - recall: 0.8002 - val_loss: 2.9268 - val_accuracy: 0.4600 - val_precision: 0.4662 - val_recall: 0.4600\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# Assuming df is your DataFrame and 'true_signal' is the target column\n",
        "target = 'true_signal'\n",
        "features = df.drop(target, axis=1)\n",
        "labels = df[target]\n",
        "\n",
        "# Apply MinMaxScaler to the features\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_features = scaler.fit_transform(features)\n",
        "\n",
        "# One-hot encode labels\n",
        "y = to_categorical(labels+1)  # Adding 1 to shift the labels to 0, 1, 2\n",
        "\n",
        "# Split the data into train and test sets\n",
        "train_size = int(len(scaled_features) * 0.7)\n",
        "test_size = len(scaled_features) - train_size\n",
        "X_train, X_test = scaled_features[0:train_size,:], scaled_features[train_size:len(scaled_features),:]\n",
        "y_train, y_test = y[0:train_size], y[train_size:len(y)]\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(680, input_shape=(X_train.shape[1],)))  # Freeze this layer\n",
        "model.add(Dropout(0.5))  # Add dropout for regularization\n",
        "model.add(BatchNormalization())  # Add batch normalization\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(0.5))  # Add dropout for regularization\n",
        "model.add(BatchNormalization())  # Add batch normalization\n",
        "model.add(Dense(3, activation='softmax'))  # Assuming there are 3 classes (0, 1, 2)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', Precision(), Recall()])\n",
        "\n",
        "# Calculate class weights\n",
        "total_samples = len(labels)\n",
        "class_samples = np.bincount(labels+1)\n",
        "num_classes = len(class_samples)\n",
        "class_weights = {i: total_samples / (num_classes * class_samples[i]) for i in range(num_classes)}\n",
        "\n",
        "# Train the model with validation data\n",
        "model.fit(X_train, y_train, epochs=1000, validation_data=(X_test, y_test), class_weight=class_weights)\n",
        "\n",
        "# Make predictions\n",
        "yhat = model.predict(X_test, verbose=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmugjZupoxaj"
      },
      "source": [
        "This didn't work again, going back to something as simple as using open, high, low and close with 5 indicators with standard windows  and then using LSTMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CuwUFUMZ52Lq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import signal\n",
        "from scipy.stats import skew, kurtosis\n",
        "import pywt\n",
        "from scipy.signal import argrelextrema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ak_OqNas52Lr"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"/content/Manappuram_10minute.csv\")\n",
        "df.tail(5)\n",
        "# Converting Date column into datetime dftype\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df.set_index('Date', inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccdNAku552Lr",
        "outputId": "4019ced2-6062-44cf-ee3a-db8f4b944144"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Open', 'High', 'Low', 'Close', 'Volume'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IpwI2iZ67P9f"
      },
      "outputs": [],
      "source": [
        "# calculates SMA using \"n\" as the rolling window size\n",
        "def ma_calc(df, n):\n",
        "  df[\"sma\"] = df.Close.rolling(window=n).mean()\n",
        "  return df\n",
        "\n",
        "# calculates SMA using \"m\" and \"n\" as the rolling window size\n",
        "def longshort_ma_calc(df, m, n):\n",
        "  df[\"sma_short\"] = df.Close.rolling(window=min(m,n)).mean()\n",
        "  df[\"sma_long\"] = df.Close.rolling(window=max(m,n)).mean()\n",
        "  return df\n",
        "\n",
        "# calculates EMA using \"n\" as the rolling window size\n",
        "def ema_calc(df, n):\n",
        "  df[\"ema\"] = df.Close.ewm(span=n, adjust=False).mean()\n",
        "  return df\n",
        "\n",
        "\n",
        "def longshort_ema_calc(df, m, n):\n",
        "  df[\"ema_short\"] = df.Close.ewm(span=min(m,n), adjust=False).mean()\n",
        "  df[\"ema_long\"] = df.Close.ewm(span=max(m,n), adjust=False).mean()\n",
        "  return df\n",
        "\n",
        "# calculates RSI using \"n\" as the lookback period\n",
        "def rsi_calc(df, n):\n",
        "  df['rsi'] = 100 - (100 / (1 + df['Close'].diff().apply(lambda x: x if x > 0 else 0).rolling(window=n).mean() / df['Close'].diff().apply(lambda x: -x if x < 0 else 0).rolling(window=n).mean()))\n",
        "  return df\n",
        "\n",
        "# calculates OBV\n",
        "def obv_calc(df):\n",
        "  df['obv'] = (np.sign(df['Close'].diff()) * df['Volume']).fillna(0).cumsum()\n",
        "  return df\n",
        "\n",
        "def bb_calc(df, n):\n",
        "  df[\"sma\"] = df.Close.rolling(window=n).mean()\n",
        "  df[\"std\"] = df.Close.rolling(window=n).std()\n",
        "  df[\"upper_bb\"] = df[\"sma\"] + (2 * df[\"std\"])\n",
        "  df[\"lower_bb\"] = df[\"sma\"] - (2 * df[\"std\"])\n",
        "  return df\n",
        "\n",
        "# Volume weighted average price\n",
        "def vwap_calc(df):\n",
        "    df['vwap'] = (df['Volume'] * df['Close']).cumsum() / df['Volume'].cumsum()\n",
        "    return df\n",
        "\n",
        "# Supertrend Indicator\n",
        "def supertrend_calc(df, period, multiplier):\n",
        "    # Calculate basic upper and lower bands\n",
        "    df['hl_avg'] = (df['High'] + df['Low']) / 2\n",
        "    df['range'] = df['High'] - df['Low']\n",
        "    df['upper_band'] = df['hl_avg'] + multiplier * df['range']\n",
        "    df['lower_band'] = df['hl_avg'] - multiplier * df['range']\n",
        "\n",
        "    # Calculate final upper and lower bands\n",
        "    df['upper_band_final'] = np.where((df['upper_band'] < df['upper_band'].shift(1)) | (df['Close'] > df['upper_band'].shift(1)), df['upper_band'], df['upper_band'].shift(1))\n",
        "    df['lower_band_final'] = np.where((df['lower_band'] > df['lower_band'].shift(1)) | (df['Close'] < df['lower_band'].shift(1)), df['lower_band'], df['lower_band'].shift(1))\n",
        "\n",
        "    # Calculate Supertrend\n",
        "    df['supertrend'] = np.where(df['Close'] <= df['upper_band_final'], df['upper_band_final'], df['lower_band_final'])\n",
        "    df['supertrend'] = np.where(df['Close'] >= df['lower_band_final'], df['lower_band_final'], df['supertrend'])\n",
        "\n",
        "    return df\n",
        "\n",
        "# calculates Average Directional Index (ADX)\n",
        "def adx_calc(df, n):\n",
        "    df['hl_diff'] = df['High'] - df['Low']\n",
        "    df['hc_diff'] = abs(df['High'] - df['Close'].shift(1))\n",
        "    df['lc_diff'] = abs(df['Low'] - df['Close'].shift(1))\n",
        "    df['tr'] = df[['hl_diff', 'hc_diff', 'lc_diff']].max(axis=1)\n",
        "    df['+dm'] = np.where((df['High'] > df['High'].shift(1)) & (df['High'] - df['High'].shift(1) > df['Low'].shift(1) - df['Low']), df['High'] - df['High'].shift(1), 0)\n",
        "    df['-dm'] = np.where((df['Low'] < df['Low'].shift(1)) & (df['High'].shift(1) - df['High'] < df['Low'].shift(1) - df['Low']), df['Low'].shift(1) - df['Low'], 0)\n",
        "    df['tr_ema'] = df['tr'].ewm(span=n, adjust=False).mean()\n",
        "    df['+dm_ema'] = df['+dm'].ewm(span=n, adjust=False).mean()\n",
        "    df['-dm_ema'] = df['-dm'].ewm(span=n, adjust=False).mean()\n",
        "    df['+di'] = (df['+dm_ema'] / df['tr_ema']) * 100\n",
        "    df['-di'] = (df['-dm_ema'] / df['tr_ema']) * 100\n",
        "    df['dx'] = (abs(df['+di'] - df['-di']) / (df['+di'] + df['-di'])) * 100\n",
        "    df['adx'] = df['dx'].rolling(window=n).mean()\n",
        "\n",
        "    return df\n",
        "\n",
        "# calculates MACD\n",
        "def macd_calc(df, short_n, long_n, signal_n):\n",
        "    df['ema_short'] = df['Close'].ewm(span=short_n, adjust=False).mean()\n",
        "    df['ema_long'] = df['Close'].ewm(span=long_n, adjust=False).mean()\n",
        "    df['macd_line'] = df['ema_short'] - df['ema_long']\n",
        "    df['signal_line'] = df['macd_line'].ewm(span=signal_n, adjust=False).mean()\n",
        "    df['macd_histogram'] = df['macd_line'] - df['signal_line']\n",
        "\n",
        "    return df\n",
        "\n",
        "def find_extrema(df, n):\n",
        "    df['min'] = df.iloc[argrelextrema(df['Close'].values, np.less_equal, order=n)[0]]['Close']\n",
        "    df['max'] = df.iloc[argrelextrema(df['Close'].values, np.greater_equal, order=n)[0]]['Close']\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6zKjAW_g7P9g"
      },
      "outputs": [],
      "source": [
        "df=find_extrema(df,16)\n",
        "df=ma_calc(df,524)\n",
        "df=longshort_ma_calc(df,564,4)\n",
        "df=ema_calc(df,63)\n",
        "df=longshort_ema_calc(df,374,5)\n",
        "df=rsi_calc(df,118)\n",
        "df=adx_calc(df,32)\n",
        "\n",
        "# columns_to_drop = ['hl_diff', 'hc_diff', 'lc_diff', 'tr', '+dm', '-dm', 'tr_ema', '+dm_ema', '-dm_ema', '+di', '-di', 'dx']\n",
        "\n",
        "# # Drop the columns\n",
        "# df = df.drop(columns=columns_to_drop)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZqNAHVbM7P9g"
      },
      "outputs": [],
      "source": [
        " # Initialize the signal column with hold signals\n",
        "df['true_signal'] = 0\n",
        "\n",
        "# Generate buy signals at local minima\n",
        "df.loc[df['min'].notna(), 'true_signal'] = 1\n",
        "\n",
        "# Generate sell signals at local maxima\n",
        "df.loc[df['max'].notna(), 'true_signal'] = -1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_ArbVmxy7P9h"
      },
      "outputs": [],
      "source": [
        "# As the buy/sell signals themselves are sparse,I'd predict positions instead of signals\n",
        "for day in np.unique(df.index.date):\n",
        "    indices = df[df.index.date == day].index\n",
        "    for i in range(len(indices) - 1):  # subtracting 1 because we're looking ahead by 1 row\n",
        "        if df.loc[indices[i], \"true_signal\"] == 1 and df.loc[indices[i + 1], \"true_signal\"] == 0:\n",
        "            df.loc[indices[i + 1], \"true_signal\"] = 1\n",
        "        elif df.loc[indices[i], \"true_signal\"] == -1 and df.loc[indices[i + 1], \"true_signal\"] == 0:\n",
        "            df.loc[indices[i + 1], \"true_signal\"] = -1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ipYxHgB7P9g",
        "outputId": "63a4337c-57e9-4101-9bf5-03a3f1755df1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0    971\n",
              "-1    811\n",
              " 1    715\n",
              "Name: true_signal, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "df.true_signal.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 882
        },
        "id": "u1ZmsRfe5vl7",
        "outputId": "ccbe1708-dd70-4a86-a072-4cefbe08b877"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       Open    High     Low   Close   Volume  min     max  \\\n",
              "Date                                                                        \n",
              "2020-01-21 09:15:00  179.30  180.20  178.25  180.15   173897  NaN     NaN   \n",
              "2020-01-21 09:25:00  180.00  181.30  180.00  180.50   175277  NaN     NaN   \n",
              "2020-01-21 09:35:00  180.50  181.05  180.25  180.55   110920  NaN     NaN   \n",
              "2020-01-21 09:45:00  180.55  181.50  180.05  181.35    80456  NaN  181.35   \n",
              "2020-01-21 09:55:00  181.35  181.65  181.00  181.30    73996  NaN     NaN   \n",
              "...                     ...     ...     ...     ...      ...  ...     ...   \n",
              "2020-04-28 14:35:00  123.90  124.25  123.70  124.15   289726  NaN     NaN   \n",
              "2020-04-28 14:45:00  124.15  125.80  124.10  125.80  1706683  NaN     NaN   \n",
              "2020-04-28 14:55:00  125.80  125.80  125.80  125.80   145240  NaN     NaN   \n",
              "2020-04-28 15:05:00  125.80  131.50  125.80  130.85  3162404  NaN  130.85   \n",
              "2020-04-28 15:15:00  130.95  130.95  129.60  129.75   221556  NaN     NaN   \n",
              "\n",
              "                            sma  sma_short    sma_long  ...   +dm  -dm  \\\n",
              "Date                                                    ...              \n",
              "2020-01-21 09:15:00         NaN        NaN         NaN  ...  0.00  0.0   \n",
              "2020-01-21 09:25:00         NaN        NaN         NaN  ...  1.10  0.0   \n",
              "2020-01-21 09:35:00         NaN        NaN         NaN  ...  0.00  0.0   \n",
              "2020-01-21 09:45:00         NaN   180.6375         NaN  ...  0.45  0.2   \n",
              "2020-01-21 09:55:00         NaN   180.9250         NaN  ...  0.15  0.0   \n",
              "...                         ...        ...         ...  ...   ...  ...   \n",
              "2020-04-28 14:35:00  107.540935   123.8500  106.497872  ...  0.00  0.0   \n",
              "2020-04-28 14:45:00  107.598187   124.3500  106.556915  ...  1.55  0.0   \n",
              "2020-04-28 14:55:00  107.656489   124.8875  106.616046  ...  0.00  0.0   \n",
              "2020-04-28 15:05:00  107.724905   126.6500  106.681649  ...  5.70  0.0   \n",
              "2020-04-28 15:15:00  107.791794   128.0500  106.746365  ...  0.00  0.0   \n",
              "\n",
              "                       tr_ema   +dm_ema   -dm_ema        +di       -di  \\\n",
              "Date                                                                     \n",
              "2020-01-21 09:15:00  1.950000  0.000000  0.000000   0.000000  0.000000   \n",
              "2020-01-21 09:25:00  1.910606  0.066667  0.000000   3.489294  0.000000   \n",
              "2020-01-21 09:35:00  1.843297  0.062626  0.000000   3.397514  0.000000   \n",
              "2020-01-21 09:45:00  1.819460  0.086103  0.012121   4.732362  0.666198   \n",
              "2020-01-21 09:55:00  1.748584  0.089976  0.011387   5.145648  0.651189   \n",
              "...                       ...       ...       ...        ...       ...   \n",
              "2020-04-28 14:35:00  0.773377  0.248342  0.026264  32.111333  3.396051   \n",
              "2020-04-28 14:45:00  0.829536  0.327230  0.024673  39.447359  2.974254   \n",
              "2020-04-28 14:55:00  0.779261  0.307398  0.023177  39.447359  2.974254   \n",
              "2020-04-28 15:05:00  1.077488  0.634222  0.021773  58.861207  2.020675   \n",
              "2020-04-28 15:15:00  1.094004  0.595785  0.020453  54.459104  1.869553   \n",
              "\n",
              "                             dx        adx  true_signal  \n",
              "Date                                                     \n",
              "2020-01-21 09:15:00         NaN        NaN            0  \n",
              "2020-01-21 09:25:00  100.000000        NaN            0  \n",
              "2020-01-21 09:35:00  100.000000        NaN            0  \n",
              "2020-01-21 09:45:00   75.319414        NaN           -1  \n",
              "2020-01-21 09:55:00   77.532943        NaN           -1  \n",
              "...                         ...        ...          ...  \n",
              "2020-04-28 14:35:00   80.871298  79.639203            0  \n",
              "2020-04-28 14:45:00   85.977650  80.222201            0  \n",
              "2020-04-28 14:55:00   85.977650  80.587223            0  \n",
              "2020-04-28 15:05:00   93.361983  81.142447           -1  \n",
              "2020-04-28 15:15:00   93.361983  81.697672           -1  \n",
              "\n",
              "[2497 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c5f8dacd-4720-4771-a573-73ac269a1053\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "      <th>sma</th>\n",
              "      <th>sma_short</th>\n",
              "      <th>sma_long</th>\n",
              "      <th>...</th>\n",
              "      <th>+dm</th>\n",
              "      <th>-dm</th>\n",
              "      <th>tr_ema</th>\n",
              "      <th>+dm_ema</th>\n",
              "      <th>-dm_ema</th>\n",
              "      <th>+di</th>\n",
              "      <th>-di</th>\n",
              "      <th>dx</th>\n",
              "      <th>adx</th>\n",
              "      <th>true_signal</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-01-21 09:15:00</th>\n",
              "      <td>179.30</td>\n",
              "      <td>180.20</td>\n",
              "      <td>178.25</td>\n",
              "      <td>180.15</td>\n",
              "      <td>173897</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.950000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-21 09:25:00</th>\n",
              "      <td>180.00</td>\n",
              "      <td>181.30</td>\n",
              "      <td>180.00</td>\n",
              "      <td>180.50</td>\n",
              "      <td>175277</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>1.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.910606</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.489294</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-21 09:35:00</th>\n",
              "      <td>180.50</td>\n",
              "      <td>181.05</td>\n",
              "      <td>180.25</td>\n",
              "      <td>180.55</td>\n",
              "      <td>110920</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.843297</td>\n",
              "      <td>0.062626</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.397514</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-21 09:45:00</th>\n",
              "      <td>180.55</td>\n",
              "      <td>181.50</td>\n",
              "      <td>180.05</td>\n",
              "      <td>181.35</td>\n",
              "      <td>80456</td>\n",
              "      <td>NaN</td>\n",
              "      <td>181.35</td>\n",
              "      <td>NaN</td>\n",
              "      <td>180.6375</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.819460</td>\n",
              "      <td>0.086103</td>\n",
              "      <td>0.012121</td>\n",
              "      <td>4.732362</td>\n",
              "      <td>0.666198</td>\n",
              "      <td>75.319414</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-21 09:55:00</th>\n",
              "      <td>181.35</td>\n",
              "      <td>181.65</td>\n",
              "      <td>181.00</td>\n",
              "      <td>181.30</td>\n",
              "      <td>73996</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>180.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.748584</td>\n",
              "      <td>0.089976</td>\n",
              "      <td>0.011387</td>\n",
              "      <td>5.145648</td>\n",
              "      <td>0.651189</td>\n",
              "      <td>77.532943</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-28 14:35:00</th>\n",
              "      <td>123.90</td>\n",
              "      <td>124.25</td>\n",
              "      <td>123.70</td>\n",
              "      <td>124.15</td>\n",
              "      <td>289726</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>107.540935</td>\n",
              "      <td>123.8500</td>\n",
              "      <td>106.497872</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.773377</td>\n",
              "      <td>0.248342</td>\n",
              "      <td>0.026264</td>\n",
              "      <td>32.111333</td>\n",
              "      <td>3.396051</td>\n",
              "      <td>80.871298</td>\n",
              "      <td>79.639203</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-28 14:45:00</th>\n",
              "      <td>124.15</td>\n",
              "      <td>125.80</td>\n",
              "      <td>124.10</td>\n",
              "      <td>125.80</td>\n",
              "      <td>1706683</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>107.598187</td>\n",
              "      <td>124.3500</td>\n",
              "      <td>106.556915</td>\n",
              "      <td>...</td>\n",
              "      <td>1.55</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.829536</td>\n",
              "      <td>0.327230</td>\n",
              "      <td>0.024673</td>\n",
              "      <td>39.447359</td>\n",
              "      <td>2.974254</td>\n",
              "      <td>85.977650</td>\n",
              "      <td>80.222201</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-28 14:55:00</th>\n",
              "      <td>125.80</td>\n",
              "      <td>125.80</td>\n",
              "      <td>125.80</td>\n",
              "      <td>125.80</td>\n",
              "      <td>145240</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>107.656489</td>\n",
              "      <td>124.8875</td>\n",
              "      <td>106.616046</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.779261</td>\n",
              "      <td>0.307398</td>\n",
              "      <td>0.023177</td>\n",
              "      <td>39.447359</td>\n",
              "      <td>2.974254</td>\n",
              "      <td>85.977650</td>\n",
              "      <td>80.587223</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-28 15:05:00</th>\n",
              "      <td>125.80</td>\n",
              "      <td>131.50</td>\n",
              "      <td>125.80</td>\n",
              "      <td>130.85</td>\n",
              "      <td>3162404</td>\n",
              "      <td>NaN</td>\n",
              "      <td>130.85</td>\n",
              "      <td>107.724905</td>\n",
              "      <td>126.6500</td>\n",
              "      <td>106.681649</td>\n",
              "      <td>...</td>\n",
              "      <td>5.70</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.077488</td>\n",
              "      <td>0.634222</td>\n",
              "      <td>0.021773</td>\n",
              "      <td>58.861207</td>\n",
              "      <td>2.020675</td>\n",
              "      <td>93.361983</td>\n",
              "      <td>81.142447</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-28 15:15:00</th>\n",
              "      <td>130.95</td>\n",
              "      <td>130.95</td>\n",
              "      <td>129.60</td>\n",
              "      <td>129.75</td>\n",
              "      <td>221556</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>107.791794</td>\n",
              "      <td>128.0500</td>\n",
              "      <td>106.746365</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.094004</td>\n",
              "      <td>0.595785</td>\n",
              "      <td>0.020453</td>\n",
              "      <td>54.459104</td>\n",
              "      <td>1.869553</td>\n",
              "      <td>93.361983</td>\n",
              "      <td>81.697672</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2497 rows × 28 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5f8dacd-4720-4771-a573-73ac269a1053')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c5f8dacd-4720-4771-a573-73ac269a1053 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c5f8dacd-4720-4771-a573-73ac269a1053');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f97e77af-7c79-444a-8c23-6f736db202e3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f97e77af-7c79-444a-8c23-6f736db202e3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f97e77af-7c79-444a-8c23-6f736db202e3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_5cd9f810-86d3-43f8-a3e0-409f978f1dba\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5cd9f810-86d3-43f8-a3e0-409f978f1dba button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3FFdZk9S8nEN"
      },
      "outputs": [],
      "source": [
        "df=df.fillna(-100)\n",
        "target=df[\"true_signal\"]\n",
        "data_set=df.drop(\"true_signal\",axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7P4oGCuF8D13",
        "outputId": "5304357c-9365-4c68-e6e5-6d0d794f204a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.87199313 0.8744045  0.8869936  ... 0.         0.         0.        ]\n",
            " [0.87800687 0.88393244 0.90191898 ... 0.         1.         0.        ]\n",
            " [0.88230241 0.881767   0.90405117 ... 0.         1.         0.        ]\n",
            " ...\n",
            " [0.41237113 0.40320485 0.43965885 ... 0.05218798 0.92988825 0.99388848]\n",
            " [0.41237113 0.45257687 0.43965885 ... 0.03545593 0.96680991 0.99694424]\n",
            " [0.45661512 0.44781291 0.47206823 ... 0.03280426 0.96680991 1.        ]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "data_set_scaled = sc.fit_transform(data_set)\n",
        "print(data_set_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNcYJQew8tjY",
        "outputId": "5d91de09-db2e-469e-b5ac-ccce1452a62d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X: (2459, 38, 27)\n",
            "Shape of y: (2459, 1)\n",
            "1967\n",
            "(1967, 38, 27)\n",
            "(492, 38, 27)\n",
            "(1967, 1)\n",
            "(492, 1)\n",
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " ...\n",
            " [0]\n",
            " [0]\n",
            " [1]]\n"
          ]
        }
      ],
      "source": [
        "# Set the number of backcandles\n",
        "backcandles = 38\n",
        "\n",
        "# Initialize an empty list for X\n",
        "X = []\n",
        "\n",
        "# Loop over the first 7 columns of data_set_scaled\n",
        "for j in range(len(data_set.columns)):\n",
        "    X.append([data_set_scaled[i-backcandles:i, j] for i in range(backcandles, data_set_scaled.shape[0])])\n",
        "\n",
        "# Convert X to a numpy array and move the first axis to the third position\n",
        "X = np.moveaxis(np.array(X), 0, 2)\n",
        "\n",
        "\n",
        "# Create the target array y\n",
        "yi = np.array(target)\n",
        "y = np.reshape(yi[backcandles:], (len(yi) - backcandles, 1))  # Exclude the first 'backcandles' entries\n",
        "\n",
        "\n",
        "# Print the shapes of X and y\n",
        "print(f\"Shape of X: {X.shape}\")\n",
        "print(f\"Shape of y: {y.shape}\")\n",
        "\n",
        "# split data into train test sets\n",
        "splitlimit = int(len(X)*0.8)\n",
        "print(splitlimit)\n",
        "X_train, X_test = X[:splitlimit], X[splitlimit:]\n",
        "y_train, y_test = y[:splitlimit], y[splitlimit:]\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "m9M_DeRQ-f29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44159783-8b5c-434b-fb74-b3dc76b8ea34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1,  0,  1])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "np.unique(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlAQPLymBaQ9",
        "outputId": "9d36c942-c965-4d1f-d1cb-69e72a8cd318"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1967, 38, 27), (492, 38, 27))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "X_train.shape,X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YpWplc_9hH6",
        "outputId": "be166893-4113-4edf-b24f-d6a5fcae75c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 2.4524 - accuracy: 0.4545 - precision_1: 0.5255 - recall_1: 0.0366\n",
            "Epoch 1: val_accuracy improved from -inf to 0.21545, saving model to best_model.h5\n",
            "132/132 [==============================] - 5s 14ms/step - loss: 2.4524 - accuracy: 0.4545 - precision_1: 0.5255 - recall_1: 0.0366 - val_loss: 1.1733 - val_accuracy: 0.2154 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
            "Epoch 2/10000\n",
            " 17/132 [==>...........................] - ETA: 0s - loss: 1.1279 - accuracy: 0.3961 - precision_1: 1.0000 - recall_1: 0.0039        "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "127/132 [===========================>..] - ETA: 0s - loss: 1.0938 - accuracy: 0.4525 - precision_1: 0.5895 - recall_1: 0.0588\n",
            "Epoch 2: val_accuracy did not improve from 0.21545\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.0941 - accuracy: 0.4540 - precision_1: 0.5895 - recall_1: 0.0569 - val_loss: 1.1525 - val_accuracy: 0.2154 - val_precision_1: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
            "Epoch 3/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 1.0882 - accuracy: 0.4404 - precision_1: 0.5880 - recall_1: 0.0667\n",
            "Epoch 3: val_accuracy did not improve from 0.21545\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.0884 - accuracy: 0.4392 - precision_1: 0.5880 - recall_1: 0.0696 - val_loss: 1.2684 - val_accuracy: 0.2154 - val_precision_1: 0.2303 - val_recall_1: 0.1606\n",
            "Epoch 4/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 1.0854 - accuracy: 0.4490 - precision_1: 0.5968 - recall_1: 0.0979\n",
            "Epoch 4: val_accuracy did not improve from 0.21545\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.0843 - accuracy: 0.4504 - precision_1: 0.6024 - recall_1: 0.1002 - val_loss: 1.4163 - val_accuracy: 0.2154 - val_precision_1: 0.2154 - val_recall_1: 0.2154\n",
            "Epoch 5/10000\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 1.0809 - accuracy: 0.4556 - precision_1: 0.5721 - recall_1: 0.1344\n",
            "Epoch 5: val_accuracy did not improve from 0.21545\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.0820 - accuracy: 0.4530 - precision_1: 0.5705 - recall_1: 0.1357 - val_loss: 1.2339 - val_accuracy: 0.2154 - val_precision_1: 0.3333 - val_recall_1: 0.1159\n",
            "Epoch 6/10000\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 1.0810 - accuracy: 0.4667 - precision_1: 0.5966 - recall_1: 0.1301\n",
            "Epoch 6: val_accuracy did not improve from 0.21545\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.0799 - accuracy: 0.4672 - precision_1: 0.5940 - recall_1: 0.1301 - val_loss: 1.3495 - val_accuracy: 0.2154 - val_precision_1: 0.2154 - val_recall_1: 0.2154\n",
            "Epoch 7/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 1.0616 - accuracy: 0.4938 - precision_1: 0.5978 - recall_1: 0.1734\n",
            "Epoch 7: val_accuracy did not improve from 0.21545\n",
            "132/132 [==============================] - 1s 11ms/step - loss: 1.0616 - accuracy: 0.4942 - precision_1: 0.5997 - recall_1: 0.1759 - val_loss: 1.3202 - val_accuracy: 0.2154 - val_precision_1: 0.2122 - val_recall_1: 0.2114\n",
            "Epoch 8/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 1.0580 - accuracy: 0.4830 - precision_1: 0.6143 - recall_1: 0.1791\n",
            "Epoch 8: val_accuracy did not improve from 0.21545\n",
            "132/132 [==============================] - 1s 10ms/step - loss: 1.0581 - accuracy: 0.4825 - precision_1: 0.6132 - recall_1: 0.1790 - val_loss: 1.2805 - val_accuracy: 0.2154 - val_precision_1: 0.2052 - val_recall_1: 0.1931\n",
            "Epoch 9/10000\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 1.2208 - accuracy: 0.4928 - precision_1: 0.6004 - recall_1: 0.1531\n",
            "Epoch 9: val_accuracy did not improve from 0.21545\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.2164 - accuracy: 0.4911 - precision_1: 0.5988 - recall_1: 0.1525 - val_loss: 1.3448 - val_accuracy: 0.2154 - val_precision_1: 0.2154 - val_recall_1: 0.2154\n",
            "Epoch 10/10000\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 1.0563 - accuracy: 0.4937 - precision_1: 0.6051 - recall_1: 0.1751\n",
            "Epoch 10: val_accuracy did not improve from 0.21545\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.0563 - accuracy: 0.4931 - precision_1: 0.6018 - recall_1: 0.1744 - val_loss: 1.4273 - val_accuracy: 0.2154 - val_precision_1: 0.2154 - val_recall_1: 0.2154\n",
            "Epoch 11/10000\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 1.0383 - accuracy: 0.5280 - precision_1: 0.6116 - recall_1: 0.2251\n",
            "Epoch 11: val_accuracy did not improve from 0.21545\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.0376 - accuracy: 0.5267 - precision_1: 0.6149 - recall_1: 0.2272 - val_loss: 1.3914 - val_accuracy: 0.2154 - val_precision_1: 0.2147 - val_recall_1: 0.2134\n",
            "Epoch 12/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 1.0092 - accuracy: 0.5411 - precision_1: 0.6310 - recall_1: 0.3073\n",
            "Epoch 12: val_accuracy did not improve from 0.21545\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.0073 - accuracy: 0.5445 - precision_1: 0.6335 - recall_1: 0.3076 - val_loss: 1.5112 - val_accuracy: 0.2154 - val_precision_1: 0.2154 - val_recall_1: 0.2154\n",
            "Epoch 13/10000\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 1.0191 - accuracy: 0.5487 - precision_1: 0.6210 - recall_1: 0.2852\n",
            "Epoch 13: val_accuracy improved from 0.21545 to 0.22358, saving model to best_model.h5\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.0209 - accuracy: 0.5491 - precision_1: 0.6186 - recall_1: 0.2877 - val_loss: 1.2464 - val_accuracy: 0.2236 - val_precision_1: 0.2596 - val_recall_1: 0.2053\n",
            "Epoch 14/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.9854 - accuracy: 0.5658 - precision_1: 0.6416 - recall_1: 0.3513\n",
            "Epoch 14: val_accuracy did not improve from 0.22358\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.9854 - accuracy: 0.5658 - precision_1: 0.6416 - recall_1: 0.3513 - val_loss: 1.4390 - val_accuracy: 0.2154 - val_precision_1: 0.2286 - val_recall_1: 0.2114\n",
            "Epoch 15/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.9931 - accuracy: 0.5608 - precision_1: 0.6328 - recall_1: 0.3710\n",
            "Epoch 15: val_accuracy improved from 0.22358 to 0.30285, saving model to best_model.h5\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.9932 - accuracy: 0.5602 - precision_1: 0.6323 - recall_1: 0.3706 - val_loss: 1.3290 - val_accuracy: 0.3028 - val_precision_1: 0.3147 - val_recall_1: 0.2398\n",
            "Epoch 16/10000\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 0.9632 - accuracy: 0.5862 - precision_1: 0.6685 - recall_1: 0.3947\n",
            "Epoch 16: val_accuracy improved from 0.30285 to 0.31098, saving model to best_model.h5\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.9641 - accuracy: 0.5872 - precision_1: 0.6672 - recall_1: 0.3894 - val_loss: 1.2482 - val_accuracy: 0.3110 - val_precision_1: 0.3333 - val_recall_1: 0.2154\n",
            "Epoch 17/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.9656 - accuracy: 0.5875 - precision_1: 0.6733 - recall_1: 0.3682\n",
            "Epoch 17: val_accuracy improved from 0.31098 to 0.34146, saving model to best_model.h5\n",
            "132/132 [==============================] - 1s 10ms/step - loss: 0.9653 - accuracy: 0.5877 - precision_1: 0.6713 - recall_1: 0.3706 - val_loss: 1.3027 - val_accuracy: 0.3415 - val_precision_1: 0.3793 - val_recall_1: 0.2907\n",
            "Epoch 18/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.9501 - accuracy: 0.6016 - precision_1: 0.6708 - recall_1: 0.3907\n",
            "Epoch 18: val_accuracy did not improve from 0.34146\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.9508 - accuracy: 0.6014 - precision_1: 0.6693 - recall_1: 0.3920 - val_loss: 1.3198 - val_accuracy: 0.3232 - val_precision_1: 0.3317 - val_recall_1: 0.2703\n",
            "Epoch 19/10000\n",
            "130/132 [============================>.] - ETA: 0s - loss: 0.9497 - accuracy: 0.5805 - precision_1: 0.6613 - recall_1: 0.4215\n",
            "Epoch 19: val_accuracy did not improve from 0.34146\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.9485 - accuracy: 0.5821 - precision_1: 0.6629 - recall_1: 0.4220 - val_loss: 1.5339 - val_accuracy: 0.2927 - val_precision_1: 0.3105 - val_recall_1: 0.2764\n",
            "Epoch 20/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.9448 - accuracy: 0.5908 - precision_1: 0.6602 - recall_1: 0.4173\n",
            "Epoch 20: val_accuracy did not improve from 0.34146\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.9452 - accuracy: 0.5902 - precision_1: 0.6597 - recall_1: 0.4169 - val_loss: 1.4667 - val_accuracy: 0.3191 - val_precision_1: 0.3372 - val_recall_1: 0.2967\n",
            "Epoch 21/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.9318 - accuracy: 0.5919 - precision_1: 0.6727 - recall_1: 0.4361\n",
            "Epoch 21: val_accuracy did not improve from 0.34146\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.9313 - accuracy: 0.5923 - precision_1: 0.6732 - recall_1: 0.4367 - val_loss: 1.3819 - val_accuracy: 0.3232 - val_precision_1: 0.3673 - val_recall_1: 0.2785\n",
            "Epoch 22/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.9138 - accuracy: 0.6208 - precision_1: 0.7014 - recall_1: 0.4625\n",
            "Epoch 22: val_accuracy improved from 0.34146 to 0.38415, saving model to best_model.h5\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.9122 - accuracy: 0.6202 - precision_1: 0.7019 - recall_1: 0.4621 - val_loss: 1.2691 - val_accuracy: 0.3841 - val_precision_1: 0.4470 - val_recall_1: 0.3171\n",
            "Epoch 23/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.8993 - accuracy: 0.6270 - precision_1: 0.6961 - recall_1: 0.4687\n",
            "Epoch 23: val_accuracy did not improve from 0.38415\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.8998 - accuracy: 0.6263 - precision_1: 0.6951 - recall_1: 0.4682 - val_loss: 1.3795 - val_accuracy: 0.3415 - val_precision_1: 0.3688 - val_recall_1: 0.2886\n",
            "Epoch 24/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.9640 - accuracy: 0.5848 - precision_1: 0.6434 - recall_1: 0.3969\n",
            "Epoch 24: val_accuracy did not improve from 0.38415\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.9656 - accuracy: 0.5821 - precision_1: 0.6429 - recall_1: 0.3945 - val_loss: 1.3331 - val_accuracy: 0.3374 - val_precision_1: 0.3526 - val_recall_1: 0.2724\n",
            "Epoch 25/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.9188 - accuracy: 0.6109 - precision_1: 0.6779 - recall_1: 0.4677\n",
            "Epoch 25: val_accuracy did not improve from 0.38415\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.9176 - accuracy: 0.6116 - precision_1: 0.6778 - recall_1: 0.4662 - val_loss: 1.4227 - val_accuracy: 0.2846 - val_precision_1: 0.3073 - val_recall_1: 0.2724\n",
            "Epoch 26/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.8904 - accuracy: 0.6265 - precision_1: 0.6956 - recall_1: 0.4977\n",
            "Epoch 26: val_accuracy did not improve from 0.38415\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.8906 - accuracy: 0.6258 - precision_1: 0.6956 - recall_1: 0.4972 - val_loss: 1.4388 - val_accuracy: 0.3598 - val_precision_1: 0.3949 - val_recall_1: 0.3130\n",
            "Epoch 27/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.9070 - accuracy: 0.6096 - precision_1: 0.6735 - recall_1: 0.4698\n",
            "Epoch 27: val_accuracy did not improve from 0.38415\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.9070 - accuracy: 0.6096 - precision_1: 0.6735 - recall_1: 0.4698 - val_loss: 1.4784 - val_accuracy: 0.2846 - val_precision_1: 0.2867 - val_recall_1: 0.2663\n",
            "Epoch 28/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.8832 - accuracy: 0.6295 - precision_1: 0.7077 - recall_1: 0.5115\n",
            "Epoch 28: val_accuracy did not improve from 0.38415\n",
            "132/132 [==============================] - 1s 10ms/step - loss: 0.8830 - accuracy: 0.6299 - precision_1: 0.7080 - recall_1: 0.5114 - val_loss: 1.4599 - val_accuracy: 0.3272 - val_precision_1: 0.3413 - val_recall_1: 0.2886\n",
            "Epoch 29/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.8884 - accuracy: 0.6231 - precision_1: 0.6972 - recall_1: 0.5076\n",
            "Epoch 29: val_accuracy did not improve from 0.38415\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.8875 - accuracy: 0.6228 - precision_1: 0.6945 - recall_1: 0.5074 - val_loss: 1.4151 - val_accuracy: 0.2967 - val_precision_1: 0.2955 - val_recall_1: 0.2642\n",
            "Epoch 30/10000\n",
            "130/132 [============================>.] - ETA: 0s - loss: 0.8875 - accuracy: 0.6313 - precision_1: 0.6965 - recall_1: 0.4908\n",
            "Epoch 30: val_accuracy did not improve from 0.38415\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.8858 - accuracy: 0.6319 - precision_1: 0.6986 - recall_1: 0.4926 - val_loss: 1.7181 - val_accuracy: 0.3232 - val_precision_1: 0.3312 - val_recall_1: 0.3110\n",
            "Epoch 31/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.8618 - accuracy: 0.6453 - precision_1: 0.7144 - recall_1: 0.5380\n",
            "Epoch 31: val_accuracy improved from 0.38415 to 0.41463, saving model to best_model.h5\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.8630 - accuracy: 0.6457 - precision_1: 0.7133 - recall_1: 0.5363 - val_loss: 1.2249 - val_accuracy: 0.4146 - val_precision_1: 0.4627 - val_recall_1: 0.3659\n",
            "Epoch 32/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.8675 - accuracy: 0.6443 - precision_1: 0.7088 - recall_1: 0.5260\n",
            "Epoch 32: val_accuracy did not improve from 0.41463\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.8677 - accuracy: 0.6446 - precision_1: 0.7082 - recall_1: 0.5257 - val_loss: 1.4394 - val_accuracy: 0.3862 - val_precision_1: 0.4393 - val_recall_1: 0.3679\n",
            "Epoch 33/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.8639 - accuracy: 0.6365 - precision_1: 0.7074 - recall_1: 0.5276\n",
            "Epoch 33: val_accuracy improved from 0.41463 to 0.45325, saving model to best_model.h5\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.8624 - accuracy: 0.6396 - precision_1: 0.7092 - recall_1: 0.5282 - val_loss: 1.5614 - val_accuracy: 0.4533 - val_precision_1: 0.4789 - val_recall_1: 0.4390\n",
            "Epoch 34/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.8680 - accuracy: 0.6573 - precision_1: 0.7086 - recall_1: 0.5422\n",
            "Epoch 34: val_accuracy did not improve from 0.45325\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.8693 - accuracy: 0.6568 - precision_1: 0.7091 - recall_1: 0.5404 - val_loss: 1.3440 - val_accuracy: 0.3699 - val_precision_1: 0.4377 - val_recall_1: 0.3354\n",
            "Epoch 35/10000\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 0.8712 - accuracy: 0.6485 - precision_1: 0.7088 - recall_1: 0.5232\n",
            "Epoch 35: val_accuracy did not improve from 0.45325\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.8689 - accuracy: 0.6512 - precision_1: 0.7114 - recall_1: 0.5252 - val_loss: 1.4524 - val_accuracy: 0.4085 - val_precision_1: 0.4693 - val_recall_1: 0.3882\n",
            "Epoch 36/10000\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 0.8997 - accuracy: 0.6270 - precision_1: 0.6890 - recall_1: 0.5111\n",
            "Epoch 36: val_accuracy did not improve from 0.45325\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.8995 - accuracy: 0.6284 - precision_1: 0.6921 - recall_1: 0.5109 - val_loss: 1.2283 - val_accuracy: 0.3028 - val_precision_1: 0.3438 - val_recall_1: 0.2459\n",
            "Epoch 37/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.8641 - accuracy: 0.6496 - precision_1: 0.7209 - recall_1: 0.5194\n",
            "Epoch 37: val_accuracy did not improve from 0.45325\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.8633 - accuracy: 0.6492 - precision_1: 0.7208 - recall_1: 0.5186 - val_loss: 1.2667 - val_accuracy: 0.4451 - val_precision_1: 0.5609 - val_recall_1: 0.4024\n",
            "Epoch 38/10000\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 0.8220 - accuracy: 0.6704 - precision_1: 0.7311 - recall_1: 0.5640\n",
            "Epoch 38: val_accuracy did not improve from 0.45325\n",
            "132/132 [==============================] - 1s 11ms/step - loss: 0.8262 - accuracy: 0.6670 - precision_1: 0.7282 - recall_1: 0.5613 - val_loss: 1.4827 - val_accuracy: 0.2967 - val_precision_1: 0.2920 - val_recall_1: 0.2683\n",
            "Epoch 39/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.8326 - accuracy: 0.6577 - precision_1: 0.7190 - recall_1: 0.5533\n",
            "Epoch 39: val_accuracy did not improve from 0.45325\n",
            "132/132 [==============================] - 1s 10ms/step - loss: 0.8330 - accuracy: 0.6609 - precision_1: 0.7195 - recall_1: 0.5541 - val_loss: 1.5551 - val_accuracy: 0.3435 - val_precision_1: 0.3552 - val_recall_1: 0.3191\n",
            "Epoch 40/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 1.7589 - accuracy: 0.5897 - precision_1: 0.6325 - recall_1: 0.4987\n",
            "Epoch 40: val_accuracy improved from 0.45325 to 0.46138, saving model to best_model.h5\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.7589 - accuracy: 0.5897 - precision_1: 0.6325 - recall_1: 0.4987 - val_loss: 1.9379 - val_accuracy: 0.4614 - val_precision_1: 0.5036 - val_recall_1: 0.4289\n",
            "Epoch 41/10000\n",
            "130/132 [============================>.] - ETA: 0s - loss: 1.2251 - accuracy: 0.6138 - precision_1: 0.6758 - recall_1: 0.5067\n",
            "Epoch 41: val_accuracy did not improve from 0.46138\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 1.2236 - accuracy: 0.6141 - precision_1: 0.6762 - recall_1: 0.5064 - val_loss: 1.3832 - val_accuracy: 0.3435 - val_precision_1: 0.3636 - val_recall_1: 0.3171\n",
            "Epoch 42/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.9696 - accuracy: 0.6560 - precision_1: 0.7077 - recall_1: 0.5445\n",
            "Epoch 42: val_accuracy did not improve from 0.46138\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.9702 - accuracy: 0.6553 - precision_1: 0.7077 - recall_1: 0.5440 - val_loss: 1.5702 - val_accuracy: 0.2907 - val_precision_1: 0.3030 - val_recall_1: 0.2846\n",
            "Epoch 43/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.8943 - accuracy: 0.6645 - precision_1: 0.7184 - recall_1: 0.5643\n",
            "Epoch 43: val_accuracy did not improve from 0.46138\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.8943 - accuracy: 0.6645 - precision_1: 0.7184 - recall_1: 0.5643 - val_loss: 1.6884 - val_accuracy: 0.2988 - val_precision_1: 0.3025 - val_recall_1: 0.2724\n",
            "Epoch 44/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.8339 - accuracy: 0.6772 - precision_1: 0.7376 - recall_1: 0.5760\n",
            "Epoch 44: val_accuracy did not improve from 0.46138\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.8339 - accuracy: 0.6772 - precision_1: 0.7376 - recall_1: 0.5760 - val_loss: 1.6721 - val_accuracy: 0.3049 - val_precision_1: 0.3017 - val_recall_1: 0.2907\n",
            "Epoch 45/10000\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 0.8427 - accuracy: 0.6747 - precision_1: 0.7452 - recall_1: 0.5771\n",
            "Epoch 45: val_accuracy did not improve from 0.46138\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.8416 - accuracy: 0.6731 - precision_1: 0.7426 - recall_1: 0.5765 - val_loss: 1.8415 - val_accuracy: 0.2886 - val_precision_1: 0.2942 - val_recall_1: 0.2805\n",
            "Epoch 46/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.8567 - accuracy: 0.6703 - precision_1: 0.7374 - recall_1: 0.5617\n",
            "Epoch 46: val_accuracy did not improve from 0.46138\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.8527 - accuracy: 0.6706 - precision_1: 0.7360 - recall_1: 0.5628 - val_loss: 1.4662 - val_accuracy: 0.3069 - val_precision_1: 0.3079 - val_recall_1: 0.2785\n",
            "Epoch 47/10000\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 0.8411 - accuracy: 0.6747 - precision_1: 0.7307 - recall_1: 0.5659\n",
            "Epoch 47: val_accuracy did not improve from 0.46138\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.8445 - accuracy: 0.6726 - precision_1: 0.7289 - recall_1: 0.5658 - val_loss: 1.4431 - val_accuracy: 0.4573 - val_precision_1: 0.4932 - val_recall_1: 0.4431\n",
            "Epoch 48/10000\n",
            "130/132 [============================>.] - ETA: 0s - loss: 0.8348 - accuracy: 0.6610 - precision_1: 0.7165 - recall_1: 0.5677\n",
            "Epoch 48: val_accuracy did not improve from 0.46138\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.8326 - accuracy: 0.6634 - precision_1: 0.7188 - recall_1: 0.5704 - val_loss: 1.3015 - val_accuracy: 0.3557 - val_precision_1: 0.3854 - val_recall_1: 0.3110\n",
            "Epoch 49/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.8028 - accuracy: 0.6898 - precision_1: 0.7465 - recall_1: 0.5921\n",
            "Epoch 49: val_accuracy did not improve from 0.46138\n",
            "132/132 [==============================] - 1s 10ms/step - loss: 0.8035 - accuracy: 0.6894 - precision_1: 0.7457 - recall_1: 0.5918 - val_loss: 1.3894 - val_accuracy: 0.4329 - val_precision_1: 0.4608 - val_recall_1: 0.3821\n",
            "Epoch 50/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.8044 - accuracy: 0.6915 - precision_1: 0.7520 - recall_1: 0.5953\n",
            "Epoch 50: val_accuracy did not improve from 0.46138\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.8037 - accuracy: 0.6919 - precision_1: 0.7521 - recall_1: 0.5953 - val_loss: 1.3242 - val_accuracy: 0.4024 - val_precision_1: 0.4543 - val_recall_1: 0.3638\n",
            "Epoch 51/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.7877 - accuracy: 0.7051 - precision_1: 0.7479 - recall_1: 0.5943\n",
            "Epoch 51: val_accuracy did not improve from 0.46138\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.7877 - accuracy: 0.7051 - precision_1: 0.7479 - recall_1: 0.5943 - val_loss: 1.4980 - val_accuracy: 0.4390 - val_precision_1: 0.4650 - val_recall_1: 0.4187\n",
            "Epoch 52/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.8096 - accuracy: 0.6904 - precision_1: 0.7435 - recall_1: 0.5953\n",
            "Epoch 52: val_accuracy improved from 0.46138 to 0.46951, saving model to best_model.h5\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.8096 - accuracy: 0.6904 - precision_1: 0.7435 - recall_1: 0.5953 - val_loss: 1.8500 - val_accuracy: 0.4695 - val_precision_1: 0.4811 - val_recall_1: 0.4654\n",
            "Epoch 53/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.8022 - accuracy: 0.6931 - precision_1: 0.7524 - recall_1: 0.5908\n",
            "Epoch 53: val_accuracy did not improve from 0.46951\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.8027 - accuracy: 0.6929 - precision_1: 0.7519 - recall_1: 0.5902 - val_loss: 1.5749 - val_accuracy: 0.2947 - val_precision_1: 0.2974 - val_recall_1: 0.2805\n",
            "Epoch 54/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.7813 - accuracy: 0.6940 - precision_1: 0.7466 - recall_1: 0.6079\n",
            "Epoch 54: val_accuracy improved from 0.46951 to 0.47967, saving model to best_model.h5\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.7830 - accuracy: 0.6909 - precision_1: 0.7439 - recall_1: 0.6070 - val_loss: 1.7996 - val_accuracy: 0.4797 - val_precision_1: 0.4968 - val_recall_1: 0.4695\n",
            "Epoch 55/10000\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 0.8257 - accuracy: 0.6778 - precision_1: 0.7360 - recall_1: 0.5709\n",
            "Epoch 55: val_accuracy did not improve from 0.47967\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.8264 - accuracy: 0.6792 - precision_1: 0.7354 - recall_1: 0.5694 - val_loss: 1.4634 - val_accuracy: 0.3130 - val_precision_1: 0.3282 - val_recall_1: 0.3049\n",
            "Epoch 56/10000\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 0.7866 - accuracy: 0.6944 - precision_1: 0.7440 - recall_1: 0.6139\n",
            "Epoch 56: val_accuracy did not improve from 0.47967\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.7884 - accuracy: 0.6934 - precision_1: 0.7438 - recall_1: 0.6126 - val_loss: 1.3651 - val_accuracy: 0.3638 - val_precision_1: 0.4103 - val_recall_1: 0.3252\n",
            "Epoch 57/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.8200 - accuracy: 0.6762 - precision_1: 0.7270 - recall_1: 0.5714\n",
            "Epoch 57: val_accuracy did not improve from 0.47967\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.8200 - accuracy: 0.6762 - precision_1: 0.7270 - recall_1: 0.5714 - val_loss: 1.4711 - val_accuracy: 0.3801 - val_precision_1: 0.3937 - val_recall_1: 0.3537\n",
            "Epoch 58/10000\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 0.7860 - accuracy: 0.7063 - precision_1: 0.7545 - recall_1: 0.6196\n",
            "Epoch 58: val_accuracy did not improve from 0.47967\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.7887 - accuracy: 0.7056 - precision_1: 0.7536 - recall_1: 0.6202 - val_loss: 1.4334 - val_accuracy: 0.3272 - val_precision_1: 0.3310 - val_recall_1: 0.2846\n",
            "Epoch 59/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.8117 - accuracy: 0.6740 - precision_1: 0.7303 - recall_1: 0.5938\n",
            "Epoch 59: val_accuracy did not improve from 0.47967\n",
            "132/132 [==============================] - 1s 10ms/step - loss: 0.8088 - accuracy: 0.6741 - precision_1: 0.7295 - recall_1: 0.5938 - val_loss: 1.6106 - val_accuracy: 0.3069 - val_precision_1: 0.3109 - val_recall_1: 0.3008\n",
            "Epoch 60/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.8056 - accuracy: 0.7018 - precision_1: 0.7476 - recall_1: 0.6140\n",
            "Epoch 60: val_accuracy did not improve from 0.47967\n",
            "132/132 [==============================] - 1s 10ms/step - loss: 0.8026 - accuracy: 0.7051 - precision_1: 0.7508 - recall_1: 0.6172 - val_loss: 1.5735 - val_accuracy: 0.3191 - val_precision_1: 0.3256 - val_recall_1: 0.3150\n",
            "Epoch 61/10000\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 0.8223 - accuracy: 0.6811 - precision_1: 0.7313 - recall_1: 0.5952\n",
            "Epoch 61: val_accuracy did not improve from 0.47967\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.8186 - accuracy: 0.6823 - precision_1: 0.7330 - recall_1: 0.5974 - val_loss: 1.7229 - val_accuracy: 0.3333 - val_precision_1: 0.3395 - val_recall_1: 0.3333\n",
            "Epoch 62/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.8181 - accuracy: 0.6909 - precision_1: 0.7375 - recall_1: 0.6014\n",
            "Epoch 62: val_accuracy did not improve from 0.47967\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.8181 - accuracy: 0.6909 - precision_1: 0.7375 - recall_1: 0.6014 - val_loss: 1.6012 - val_accuracy: 0.3333 - val_precision_1: 0.3454 - val_recall_1: 0.3293\n",
            "Epoch 63/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.8412 - accuracy: 0.6863 - precision_1: 0.7318 - recall_1: 0.5866\n",
            "Epoch 63: val_accuracy did not improve from 0.47967\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.8424 - accuracy: 0.6858 - precision_1: 0.7316 - recall_1: 0.5846 - val_loss: 1.3332 - val_accuracy: 0.3780 - val_precision_1: 0.4350 - val_recall_1: 0.3537\n",
            "Epoch 64/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.7778 - accuracy: 0.7043 - precision_1: 0.7489 - recall_1: 0.6102\n",
            "Epoch 64: val_accuracy did not improve from 0.47967\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.7775 - accuracy: 0.7046 - precision_1: 0.7492 - recall_1: 0.6106 - val_loss: 2.0199 - val_accuracy: 0.3740 - val_precision_1: 0.3722 - val_recall_1: 0.3699\n",
            "Epoch 65/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.8093 - accuracy: 0.6811 - precision_1: 0.7316 - recall_1: 0.5943\n",
            "Epoch 65: val_accuracy did not improve from 0.47967\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.8099 - accuracy: 0.6817 - precision_1: 0.7331 - recall_1: 0.5948 - val_loss: 1.5846 - val_accuracy: 0.4695 - val_precision_1: 0.4893 - val_recall_1: 0.4654\n",
            "Epoch 66/10000\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 0.7744 - accuracy: 0.7163 - precision_1: 0.7591 - recall_1: 0.6336\n",
            "Epoch 66: val_accuracy improved from 0.47967 to 0.48984, saving model to best_model.h5\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.7726 - accuracy: 0.7173 - precision_1: 0.7602 - recall_1: 0.6335 - val_loss: 1.3069 - val_accuracy: 0.4898 - val_precision_1: 0.5649 - val_recall_1: 0.4512\n",
            "Epoch 67/10000\n",
            "130/132 [============================>.] - ETA: 0s - loss: 0.7676 - accuracy: 0.7200 - precision_1: 0.7599 - recall_1: 0.6379\n",
            "Epoch 67: val_accuracy did not improve from 0.48984\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.7682 - accuracy: 0.7194 - precision_1: 0.7592 - recall_1: 0.6380 - val_loss: 1.6194 - val_accuracy: 0.4776 - val_precision_1: 0.4989 - val_recall_1: 0.4654\n",
            "Epoch 68/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.8007 - accuracy: 0.6972 - precision_1: 0.7483 - recall_1: 0.6097\n",
            "Epoch 68: val_accuracy did not improve from 0.48984\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.8010 - accuracy: 0.6970 - precision_1: 0.7480 - recall_1: 0.6096 - val_loss: 1.6207 - val_accuracy: 0.4512 - val_precision_1: 0.4791 - val_recall_1: 0.4431\n",
            "Epoch 69/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.7784 - accuracy: 0.7062 - precision_1: 0.7689 - recall_1: 0.6243\n",
            "Epoch 69: val_accuracy did not improve from 0.48984\n",
            "132/132 [==============================] - 2s 14ms/step - loss: 0.7784 - accuracy: 0.7062 - precision_1: 0.7689 - recall_1: 0.6243 - val_loss: 1.4225 - val_accuracy: 0.3232 - val_precision_1: 0.3319 - val_recall_1: 0.3171\n",
            "Epoch 70/10000\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 0.8042 - accuracy: 0.6963 - precision_1: 0.7422 - recall_1: 0.6079\n",
            "Epoch 70: val_accuracy did not improve from 0.48984\n",
            "132/132 [==============================] - 2s 17ms/step - loss: 0.8026 - accuracy: 0.6965 - precision_1: 0.7426 - recall_1: 0.6085 - val_loss: 1.7875 - val_accuracy: 0.2967 - val_precision_1: 0.2965 - val_recall_1: 0.2886\n",
            "Epoch 71/10000\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 0.7629 - accuracy: 0.7061 - precision_1: 0.7600 - recall_1: 0.6384\n",
            "Epoch 71: val_accuracy did not improve from 0.48984\n",
            "132/132 [==============================] - 1s 10ms/step - loss: 0.7656 - accuracy: 0.7067 - precision_1: 0.7587 - recall_1: 0.6396 - val_loss: 1.3342 - val_accuracy: 0.3618 - val_precision_1: 0.3537 - val_recall_1: 0.3171\n",
            "Epoch 72/10000\n",
            "130/132 [============================>.] - ETA: 0s - loss: 0.7760 - accuracy: 0.7190 - precision_1: 0.7618 - recall_1: 0.6528\n",
            "Epoch 72: val_accuracy did not improve from 0.48984\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.7794 - accuracy: 0.7173 - precision_1: 0.7602 - recall_1: 0.6512 - val_loss: 1.3143 - val_accuracy: 0.3841 - val_precision_1: 0.3872 - val_recall_1: 0.3557\n",
            "Epoch 73/10000\n",
            "130/132 [============================>.] - ETA: 0s - loss: 0.7664 - accuracy: 0.7236 - precision_1: 0.7778 - recall_1: 0.6426\n",
            "Epoch 73: val_accuracy did not improve from 0.48984\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.7665 - accuracy: 0.7234 - precision_1: 0.7783 - recall_1: 0.6426 - val_loss: 1.5949 - val_accuracy: 0.3191 - val_precision_1: 0.3255 - val_recall_1: 0.3089\n",
            "Epoch 74/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.7522 - accuracy: 0.7167 - precision_1: 0.7706 - recall_1: 0.6490\n",
            "Epoch 74: val_accuracy did not improve from 0.48984\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.7519 - accuracy: 0.7168 - precision_1: 0.7694 - recall_1: 0.6497 - val_loss: 2.0411 - val_accuracy: 0.4797 - val_precision_1: 0.5076 - val_recall_1: 0.4776\n",
            "Epoch 75/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.7794 - accuracy: 0.7235 - precision_1: 0.7669 - recall_1: 0.6444\n",
            "Epoch 75: val_accuracy did not improve from 0.48984\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.7784 - accuracy: 0.7229 - precision_1: 0.7671 - recall_1: 0.6446 - val_loss: 1.5235 - val_accuracy: 0.4146 - val_precision_1: 0.4207 - val_recall_1: 0.4045\n",
            "Epoch 76/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.7809 - accuracy: 0.7033 - precision_1: 0.7530 - recall_1: 0.6438\n",
            "Epoch 76: val_accuracy did not improve from 0.48984\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.7808 - accuracy: 0.7036 - precision_1: 0.7533 - recall_1: 0.6441 - val_loss: 1.2050 - val_accuracy: 0.4309 - val_precision_1: 0.4673 - val_recall_1: 0.3780\n",
            "Epoch 77/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.7624 - accuracy: 0.7229 - precision_1: 0.7692 - recall_1: 0.6406\n",
            "Epoch 77: val_accuracy improved from 0.48984 to 0.50813, saving model to best_model.h5\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.7624 - accuracy: 0.7229 - precision_1: 0.7692 - recall_1: 0.6406 - val_loss: 1.3566 - val_accuracy: 0.5081 - val_precision_1: 0.5409 - val_recall_1: 0.4837\n",
            "Epoch 78/10000\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 0.8255 - accuracy: 0.7116 - precision_1: 0.7558 - recall_1: 0.6418\n",
            "Epoch 78: val_accuracy did not improve from 0.50813\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.8375 - accuracy: 0.7092 - precision_1: 0.7522 - recall_1: 0.6375 - val_loss: 1.9641 - val_accuracy: 0.4289 - val_precision_1: 0.4543 - val_recall_1: 0.4248\n",
            "Epoch 79/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.8226 - accuracy: 0.7028 - precision_1: 0.7637 - recall_1: 0.6249\n",
            "Epoch 79: val_accuracy improved from 0.50813 to 0.52439, saving model to best_model.h5\n",
            "132/132 [==============================] - 1s 11ms/step - loss: 0.8231 - accuracy: 0.7026 - precision_1: 0.7634 - recall_1: 0.6248 - val_loss: 1.4730 - val_accuracy: 0.5244 - val_precision_1: 0.5373 - val_recall_1: 0.5122\n",
            "Epoch 80/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.7796 - accuracy: 0.7178 - precision_1: 0.7619 - recall_1: 0.6492\n",
            "Epoch 80: val_accuracy did not improve from 0.52439\n",
            "132/132 [==============================] - 1s 10ms/step - loss: 0.7796 - accuracy: 0.7178 - precision_1: 0.7619 - recall_1: 0.6492 - val_loss: 1.3165 - val_accuracy: 0.3760 - val_precision_1: 0.3670 - val_recall_1: 0.3252\n",
            "Epoch 81/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.7404 - accuracy: 0.7359 - precision_1: 0.7839 - recall_1: 0.6693\n",
            "Epoch 81: val_accuracy did not improve from 0.52439\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.7403 - accuracy: 0.7356 - precision_1: 0.7844 - recall_1: 0.6695 - val_loss: 1.7103 - val_accuracy: 0.4573 - val_precision_1: 0.4735 - val_recall_1: 0.4533\n",
            "Epoch 82/10000\n",
            "130/132 [============================>.] - ETA: 0s - loss: 0.7881 - accuracy: 0.7092 - precision_1: 0.7659 - recall_1: 0.6344\n",
            "Epoch 82: val_accuracy did not improve from 0.52439\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.7875 - accuracy: 0.7087 - precision_1: 0.7656 - recall_1: 0.6345 - val_loss: 1.5402 - val_accuracy: 0.3110 - val_precision_1: 0.3254 - val_recall_1: 0.3049\n",
            "Epoch 83/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.7313 - accuracy: 0.7437 - precision_1: 0.7917 - recall_1: 0.6817\n",
            "Epoch 83: val_accuracy did not improve from 0.52439\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.7324 - accuracy: 0.7433 - precision_1: 0.7912 - recall_1: 0.6817 - val_loss: 1.6181 - val_accuracy: 0.4472 - val_precision_1: 0.4602 - val_recall_1: 0.4350\n",
            "Epoch 84/10000\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 0.7749 - accuracy: 0.7163 - precision_1: 0.7636 - recall_1: 0.6443\n",
            "Epoch 84: val_accuracy did not improve from 0.52439\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.7751 - accuracy: 0.7158 - precision_1: 0.7658 - recall_1: 0.6451 - val_loss: 1.3888 - val_accuracy: 0.4472 - val_precision_1: 0.4577 - val_recall_1: 0.4289\n",
            "Epoch 85/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.7448 - accuracy: 0.7270 - precision_1: 0.7767 - recall_1: 0.6736\n",
            "Epoch 85: val_accuracy did not improve from 0.52439\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.7448 - accuracy: 0.7270 - precision_1: 0.7767 - recall_1: 0.6736 - val_loss: 1.1372 - val_accuracy: 0.4715 - val_precision_1: 0.4777 - val_recall_1: 0.3923\n",
            "Epoch 86/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.7441 - accuracy: 0.7397 - precision_1: 0.7802 - recall_1: 0.6624\n",
            "Epoch 86: val_accuracy did not improve from 0.52439\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.7441 - accuracy: 0.7397 - precision_1: 0.7802 - recall_1: 0.6624 - val_loss: 1.6930 - val_accuracy: 0.4614 - val_precision_1: 0.4837 - val_recall_1: 0.4533\n",
            "Epoch 87/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.7414 - accuracy: 0.7412 - precision_1: 0.7888 - recall_1: 0.6873\n",
            "Epoch 87: val_accuracy did not improve from 0.52439\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.7414 - accuracy: 0.7412 - precision_1: 0.7888 - recall_1: 0.6873 - val_loss: 1.8596 - val_accuracy: 0.4675 - val_precision_1: 0.4883 - val_recall_1: 0.4654\n",
            "Epoch 88/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.7468 - accuracy: 0.7457 - precision_1: 0.7777 - recall_1: 0.6889\n",
            "Epoch 88: val_accuracy improved from 0.52439 to 0.54472, saving model to best_model.h5\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.7475 - accuracy: 0.7448 - precision_1: 0.7764 - recall_1: 0.6868 - val_loss: 1.3583 - val_accuracy: 0.5447 - val_precision_1: 0.6023 - val_recall_1: 0.5325\n",
            "Epoch 89/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.7829 - accuracy: 0.7377 - precision_1: 0.7746 - recall_1: 0.6655\n",
            "Epoch 89: val_accuracy improved from 0.54472 to 0.56504, saving model to best_model.h5\n",
            "132/132 [==============================] - 1s 10ms/step - loss: 0.7829 - accuracy: 0.7377 - precision_1: 0.7746 - recall_1: 0.6655 - val_loss: 1.2800 - val_accuracy: 0.5650 - val_precision_1: 0.5835 - val_recall_1: 0.5183\n",
            "Epoch 90/10000\n",
            "130/132 [============================>.] - ETA: 0s - loss: 0.7269 - accuracy: 0.7605 - precision_1: 0.7998 - recall_1: 0.6923\n",
            "Epoch 90: val_accuracy did not improve from 0.56504\n",
            "132/132 [==============================] - 1s 10ms/step - loss: 0.7270 - accuracy: 0.7600 - precision_1: 0.7998 - recall_1: 0.6924 - val_loss: 1.4301 - val_accuracy: 0.4309 - val_precision_1: 0.4247 - val_recall_1: 0.3841\n",
            "Epoch 91/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.7367 - accuracy: 0.7425 - precision_1: 0.7888 - recall_1: 0.6824\n",
            "Epoch 91: val_accuracy did not improve from 0.56504\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.7365 - accuracy: 0.7428 - precision_1: 0.7891 - recall_1: 0.6828 - val_loss: 1.4201 - val_accuracy: 0.5224 - val_precision_1: 0.5616 - val_recall_1: 0.5000\n",
            "Epoch 92/10000\n",
            "130/132 [============================>.] - ETA: 0s - loss: 0.7192 - accuracy: 0.7682 - precision_1: 0.8094 - recall_1: 0.7144\n",
            "Epoch 92: val_accuracy did not improve from 0.56504\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.7183 - accuracy: 0.7687 - precision_1: 0.8099 - recall_1: 0.7148 - val_loss: 1.2290 - val_accuracy: 0.4756 - val_precision_1: 0.5274 - val_recall_1: 0.4309\n",
            "Epoch 93/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.7396 - accuracy: 0.7401 - precision_1: 0.7777 - recall_1: 0.6853\n",
            "Epoch 93: val_accuracy did not improve from 0.56504\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.7406 - accuracy: 0.7402 - precision_1: 0.7771 - recall_1: 0.6858 - val_loss: 1.4593 - val_accuracy: 0.4126 - val_precision_1: 0.4252 - val_recall_1: 0.3984\n",
            "Epoch 94/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.6735 - accuracy: 0.7922 - precision_1: 0.8249 - recall_1: 0.7452\n",
            "Epoch 94: val_accuracy did not improve from 0.56504\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.6707 - accuracy: 0.7936 - precision_1: 0.8262 - recall_1: 0.7468 - val_loss: 1.4952 - val_accuracy: 0.5285 - val_precision_1: 0.5543 - val_recall_1: 0.4980\n",
            "Epoch 95/10000\n",
            "130/132 [============================>.] - ETA: 0s - loss: 0.6790 - accuracy: 0.7841 - precision_1: 0.8208 - recall_1: 0.7328\n",
            "Epoch 95: val_accuracy did not improve from 0.56504\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.6784 - accuracy: 0.7844 - precision_1: 0.8221 - recall_1: 0.7331 - val_loss: 1.4197 - val_accuracy: 0.3598 - val_precision_1: 0.3716 - val_recall_1: 0.3354\n",
            "Epoch 96/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.6942 - accuracy: 0.7682 - precision_1: 0.8076 - recall_1: 0.7193\n",
            "Epoch 96: val_accuracy did not improve from 0.56504\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.6951 - accuracy: 0.7677 - precision_1: 0.8079 - recall_1: 0.7184 - val_loss: 1.2990 - val_accuracy: 0.5447 - val_precision_1: 0.5833 - val_recall_1: 0.5264\n",
            "Epoch 97/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.6886 - accuracy: 0.7885 - precision_1: 0.8248 - recall_1: 0.7234\n",
            "Epoch 97: val_accuracy improved from 0.56504 to 0.60366, saving model to best_model.h5\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.6909 - accuracy: 0.7870 - precision_1: 0.8227 - recall_1: 0.7219 - val_loss: 1.0645 - val_accuracy: 0.6037 - val_precision_1: 0.6552 - val_recall_1: 0.5407\n",
            "Epoch 98/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.7467 - accuracy: 0.7669 - precision_1: 0.8026 - recall_1: 0.7213\n",
            "Epoch 98: val_accuracy did not improve from 0.60366\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.7465 - accuracy: 0.7656 - precision_1: 0.8014 - recall_1: 0.7199 - val_loss: 1.2195 - val_accuracy: 0.5610 - val_precision_1: 0.6127 - val_recall_1: 0.5305\n",
            "Epoch 99/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.6667 - accuracy: 0.7937 - precision_1: 0.8251 - recall_1: 0.7469\n",
            "Epoch 99: val_accuracy did not improve from 0.60366\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.6631 - accuracy: 0.7956 - precision_1: 0.8264 - recall_1: 0.7478 - val_loss: 1.3208 - val_accuracy: 0.4350 - val_precision_1: 0.4452 - val_recall_1: 0.3801\n",
            "Epoch 100/10000\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 0.7000 - accuracy: 0.7825 - precision_1: 0.8168 - recall_1: 0.7291\n",
            "Epoch 100: val_accuracy did not improve from 0.60366\n",
            "132/132 [==============================] - 1s 10ms/step - loss: 0.6959 - accuracy: 0.7839 - precision_1: 0.8191 - recall_1: 0.7295 - val_loss: 1.3407 - val_accuracy: 0.4756 - val_precision_1: 0.5012 - val_recall_1: 0.4309\n",
            "Epoch 101/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.6571 - accuracy: 0.8016 - precision_1: 0.8332 - recall_1: 0.7625\n",
            "Epoch 101: val_accuracy did not improve from 0.60366\n",
            "132/132 [==============================] - 1s 10ms/step - loss: 0.6546 - accuracy: 0.8033 - precision_1: 0.8351 - recall_1: 0.7646 - val_loss: 2.0842 - val_accuracy: 0.5142 - val_precision_1: 0.5166 - val_recall_1: 0.5061\n",
            "Epoch 102/10000\n",
            "130/132 [============================>.] - ETA: 0s - loss: 0.6658 - accuracy: 0.7923 - precision_1: 0.8206 - recall_1: 0.7436\n",
            "Epoch 102: val_accuracy did not improve from 0.60366\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.6643 - accuracy: 0.7931 - precision_1: 0.8220 - recall_1: 0.7443 - val_loss: 1.3689 - val_accuracy: 0.5285 - val_precision_1: 0.5326 - val_recall_1: 0.4817\n",
            "Epoch 103/10000\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 0.6839 - accuracy: 0.7915 - precision_1: 0.8233 - recall_1: 0.7344\n",
            "Epoch 103: val_accuracy did not improve from 0.60366\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.6874 - accuracy: 0.7900 - precision_1: 0.8217 - recall_1: 0.7331 - val_loss: 1.3488 - val_accuracy: 0.4512 - val_precision_1: 0.4677 - val_recall_1: 0.4126\n",
            "Epoch 104/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.6119 - accuracy: 0.8257 - precision_1: 0.8562 - recall_1: 0.7753\n",
            "Epoch 104: val_accuracy did not improve from 0.60366\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.6108 - accuracy: 0.8261 - precision_1: 0.8573 - recall_1: 0.7758 - val_loss: 1.4422 - val_accuracy: 0.5000 - val_precision_1: 0.5012 - val_recall_1: 0.4411\n",
            "Epoch 105/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.6562 - accuracy: 0.8056 - precision_1: 0.8368 - recall_1: 0.7644\n",
            "Epoch 105: val_accuracy did not improve from 0.60366\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.6569 - accuracy: 0.8053 - precision_1: 0.8368 - recall_1: 0.7636 - val_loss: 1.3756 - val_accuracy: 0.5671 - val_precision_1: 0.5969 - val_recall_1: 0.5447\n",
            "Epoch 106/10000\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 0.6325 - accuracy: 0.8053 - precision_1: 0.8413 - recall_1: 0.7691\n",
            "Epoch 106: val_accuracy improved from 0.60366 to 0.61789, saving model to best_model.h5\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.6273 - accuracy: 0.8073 - precision_1: 0.8426 - recall_1: 0.7728 - val_loss: 1.1613 - val_accuracy: 0.6179 - val_precision_1: 0.6506 - val_recall_1: 0.5752\n",
            "Epoch 107/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.6695 - accuracy: 0.8042 - precision_1: 0.8276 - recall_1: 0.7512\n",
            "Epoch 107: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.6606 - accuracy: 0.8088 - precision_1: 0.8318 - recall_1: 0.7570 - val_loss: 1.2934 - val_accuracy: 0.5996 - val_precision_1: 0.6425 - val_recall_1: 0.5589\n",
            "Epoch 108/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.6419 - accuracy: 0.8180 - precision_1: 0.8435 - recall_1: 0.7783\n",
            "Epoch 108: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.6419 - accuracy: 0.8180 - precision_1: 0.8435 - recall_1: 0.7783 - val_loss: 1.2525 - val_accuracy: 0.5732 - val_precision_1: 0.6253 - val_recall_1: 0.5325\n",
            "Epoch 109/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.5911 - accuracy: 0.8268 - precision_1: 0.8585 - recall_1: 0.7995\n",
            "Epoch 109: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.5889 - accuracy: 0.8292 - precision_1: 0.8606 - recall_1: 0.8002 - val_loss: 1.2630 - val_accuracy: 0.5569 - val_precision_1: 0.5774 - val_recall_1: 0.5081\n",
            "Epoch 110/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.6210 - accuracy: 0.8163 - precision_1: 0.8458 - recall_1: 0.7817\n",
            "Epoch 110: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 10ms/step - loss: 0.6206 - accuracy: 0.8165 - precision_1: 0.8460 - recall_1: 0.7819 - val_loss: 1.3013 - val_accuracy: 0.5935 - val_precision_1: 0.6000 - val_recall_1: 0.5549\n",
            "Epoch 111/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.5940 - accuracy: 0.8193 - precision_1: 0.8549 - recall_1: 0.7917\n",
            "Epoch 111: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 11ms/step - loss: 0.5923 - accuracy: 0.8200 - precision_1: 0.8548 - recall_1: 0.7931 - val_loss: 1.5103 - val_accuracy: 0.4919 - val_precision_1: 0.4932 - val_recall_1: 0.4451\n",
            "Epoch 112/10000\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 0.6591 - accuracy: 0.8037 - precision_1: 0.8317 - recall_1: 0.7688\n",
            "Epoch 112: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.6648 - accuracy: 0.8017 - precision_1: 0.8285 - recall_1: 0.7661 - val_loss: 1.2540 - val_accuracy: 0.5955 - val_precision_1: 0.6168 - val_recall_1: 0.5528\n",
            "Epoch 113/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.6250 - accuracy: 0.8135 - precision_1: 0.8475 - recall_1: 0.7818\n",
            "Epoch 113: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.6247 - accuracy: 0.8139 - precision_1: 0.8480 - recall_1: 0.7829 - val_loss: 1.4301 - val_accuracy: 0.5447 - val_precision_1: 0.5553 - val_recall_1: 0.5305\n",
            "Epoch 114/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.6041 - accuracy: 0.8254 - precision_1: 0.8506 - recall_1: 0.7939\n",
            "Epoch 114: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.6036 - accuracy: 0.8256 - precision_1: 0.8508 - recall_1: 0.7941 - val_loss: 1.6725 - val_accuracy: 0.4004 - val_precision_1: 0.3875 - val_recall_1: 0.3537\n",
            "Epoch 115/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.5749 - accuracy: 0.8317 - precision_1: 0.8551 - recall_1: 0.8038\n",
            "Epoch 115: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.5749 - accuracy: 0.8317 - precision_1: 0.8551 - recall_1: 0.8038 - val_loss: 1.3452 - val_accuracy: 0.4878 - val_precision_1: 0.4805 - val_recall_1: 0.4268\n",
            "Epoch 116/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.5964 - accuracy: 0.8277 - precision_1: 0.8559 - recall_1: 0.7972\n",
            "Epoch 116: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.5964 - accuracy: 0.8277 - precision_1: 0.8559 - recall_1: 0.7972 - val_loss: 1.3985 - val_accuracy: 0.5528 - val_precision_1: 0.5708 - val_recall_1: 0.5325\n",
            "Epoch 117/10000\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 1.0098 - accuracy: 0.7579 - precision_1: 0.7853 - recall_1: 0.7179\n",
            "Epoch 117: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.0567 - accuracy: 0.7443 - precision_1: 0.7752 - recall_1: 0.7011 - val_loss: 1.7393 - val_accuracy: 0.5427 - val_precision_1: 0.7007 - val_recall_1: 0.4187\n",
            "Epoch 118/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 1.0989 - accuracy: 0.6351 - precision_1: 0.6977 - recall_1: 0.5226\n",
            "Epoch 118: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.0987 - accuracy: 0.6355 - precision_1: 0.6979 - recall_1: 0.5226 - val_loss: 1.2113 - val_accuracy: 0.5589 - val_precision_1: 0.6103 - val_recall_1: 0.4837\n",
            "Epoch 119/10000\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 0.8314 - accuracy: 0.7104 - precision_1: 0.7587 - recall_1: 0.6491\n",
            "Epoch 119: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.8214 - accuracy: 0.7184 - precision_1: 0.7651 - recall_1: 0.6558 - val_loss: 1.1761 - val_accuracy: 0.5630 - val_precision_1: 0.6183 - val_recall_1: 0.5366\n",
            "Epoch 120/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.6814 - accuracy: 0.7824 - precision_1: 0.8271 - recall_1: 0.7318\n",
            "Epoch 120: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 10ms/step - loss: 0.6834 - accuracy: 0.7814 - precision_1: 0.8250 - recall_1: 0.7311 - val_loss: 1.2288 - val_accuracy: 0.5346 - val_precision_1: 0.5646 - val_recall_1: 0.5061\n",
            "Epoch 121/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.6271 - accuracy: 0.8062 - precision_1: 0.8344 - recall_1: 0.7602\n",
            "Epoch 121: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.6299 - accuracy: 0.8048 - precision_1: 0.8335 - recall_1: 0.7585 - val_loss: 1.2142 - val_accuracy: 0.4797 - val_precision_1: 0.4853 - val_recall_1: 0.4024\n",
            "Epoch 122/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.6130 - accuracy: 0.8094 - precision_1: 0.8439 - recall_1: 0.7722\n",
            "Epoch 122: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.6130 - accuracy: 0.8094 - precision_1: 0.8439 - recall_1: 0.7722 - val_loss: 1.6744 - val_accuracy: 0.4695 - val_precision_1: 0.4871 - val_recall_1: 0.4614\n",
            "Epoch 123/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.5857 - accuracy: 0.8256 - precision_1: 0.8511 - recall_1: 0.7961\n",
            "Epoch 123: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.5857 - accuracy: 0.8256 - precision_1: 0.8511 - recall_1: 0.7961 - val_loss: 1.4023 - val_accuracy: 0.5041 - val_precision_1: 0.5103 - val_recall_1: 0.4512\n",
            "Epoch 124/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.5840 - accuracy: 0.8297 - precision_1: 0.8572 - recall_1: 0.7911\n",
            "Epoch 124: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.5779 - accuracy: 0.8332 - precision_1: 0.8602 - recall_1: 0.7946 - val_loss: 1.7209 - val_accuracy: 0.3923 - val_precision_1: 0.3996 - val_recall_1: 0.3679\n",
            "Epoch 125/10000\n",
            "130/132 [============================>.] - ETA: 0s - loss: 0.5634 - accuracy: 0.8395 - precision_1: 0.8647 - recall_1: 0.8128\n",
            "Epoch 125: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.5638 - accuracy: 0.8399 - precision_1: 0.8648 - recall_1: 0.8129 - val_loss: 1.1880 - val_accuracy: 0.5996 - val_precision_1: 0.6473 - val_recall_1: 0.5671\n",
            "Epoch 126/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.5854 - accuracy: 0.8307 - precision_1: 0.8540 - recall_1: 0.8042\n",
            "Epoch 126: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.5877 - accuracy: 0.8312 - precision_1: 0.8537 - recall_1: 0.8038 - val_loss: 1.2113 - val_accuracy: 0.5935 - val_precision_1: 0.6093 - val_recall_1: 0.5325\n",
            "Epoch 127/10000\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 0.6839 - accuracy: 0.7877 - precision_1: 0.8202 - recall_1: 0.7397\n",
            "Epoch 127: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.6827 - accuracy: 0.7890 - precision_1: 0.8206 - recall_1: 0.7397 - val_loss: 1.3924 - val_accuracy: 0.4593 - val_precision_1: 0.4677 - val_recall_1: 0.4268\n",
            "Epoch 128/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.5667 - accuracy: 0.8353 - precision_1: 0.8644 - recall_1: 0.8038\n",
            "Epoch 128: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.5667 - accuracy: 0.8353 - precision_1: 0.8644 - recall_1: 0.8038 - val_loss: 1.1047 - val_accuracy: 0.5711 - val_precision_1: 0.6051 - val_recall_1: 0.5264\n",
            "Epoch 129/10000\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 0.5567 - accuracy: 0.8444 - precision_1: 0.8674 - recall_1: 0.8132\n",
            "Epoch 129: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.5575 - accuracy: 0.8449 - precision_1: 0.8678 - recall_1: 0.8144 - val_loss: 1.4721 - val_accuracy: 0.5285 - val_precision_1: 0.5588 - val_recall_1: 0.5020\n",
            "Epoch 130/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.5384 - accuracy: 0.8463 - precision_1: 0.8704 - recall_1: 0.8270\n",
            "Epoch 130: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.5380 - accuracy: 0.8465 - precision_1: 0.8705 - recall_1: 0.8271 - val_loss: 1.4253 - val_accuracy: 0.5569 - val_precision_1: 0.5675 - val_recall_1: 0.5467\n",
            "Epoch 131/10000\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 0.5248 - accuracy: 0.8519 - precision_1: 0.8705 - recall_1: 0.8286\n",
            "Epoch 131: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 10ms/step - loss: 0.5273 - accuracy: 0.8500 - precision_1: 0.8696 - recall_1: 0.8271 - val_loss: 1.5113 - val_accuracy: 0.5407 - val_precision_1: 0.5506 - val_recall_1: 0.5305\n",
            "Epoch 132/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.5498 - accuracy: 0.8419 - precision_1: 0.8656 - recall_1: 0.8155\n",
            "Epoch 132: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 11ms/step - loss: 0.5498 - accuracy: 0.8419 - precision_1: 0.8656 - recall_1: 0.8155 - val_loss: 1.3618 - val_accuracy: 0.5488 - val_precision_1: 0.5714 - val_recall_1: 0.5285\n",
            "Epoch 133/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.5581 - accuracy: 0.8310 - precision_1: 0.8618 - recall_1: 0.8084\n",
            "Epoch 133: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.5566 - accuracy: 0.8327 - precision_1: 0.8639 - recall_1: 0.8099 - val_loss: 1.6659 - val_accuracy: 0.5142 - val_precision_1: 0.5192 - val_recall_1: 0.4939\n",
            "Epoch 134/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.6677 - accuracy: 0.8031 - precision_1: 0.8310 - recall_1: 0.7597\n",
            "Epoch 134: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.6681 - accuracy: 0.8033 - precision_1: 0.8308 - recall_1: 0.7590 - val_loss: 1.3485 - val_accuracy: 0.5630 - val_precision_1: 0.5802 - val_recall_1: 0.5366\n",
            "Epoch 135/10000\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 0.5411 - accuracy: 0.8443 - precision_1: 0.8681 - recall_1: 0.8176\n",
            "Epoch 135: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.5390 - accuracy: 0.8470 - precision_1: 0.8704 - recall_1: 0.8195 - val_loss: 1.4836 - val_accuracy: 0.5305 - val_precision_1: 0.5445 - val_recall_1: 0.5102\n",
            "Epoch 136/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.5576 - accuracy: 0.8438 - precision_1: 0.8694 - recall_1: 0.8078\n",
            "Epoch 136: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.5552 - accuracy: 0.8444 - precision_1: 0.8703 - recall_1: 0.8083 - val_loss: 1.4899 - val_accuracy: 0.5285 - val_precision_1: 0.5311 - val_recall_1: 0.5203\n",
            "Epoch 137/10000\n",
            "130/132 [============================>.] - ETA: 0s - loss: 0.5792 - accuracy: 0.8333 - precision_1: 0.8532 - recall_1: 0.8077\n",
            "Epoch 137: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.5790 - accuracy: 0.8343 - precision_1: 0.8538 - recall_1: 0.8078 - val_loss: 1.3288 - val_accuracy: 0.5894 - val_precision_1: 0.6039 - val_recall_1: 0.5671\n",
            "Epoch 138/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.5396 - accuracy: 0.8536 - precision_1: 0.8755 - recall_1: 0.8318\n",
            "Epoch 138: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.5398 - accuracy: 0.8536 - precision_1: 0.8753 - recall_1: 0.8317 - val_loss: 1.4735 - val_accuracy: 0.5508 - val_precision_1: 0.5563 - val_recall_1: 0.5325\n",
            "Epoch 139/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.5649 - accuracy: 0.8401 - precision_1: 0.8608 - recall_1: 0.8083\n",
            "Epoch 139: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.5675 - accuracy: 0.8393 - precision_1: 0.8612 - recall_1: 0.8078 - val_loss: 1.5635 - val_accuracy: 0.5386 - val_precision_1: 0.5472 - val_recall_1: 0.5183\n",
            "Epoch 140/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.5676 - accuracy: 0.8358 - precision_1: 0.8627 - recall_1: 0.8017\n",
            "Epoch 140: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.5676 - accuracy: 0.8358 - precision_1: 0.8627 - recall_1: 0.8017 - val_loss: 1.4404 - val_accuracy: 0.5386 - val_precision_1: 0.5470 - val_recall_1: 0.5203\n",
            "Epoch 141/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.5728 - accuracy: 0.8343 - precision_1: 0.8624 - recall_1: 0.8124\n",
            "Epoch 141: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 10ms/step - loss: 0.5728 - accuracy: 0.8343 - precision_1: 0.8624 - recall_1: 0.8124 - val_loss: 1.4309 - val_accuracy: 0.5691 - val_precision_1: 0.5823 - val_recall_1: 0.5467\n",
            "Epoch 142/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.5057 - accuracy: 0.8625 - precision_1: 0.8777 - recall_1: 0.8362\n",
            "Epoch 142: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.5054 - accuracy: 0.8627 - precision_1: 0.8779 - recall_1: 0.8368 - val_loss: 1.6575 - val_accuracy: 0.5650 - val_precision_1: 0.5720 - val_recall_1: 0.5569\n",
            "Epoch 143/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.5131 - accuracy: 0.8598 - precision_1: 0.8832 - recall_1: 0.8294\n",
            "Epoch 143: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.5141 - accuracy: 0.8597 - precision_1: 0.8826 - recall_1: 0.8297 - val_loss: 1.7911 - val_accuracy: 0.4431 - val_precision_1: 0.4495 - val_recall_1: 0.4248\n",
            "Epoch 144/10000\n",
            "130/132 [============================>.] - ETA: 0s - loss: 0.5888 - accuracy: 0.8272 - precision_1: 0.8504 - recall_1: 0.8015\n",
            "Epoch 144: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.5864 - accuracy: 0.8282 - precision_1: 0.8517 - recall_1: 0.8027 - val_loss: 1.1125 - val_accuracy: 0.6138 - val_precision_1: 0.6516 - val_recall_1: 0.5854\n",
            "Epoch 145/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.5494 - accuracy: 0.8425 - precision_1: 0.8674 - recall_1: 0.8142\n",
            "Epoch 145: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.5468 - accuracy: 0.8434 - precision_1: 0.8684 - recall_1: 0.8155 - val_loss: 1.5778 - val_accuracy: 0.5488 - val_precision_1: 0.5702 - val_recall_1: 0.5285\n",
            "Epoch 146/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.5106 - accuracy: 0.8630 - precision_1: 0.8833 - recall_1: 0.8408\n",
            "Epoch 146: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.5101 - accuracy: 0.8627 - precision_1: 0.8830 - recall_1: 0.8404 - val_loss: 1.5848 - val_accuracy: 0.5346 - val_precision_1: 0.5357 - val_recall_1: 0.5183\n",
            "Epoch 147/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.5544 - accuracy: 0.8455 - precision_1: 0.8694 - recall_1: 0.8222\n",
            "Epoch 147: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.5533 - accuracy: 0.8454 - precision_1: 0.8694 - recall_1: 0.8226 - val_loss: 1.7212 - val_accuracy: 0.5142 - val_precision_1: 0.5161 - val_recall_1: 0.4878\n",
            "Epoch 148/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.5233 - accuracy: 0.8552 - precision_1: 0.8711 - recall_1: 0.8307\n",
            "Epoch 148: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.5215 - accuracy: 0.8556 - precision_1: 0.8714 - recall_1: 0.8302 - val_loss: 1.6166 - val_accuracy: 0.4776 - val_precision_1: 0.4871 - val_recall_1: 0.4593\n",
            "Epoch 149/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.6564 - accuracy: 0.8196 - precision_1: 0.8485 - recall_1: 0.7845\n",
            "Epoch 149: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.6591 - accuracy: 0.8185 - precision_1: 0.8481 - recall_1: 0.7834 - val_loss: 1.6667 - val_accuracy: 0.4146 - val_precision_1: 0.4096 - val_recall_1: 0.3821\n",
            "Epoch 150/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.5649 - accuracy: 0.8323 - precision_1: 0.8614 - recall_1: 0.8125\n",
            "Epoch 150: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.5632 - accuracy: 0.8327 - precision_1: 0.8620 - recall_1: 0.8129 - val_loss: 1.4718 - val_accuracy: 0.5224 - val_precision_1: 0.5351 - val_recall_1: 0.4959\n",
            "Epoch 151/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.5437 - accuracy: 0.8448 - precision_1: 0.8682 - recall_1: 0.8234\n",
            "Epoch 151: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.5415 - accuracy: 0.8454 - precision_1: 0.8683 - recall_1: 0.8246 - val_loss: 1.8644 - val_accuracy: 0.4980 - val_precision_1: 0.4979 - val_recall_1: 0.4776\n",
            "Epoch 152/10000\n",
            "130/132 [============================>.] - ETA: 0s - loss: 0.5434 - accuracy: 0.8528 - precision_1: 0.8680 - recall_1: 0.8297\n",
            "Epoch 152: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 2s 11ms/step - loss: 0.5431 - accuracy: 0.8531 - precision_1: 0.8682 - recall_1: 0.8302 - val_loss: 1.5982 - val_accuracy: 0.5285 - val_precision_1: 0.5316 - val_recall_1: 0.5122\n",
            "Epoch 153/10000\n",
            "130/132 [============================>.] - ETA: 0s - loss: 0.5037 - accuracy: 0.8574 - precision_1: 0.8755 - recall_1: 0.8364\n",
            "Epoch 153: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 10ms/step - loss: 0.5021 - accuracy: 0.8577 - precision_1: 0.8760 - recall_1: 0.8368 - val_loss: 1.9105 - val_accuracy: 0.4858 - val_precision_1: 0.4885 - val_recall_1: 0.4756\n",
            "Epoch 154/10000\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 0.5294 - accuracy: 0.8487 - precision_1: 0.8721 - recall_1: 0.8259\n",
            "Epoch 154: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.5273 - accuracy: 0.8495 - precision_1: 0.8738 - recall_1: 0.8271 - val_loss: 1.4528 - val_accuracy: 0.5346 - val_precision_1: 0.5516 - val_recall_1: 0.5102\n",
            "Epoch 155/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.4696 - accuracy: 0.8713 - precision_1: 0.8905 - recall_1: 0.8491\n",
            "Epoch 155: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.4736 - accuracy: 0.8709 - precision_1: 0.8897 - recall_1: 0.8485 - val_loss: 1.5633 - val_accuracy: 0.4472 - val_precision_1: 0.4533 - val_recall_1: 0.4045\n",
            "Epoch 156/10000\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 0.5300 - accuracy: 0.8491 - precision_1: 0.8742 - recall_1: 0.8336\n",
            "Epoch 156: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.5222 - accuracy: 0.8536 - precision_1: 0.8780 - recall_1: 0.8378 - val_loss: 1.3049 - val_accuracy: 0.5915 - val_precision_1: 0.5978 - val_recall_1: 0.5650\n",
            "Epoch 157/10000\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 0.5193 - accuracy: 0.8529 - precision_1: 0.8765 - recall_1: 0.8333\n",
            "Epoch 157: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.5154 - accuracy: 0.8556 - precision_1: 0.8787 - recall_1: 0.8363 - val_loss: 1.4967 - val_accuracy: 0.5569 - val_precision_1: 0.5754 - val_recall_1: 0.5508\n",
            "Epoch 158/10000\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 0.5239 - accuracy: 0.8529 - precision_1: 0.8689 - recall_1: 0.8349\n",
            "Epoch 158: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.5217 - accuracy: 0.8541 - precision_1: 0.8699 - recall_1: 0.8363 - val_loss: 1.7283 - val_accuracy: 0.5244 - val_precision_1: 0.5281 - val_recall_1: 0.5163\n",
            "Epoch 159/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.5127 - accuracy: 0.8594 - precision_1: 0.8762 - recall_1: 0.8377\n",
            "Epoch 159: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.5115 - accuracy: 0.8602 - precision_1: 0.8776 - recall_1: 0.8383 - val_loss: 1.4794 - val_accuracy: 0.5752 - val_precision_1: 0.5931 - val_recall_1: 0.5630\n",
            "Epoch 160/10000\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 0.5188 - accuracy: 0.8523 - precision_1: 0.8751 - recall_1: 0.8256\n",
            "Epoch 160: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.5184 - accuracy: 0.8531 - precision_1: 0.8755 - recall_1: 0.8261 - val_loss: 1.3987 - val_accuracy: 0.5711 - val_precision_1: 0.5823 - val_recall_1: 0.5467\n",
            "Epoch 161/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.4902 - accuracy: 0.8646 - precision_1: 0.8842 - recall_1: 0.8469\n",
            "Epoch 161: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.4906 - accuracy: 0.8648 - precision_1: 0.8846 - recall_1: 0.8454 - val_loss: 1.7243 - val_accuracy: 0.5386 - val_precision_1: 0.5516 - val_recall_1: 0.5325\n",
            "Epoch 162/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.5996 - accuracy: 0.8365 - precision_1: 0.8577 - recall_1: 0.8130\n",
            "Epoch 162: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 11ms/step - loss: 0.5959 - accuracy: 0.8378 - precision_1: 0.8585 - recall_1: 0.8144 - val_loss: 1.3863 - val_accuracy: 0.5285 - val_precision_1: 0.5317 - val_recall_1: 0.4939\n",
            "Epoch 163/10000\n",
            "130/132 [============================>.] - ETA: 0s - loss: 0.5724 - accuracy: 0.8472 - precision_1: 0.8686 - recall_1: 0.8241\n",
            "Epoch 163: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 11ms/step - loss: 0.5706 - accuracy: 0.8480 - precision_1: 0.8693 - recall_1: 0.8251 - val_loss: 1.5045 - val_accuracy: 0.5102 - val_precision_1: 0.5192 - val_recall_1: 0.4939\n",
            "Epoch 164/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.5074 - accuracy: 0.8594 - precision_1: 0.8805 - recall_1: 0.8450\n",
            "Epoch 164: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.5059 - accuracy: 0.8607 - precision_1: 0.8818 - recall_1: 0.8454 - val_loss: 1.3729 - val_accuracy: 0.5671 - val_precision_1: 0.5835 - val_recall_1: 0.5325\n",
            "Epoch 165/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.4581 - accuracy: 0.8760 - precision_1: 0.8978 - recall_1: 0.8532\n",
            "Epoch 165: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.4575 - accuracy: 0.8754 - precision_1: 0.8978 - recall_1: 0.8531 - val_loss: 1.5052 - val_accuracy: 0.5203 - val_precision_1: 0.5181 - val_recall_1: 0.4939\n",
            "Epoch 166/10000\n",
            "130/132 [============================>.] - ETA: 0s - loss: 0.4832 - accuracy: 0.8713 - precision_1: 0.8873 - recall_1: 0.8518\n",
            "Epoch 166: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.4872 - accuracy: 0.8693 - precision_1: 0.8860 - recall_1: 0.8495 - val_loss: 1.4766 - val_accuracy: 0.5691 - val_precision_1: 0.5965 - val_recall_1: 0.5467\n",
            "Epoch 167/10000\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 0.4959 - accuracy: 0.8693 - precision_1: 0.8930 - recall_1: 0.8501\n",
            "Epoch 167: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.4965 - accuracy: 0.8673 - precision_1: 0.8901 - recall_1: 0.8485 - val_loss: 1.5301 - val_accuracy: 0.5366 - val_precision_1: 0.5669 - val_recall_1: 0.5081\n",
            "Epoch 168/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.5304 - accuracy: 0.8625 - precision_1: 0.8813 - recall_1: 0.8427\n",
            "Epoch 168: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.5310 - accuracy: 0.8617 - precision_1: 0.8809 - recall_1: 0.8424 - val_loss: 1.5601 - val_accuracy: 0.5508 - val_precision_1: 0.5644 - val_recall_1: 0.5346\n",
            "Epoch 169/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.4685 - accuracy: 0.8745 - precision_1: 0.8931 - recall_1: 0.8598\n",
            "Epoch 169: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.4700 - accuracy: 0.8724 - precision_1: 0.8917 - recall_1: 0.8582 - val_loss: 1.5332 - val_accuracy: 0.5528 - val_precision_1: 0.5551 - val_recall_1: 0.5122\n",
            "Epoch 170/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.4579 - accuracy: 0.8776 - precision_1: 0.8988 - recall_1: 0.8646\n",
            "Epoch 170: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.4582 - accuracy: 0.8770 - precision_1: 0.8980 - recall_1: 0.8643 - val_loss: 1.3696 - val_accuracy: 0.5813 - val_precision_1: 0.5919 - val_recall_1: 0.5366\n",
            "Epoch 171/10000\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 0.6059 - accuracy: 0.8180 - precision_1: 0.8420 - recall_1: 0.7979\n",
            "Epoch 171: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.6004 - accuracy: 0.8200 - precision_1: 0.8443 - recall_1: 0.7997 - val_loss: 1.4197 - val_accuracy: 0.5467 - val_precision_1: 0.5560 - val_recall_1: 0.5244\n",
            "Epoch 172/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.5205 - accuracy: 0.8651 - precision_1: 0.8853 - recall_1: 0.8443\n",
            "Epoch 172: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.5201 - accuracy: 0.8643 - precision_1: 0.8843 - recall_1: 0.8434 - val_loss: 1.3108 - val_accuracy: 0.6098 - val_precision_1: 0.6190 - val_recall_1: 0.5813\n",
            "Epoch 173/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.5081 - accuracy: 0.8598 - precision_1: 0.8739 - recall_1: 0.8331\n",
            "Epoch 173: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.5085 - accuracy: 0.8602 - precision_1: 0.8741 - recall_1: 0.8332 - val_loss: 1.5396 - val_accuracy: 0.5203 - val_precision_1: 0.5275 - val_recall_1: 0.4878\n",
            "Epoch 174/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.4672 - accuracy: 0.8785 - precision_1: 0.8966 - recall_1: 0.8638\n",
            "Epoch 174: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.4672 - accuracy: 0.8785 - precision_1: 0.8966 - recall_1: 0.8638 - val_loss: 1.5474 - val_accuracy: 0.5346 - val_precision_1: 0.5468 - val_recall_1: 0.5102\n",
            "Epoch 175/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.4438 - accuracy: 0.8830 - precision_1: 0.8989 - recall_1: 0.8641\n",
            "Epoch 175: val_accuracy did not improve from 0.61789\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.4435 - accuracy: 0.8831 - precision_1: 0.8990 - recall_1: 0.8643 - val_loss: 1.4388 - val_accuracy: 0.5346 - val_precision_1: 0.5517 - val_recall_1: 0.5203\n",
            "Epoch 176/10000\n",
            "130/132 [============================>.] - ETA: 0s - loss: 1.0919 - accuracy: 0.7323 - precision_1: 0.7601 - recall_1: 0.7051\n",
            "Epoch 176: val_accuracy improved from 0.61789 to 0.62398, saving model to best_model.h5\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 1.0932 - accuracy: 0.7316 - precision_1: 0.7600 - recall_1: 0.7036 - val_loss: 1.2782 - val_accuracy: 0.6240 - val_precision_1: 0.6757 - val_recall_1: 0.5589\n",
            "Epoch 177/10000\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 0.7686 - accuracy: 0.7707 - precision_1: 0.8110 - recall_1: 0.7323\n",
            "Epoch 177: val_accuracy improved from 0.62398 to 0.64024, saving model to best_model.h5\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.7665 - accuracy: 0.7728 - precision_1: 0.8116 - recall_1: 0.7336 - val_loss: 1.1072 - val_accuracy: 0.6402 - val_precision_1: 0.6773 - val_recall_1: 0.5589\n",
            "Epoch 178/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.4434 - accuracy: 0.8855 - precision_1: 0.9077 - recall_1: 0.8662\n",
            "Epoch 178: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.4449 - accuracy: 0.8851 - precision_1: 0.9073 - recall_1: 0.8658 - val_loss: 1.3592 - val_accuracy: 0.5772 - val_precision_1: 0.5855 - val_recall_1: 0.5569\n",
            "Epoch 179/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.4269 - accuracy: 0.8936 - precision_1: 0.9124 - recall_1: 0.8743\n",
            "Epoch 179: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.4283 - accuracy: 0.8932 - precision_1: 0.9119 - recall_1: 0.8739 - val_loss: 1.3788 - val_accuracy: 0.5854 - val_precision_1: 0.5916 - val_recall_1: 0.5447\n",
            "Epoch 180/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.4440 - accuracy: 0.8837 - precision_1: 0.9050 - recall_1: 0.8615\n",
            "Epoch 180: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.4424 - accuracy: 0.8846 - precision_1: 0.9055 - recall_1: 0.8622 - val_loss: 1.6552 - val_accuracy: 0.4919 - val_precision_1: 0.4979 - val_recall_1: 0.4715\n",
            "Epoch 181/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.4382 - accuracy: 0.8861 - precision_1: 0.9014 - recall_1: 0.8640\n",
            "Epoch 181: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.4383 - accuracy: 0.8856 - precision_1: 0.9019 - recall_1: 0.8643 - val_loss: 1.5075 - val_accuracy: 0.5610 - val_precision_1: 0.5773 - val_recall_1: 0.5386\n",
            "Epoch 182/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.4312 - accuracy: 0.8827 - precision_1: 0.9006 - recall_1: 0.8661\n",
            "Epoch 182: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 10ms/step - loss: 0.4324 - accuracy: 0.8826 - precision_1: 0.9002 - recall_1: 0.8663 - val_loss: 1.4430 - val_accuracy: 0.5488 - val_precision_1: 0.5575 - val_recall_1: 0.5224\n",
            "Epoch 183/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.4671 - accuracy: 0.8805 - precision_1: 0.8947 - recall_1: 0.8597\n",
            "Epoch 183: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 11ms/step - loss: 0.4671 - accuracy: 0.8805 - precision_1: 0.8947 - recall_1: 0.8597 - val_loss: 1.6654 - val_accuracy: 0.5142 - val_precision_1: 0.5303 - val_recall_1: 0.4980\n",
            "Epoch 184/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.4371 - accuracy: 0.8819 - precision_1: 0.9040 - recall_1: 0.8651\n",
            "Epoch 184: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.4352 - accuracy: 0.8826 - precision_1: 0.9044 - recall_1: 0.8653 - val_loss: 1.4601 - val_accuracy: 0.5955 - val_precision_1: 0.6069 - val_recall_1: 0.5711\n",
            "Epoch 185/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.5811 - accuracy: 0.8458 - precision_1: 0.8639 - recall_1: 0.8239\n",
            "Epoch 185: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.5810 - accuracy: 0.8460 - precision_1: 0.8641 - recall_1: 0.8241 - val_loss: 1.5581 - val_accuracy: 0.5020 - val_precision_1: 0.5088 - val_recall_1: 0.4675\n",
            "Epoch 186/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.4120 - accuracy: 0.8946 - precision_1: 0.9106 - recall_1: 0.8791\n",
            "Epoch 186: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.4131 - accuracy: 0.8932 - precision_1: 0.9089 - recall_1: 0.8780 - val_loss: 1.6501 - val_accuracy: 0.5000 - val_precision_1: 0.5118 - val_recall_1: 0.4837\n",
            "Epoch 187/10000\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 0.4423 - accuracy: 0.8864 - precision_1: 0.8975 - recall_1: 0.8683\n",
            "Epoch 187: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.4360 - accuracy: 0.8882 - precision_1: 0.8997 - recall_1: 0.8709 - val_loss: 1.4011 - val_accuracy: 0.5569 - val_precision_1: 0.5668 - val_recall_1: 0.5346\n",
            "Epoch 188/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.4226 - accuracy: 0.8920 - precision_1: 0.9070 - recall_1: 0.8765\n",
            "Epoch 188: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.4231 - accuracy: 0.8912 - precision_1: 0.9068 - recall_1: 0.8754 - val_loss: 1.3202 - val_accuracy: 0.5894 - val_precision_1: 0.6189 - val_recall_1: 0.5711\n",
            "Epoch 189/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.4264 - accuracy: 0.9003 - precision_1: 0.9164 - recall_1: 0.8803\n",
            "Epoch 189: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.4268 - accuracy: 0.8983 - precision_1: 0.9148 - recall_1: 0.8790 - val_loss: 1.6418 - val_accuracy: 0.5366 - val_precision_1: 0.5404 - val_recall_1: 0.5163\n",
            "Epoch 190/10000\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 0.3874 - accuracy: 0.9024 - precision_1: 0.9159 - recall_1: 0.8891\n",
            "Epoch 190: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.3846 - accuracy: 0.9034 - precision_1: 0.9167 - recall_1: 0.8892 - val_loss: 1.3462 - val_accuracy: 0.5955 - val_precision_1: 0.6116 - val_recall_1: 0.5793\n",
            "Epoch 191/10000\n",
            "130/132 [============================>.] - ETA: 0s - loss: 0.4155 - accuracy: 0.8923 - precision_1: 0.9022 - recall_1: 0.8800\n",
            "Epoch 191: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.4148 - accuracy: 0.8927 - precision_1: 0.9025 - recall_1: 0.8800 - val_loss: 1.9188 - val_accuracy: 0.4858 - val_precision_1: 0.4906 - val_recall_1: 0.4756\n",
            "Epoch 192/10000\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 0.4134 - accuracy: 0.8974 - precision_1: 0.9117 - recall_1: 0.8847\n",
            "Epoch 192: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.4145 - accuracy: 0.8958 - precision_1: 0.9122 - recall_1: 0.8821 - val_loss: 1.6312 - val_accuracy: 0.4776 - val_precision_1: 0.4915 - val_recall_1: 0.4695\n",
            "Epoch 193/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.4172 - accuracy: 0.8977 - precision_1: 0.9077 - recall_1: 0.8763\n",
            "Epoch 193: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 10ms/step - loss: 0.4175 - accuracy: 0.8973 - precision_1: 0.9073 - recall_1: 0.8760 - val_loss: 1.6230 - val_accuracy: 0.5427 - val_precision_1: 0.5551 - val_recall_1: 0.5325\n",
            "Epoch 194/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.4095 - accuracy: 0.8932 - precision_1: 0.9131 - recall_1: 0.8815\n",
            "Epoch 194: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.4095 - accuracy: 0.8932 - precision_1: 0.9131 - recall_1: 0.8815 - val_loss: 1.9185 - val_accuracy: 0.4980 - val_precision_1: 0.5053 - val_recall_1: 0.4817\n",
            "Epoch 195/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.5125 - accuracy: 0.8688 - precision_1: 0.8855 - recall_1: 0.8531\n",
            "Epoch 195: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.5125 - accuracy: 0.8688 - precision_1: 0.8855 - recall_1: 0.8531 - val_loss: 1.7029 - val_accuracy: 0.4106 - val_precision_1: 0.4286 - val_recall_1: 0.3780\n",
            "Epoch 196/10000\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 0.4644 - accuracy: 0.8827 - precision_1: 0.8994 - recall_1: 0.8677\n",
            "Epoch 196: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.4691 - accuracy: 0.8810 - precision_1: 0.8978 - recall_1: 0.8663 - val_loss: 1.5727 - val_accuracy: 0.5650 - val_precision_1: 0.5687 - val_recall_1: 0.5467\n",
            "Epoch 197/10000\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 0.4437 - accuracy: 0.8853 - precision_1: 0.8981 - recall_1: 0.8699\n",
            "Epoch 197: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.4429 - accuracy: 0.8841 - precision_1: 0.8991 - recall_1: 0.8693 - val_loss: 1.8722 - val_accuracy: 0.5203 - val_precision_1: 0.5363 - val_recall_1: 0.5102\n",
            "Epoch 198/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.3860 - accuracy: 0.9129 - precision_1: 0.9207 - recall_1: 0.9018\n",
            "Epoch 198: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.3863 - accuracy: 0.9131 - precision_1: 0.9206 - recall_1: 0.9024 - val_loss: 1.3949 - val_accuracy: 0.5915 - val_precision_1: 0.6064 - val_recall_1: 0.5793\n",
            "Epoch 199/10000\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 0.4056 - accuracy: 0.8989 - precision_1: 0.9127 - recall_1: 0.8847\n",
            "Epoch 199: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.4085 - accuracy: 0.8968 - precision_1: 0.9108 - recall_1: 0.8821 - val_loss: 1.9822 - val_accuracy: 0.4512 - val_precision_1: 0.4526 - val_recall_1: 0.4370\n",
            "Epoch 200/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.4805 - accuracy: 0.8795 - precision_1: 0.8997 - recall_1: 0.8617\n",
            "Epoch 200: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.4805 - accuracy: 0.8795 - precision_1: 0.8997 - recall_1: 0.8617 - val_loss: 1.4350 - val_accuracy: 0.5772 - val_precision_1: 0.5884 - val_recall_1: 0.5549\n",
            "Epoch 201/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.4193 - accuracy: 0.8908 - precision_1: 0.9041 - recall_1: 0.8756\n",
            "Epoch 201: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.4148 - accuracy: 0.8922 - precision_1: 0.9051 - recall_1: 0.8775 - val_loss: 1.7350 - val_accuracy: 0.5447 - val_precision_1: 0.5426 - val_recall_1: 0.5183\n",
            "Epoch 202/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.4813 - accuracy: 0.8766 - precision_1: 0.8906 - recall_1: 0.8604\n",
            "Epoch 202: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.4779 - accuracy: 0.8775 - precision_1: 0.8911 - recall_1: 0.8612 - val_loss: 1.9144 - val_accuracy: 0.5122 - val_precision_1: 0.5140 - val_recall_1: 0.4858\n",
            "Epoch 203/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.4095 - accuracy: 0.8974 - precision_1: 0.9162 - recall_1: 0.8880\n",
            "Epoch 203: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 10ms/step - loss: 0.4064 - accuracy: 0.8993 - precision_1: 0.9177 - recall_1: 0.8897 - val_loss: 1.9978 - val_accuracy: 0.5102 - val_precision_1: 0.5162 - val_recall_1: 0.4858\n",
            "Epoch 204/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.3966 - accuracy: 0.9034 - precision_1: 0.9155 - recall_1: 0.8927\n",
            "Epoch 204: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.3966 - accuracy: 0.9034 - precision_1: 0.9155 - recall_1: 0.8927 - val_loss: 1.7470 - val_accuracy: 0.5488 - val_precision_1: 0.5532 - val_recall_1: 0.5285\n",
            "Epoch 205/10000\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 0.4194 - accuracy: 0.8981 - precision_1: 0.9111 - recall_1: 0.8805\n",
            "Epoch 205: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.4250 - accuracy: 0.8958 - precision_1: 0.9090 - recall_1: 0.8790 - val_loss: 1.3247 - val_accuracy: 0.6138 - val_precision_1: 0.6291 - val_recall_1: 0.5894\n",
            "Epoch 206/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.4049 - accuracy: 0.8993 - precision_1: 0.9116 - recall_1: 0.8856\n",
            "Epoch 206: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.4049 - accuracy: 0.8993 - precision_1: 0.9116 - recall_1: 0.8856 - val_loss: 1.8734 - val_accuracy: 0.4898 - val_precision_1: 0.4926 - val_recall_1: 0.4756\n",
            "Epoch 207/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.3661 - accuracy: 0.9085 - precision_1: 0.9169 - recall_1: 0.9008\n",
            "Epoch 207: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3676 - accuracy: 0.9075 - precision_1: 0.9157 - recall_1: 0.8998 - val_loss: 1.6224 - val_accuracy: 0.5589 - val_precision_1: 0.5717 - val_recall_1: 0.5508\n",
            "Epoch 208/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.5887 - accuracy: 0.8479 - precision_1: 0.8629 - recall_1: 0.8297\n",
            "Epoch 208: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.5838 - accuracy: 0.8490 - precision_1: 0.8646 - recall_1: 0.8312 - val_loss: 1.5202 - val_accuracy: 0.5569 - val_precision_1: 0.5621 - val_recall_1: 0.5244\n",
            "Epoch 209/10000\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 0.3881 - accuracy: 0.9042 - precision_1: 0.9180 - recall_1: 0.8889\n",
            "Epoch 209: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.3980 - accuracy: 0.9014 - precision_1: 0.9154 - recall_1: 0.8851 - val_loss: 1.4873 - val_accuracy: 0.5508 - val_precision_1: 0.5640 - val_recall_1: 0.5285\n",
            "Epoch 210/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.3819 - accuracy: 0.9095 - precision_1: 0.9239 - recall_1: 0.8948\n",
            "Epoch 210: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.3819 - accuracy: 0.9095 - precision_1: 0.9239 - recall_1: 0.8948 - val_loss: 2.0394 - val_accuracy: 0.4776 - val_precision_1: 0.4895 - val_recall_1: 0.4736\n",
            "Epoch 211/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.3485 - accuracy: 0.9167 - precision_1: 0.9254 - recall_1: 0.9047\n",
            "Epoch 211: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3488 - accuracy: 0.9171 - precision_1: 0.9256 - recall_1: 0.9049 - val_loss: 1.7161 - val_accuracy: 0.5305 - val_precision_1: 0.5264 - val_recall_1: 0.5061\n",
            "Epoch 212/10000\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 0.4149 - accuracy: 0.8981 - precision_1: 0.9090 - recall_1: 0.8848\n",
            "Epoch 212: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.4138 - accuracy: 0.8973 - precision_1: 0.9086 - recall_1: 0.8846 - val_loss: 1.9499 - val_accuracy: 0.4776 - val_precision_1: 0.4753 - val_recall_1: 0.4492\n",
            "Epoch 213/10000\n",
            "130/132 [============================>.] - ETA: 0s - loss: 0.4074 - accuracy: 0.9005 - precision_1: 0.9120 - recall_1: 0.8877\n",
            "Epoch 213: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 10ms/step - loss: 0.4073 - accuracy: 0.8998 - precision_1: 0.9112 - recall_1: 0.8871 - val_loss: 2.5584 - val_accuracy: 0.4776 - val_precision_1: 0.4833 - val_recall_1: 0.4695\n",
            "Epoch 214/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.3866 - accuracy: 0.9034 - precision_1: 0.9150 - recall_1: 0.8961\n",
            "Epoch 214: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.3848 - accuracy: 0.9039 - precision_1: 0.9154 - recall_1: 0.8968 - val_loss: 1.7735 - val_accuracy: 0.5183 - val_precision_1: 0.5241 - val_recall_1: 0.5081\n",
            "Epoch 215/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.3526 - accuracy: 0.9234 - precision_1: 0.9313 - recall_1: 0.9108\n",
            "Epoch 215: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3589 - accuracy: 0.9212 - precision_1: 0.9288 - recall_1: 0.9090 - val_loss: 1.6408 - val_accuracy: 0.5569 - val_precision_1: 0.5672 - val_recall_1: 0.5488\n",
            "Epoch 216/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.5144 - accuracy: 0.8627 - precision_1: 0.8740 - recall_1: 0.8500\n",
            "Epoch 216: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.5144 - accuracy: 0.8627 - precision_1: 0.8740 - recall_1: 0.8500 - val_loss: 1.2897 - val_accuracy: 0.6280 - val_precision_1: 0.6435 - val_recall_1: 0.6016\n",
            "Epoch 217/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.3588 - accuracy: 0.9152 - precision_1: 0.9231 - recall_1: 0.9059\n",
            "Epoch 217: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3606 - accuracy: 0.9156 - precision_1: 0.9238 - recall_1: 0.9065 - val_loss: 1.9562 - val_accuracy: 0.4898 - val_precision_1: 0.4884 - val_recall_1: 0.4695\n",
            "Epoch 218/10000\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 0.3807 - accuracy: 0.9051 - precision_1: 0.9146 - recall_1: 0.8965\n",
            "Epoch 218: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3834 - accuracy: 0.9034 - precision_1: 0.9143 - recall_1: 0.8948 - val_loss: 1.5733 - val_accuracy: 0.5630 - val_precision_1: 0.5662 - val_recall_1: 0.5386\n",
            "Epoch 219/10000\n",
            "130/132 [============================>.] - ETA: 0s - loss: 0.3974 - accuracy: 0.9026 - precision_1: 0.9144 - recall_1: 0.8928\n",
            "Epoch 219: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3977 - accuracy: 0.9024 - precision_1: 0.9141 - recall_1: 0.8927 - val_loss: 1.4997 - val_accuracy: 0.5610 - val_precision_1: 0.5690 - val_recall_1: 0.5447\n",
            "Epoch 220/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.3470 - accuracy: 0.9191 - precision_1: 0.9289 - recall_1: 0.9115\n",
            "Epoch 220: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.3469 - accuracy: 0.9192 - precision_1: 0.9290 - recall_1: 0.9115 - val_loss: 1.8559 - val_accuracy: 0.4756 - val_precision_1: 0.4828 - val_recall_1: 0.4553\n",
            "Epoch 221/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.3672 - accuracy: 0.9115 - precision_1: 0.9210 - recall_1: 0.9013\n",
            "Epoch 221: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.3669 - accuracy: 0.9115 - precision_1: 0.9210 - recall_1: 0.9014 - val_loss: 1.4910 - val_accuracy: 0.6057 - val_precision_1: 0.6066 - val_recall_1: 0.5955\n",
            "Epoch 222/10000\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 0.3643 - accuracy: 0.9132 - precision_1: 0.9202 - recall_1: 0.9085\n",
            "Epoch 222: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.3615 - accuracy: 0.9141 - precision_1: 0.9207 - recall_1: 0.9095 - val_loss: 1.9458 - val_accuracy: 0.4553 - val_precision_1: 0.4509 - val_recall_1: 0.4289\n",
            "Epoch 223/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.3622 - accuracy: 0.9177 - precision_1: 0.9226 - recall_1: 0.9120\n",
            "Epoch 223: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 10ms/step - loss: 0.3634 - accuracy: 0.9166 - precision_1: 0.9213 - recall_1: 0.9105 - val_loss: 1.6726 - val_accuracy: 0.5203 - val_precision_1: 0.5245 - val_recall_1: 0.5000\n",
            "Epoch 224/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.3718 - accuracy: 0.9089 - precision_1: 0.9180 - recall_1: 0.8984\n",
            "Epoch 224: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.3694 - accuracy: 0.9100 - precision_1: 0.9195 - recall_1: 0.8998 - val_loss: 1.5736 - val_accuracy: 0.5650 - val_precision_1: 0.5687 - val_recall_1: 0.5467\n",
            "Epoch 225/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.4148 - accuracy: 0.8997 - precision_1: 0.9102 - recall_1: 0.8882\n",
            "Epoch 225: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.4106 - accuracy: 0.9024 - precision_1: 0.9125 - recall_1: 0.8907 - val_loss: 1.6460 - val_accuracy: 0.5610 - val_precision_1: 0.5699 - val_recall_1: 0.5549\n",
            "Epoch 226/10000\n",
            "130/132 [============================>.] - ETA: 0s - loss: 0.4194 - accuracy: 0.8979 - precision_1: 0.9087 - recall_1: 0.8877\n",
            "Epoch 226: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.4183 - accuracy: 0.8983 - precision_1: 0.9089 - recall_1: 0.8882 - val_loss: 2.0771 - val_accuracy: 0.5102 - val_precision_1: 0.5105 - val_recall_1: 0.4939\n",
            "Epoch 227/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.3406 - accuracy: 0.9230 - precision_1: 0.9323 - recall_1: 0.9111\n",
            "Epoch 227: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3410 - accuracy: 0.9227 - precision_1: 0.9319 - recall_1: 0.9110 - val_loss: 2.6768 - val_accuracy: 0.4797 - val_precision_1: 0.4823 - val_recall_1: 0.4715\n",
            "Epoch 228/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.3491 - accuracy: 0.9176 - precision_1: 0.9274 - recall_1: 0.9123\n",
            "Epoch 228: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3506 - accuracy: 0.9181 - precision_1: 0.9277 - recall_1: 0.9131 - val_loss: 1.9221 - val_accuracy: 0.5467 - val_precision_1: 0.5432 - val_recall_1: 0.5244\n",
            "Epoch 229/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.4190 - accuracy: 0.8997 - precision_1: 0.9094 - recall_1: 0.8891\n",
            "Epoch 229: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.4189 - accuracy: 0.8998 - precision_1: 0.9095 - recall_1: 0.8892 - val_loss: 1.2990 - val_accuracy: 0.6301 - val_precision_1: 0.6333 - val_recall_1: 0.6037\n",
            "Epoch 230/10000\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 0.5801 - accuracy: 0.8421 - precision_1: 0.8669 - recall_1: 0.8299\n",
            "Epoch 230: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.5716 - accuracy: 0.8454 - precision_1: 0.8690 - recall_1: 0.8327 - val_loss: 1.5485 - val_accuracy: 0.5630 - val_precision_1: 0.5739 - val_recall_1: 0.5447\n",
            "Epoch 231/10000\n",
            "130/132 [============================>.] - ETA: 0s - loss: 0.3616 - accuracy: 0.9118 - precision_1: 0.9224 - recall_1: 0.9026\n",
            "Epoch 231: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3599 - accuracy: 0.9126 - precision_1: 0.9231 - recall_1: 0.9034 - val_loss: 1.7656 - val_accuracy: 0.5346 - val_precision_1: 0.5326 - val_recall_1: 0.5142\n",
            "Epoch 232/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.3157 - accuracy: 0.9359 - precision_1: 0.9414 - recall_1: 0.9286\n",
            "Epoch 232: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3143 - accuracy: 0.9365 - precision_1: 0.9418 - recall_1: 0.9293 - val_loss: 1.9719 - val_accuracy: 0.4939 - val_precision_1: 0.4938 - val_recall_1: 0.4817\n",
            "Epoch 233/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.3347 - accuracy: 0.9224 - precision_1: 0.9274 - recall_1: 0.9109\n",
            "Epoch 233: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3344 - accuracy: 0.9227 - precision_1: 0.9276 - recall_1: 0.9115 - val_loss: 1.7718 - val_accuracy: 0.4817 - val_precision_1: 0.4895 - val_recall_1: 0.4756\n",
            "Epoch 234/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.3656 - accuracy: 0.9155 - precision_1: 0.9236 - recall_1: 0.9076\n",
            "Epoch 234: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.3634 - accuracy: 0.9166 - precision_1: 0.9245 - recall_1: 0.9090 - val_loss: 1.6341 - val_accuracy: 0.5325 - val_precision_1: 0.5445 - val_recall_1: 0.5102\n",
            "Epoch 235/10000\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 0.3185 - accuracy: 0.9291 - precision_1: 0.9363 - recall_1: 0.9243\n",
            "Epoch 235: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 10ms/step - loss: 0.3228 - accuracy: 0.9268 - precision_1: 0.9341 - recall_1: 0.9222 - val_loss: 1.8620 - val_accuracy: 0.5041 - val_precision_1: 0.5179 - val_recall_1: 0.5000\n",
            "Epoch 236/10000\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 0.3127 - accuracy: 0.9339 - precision_1: 0.9424 - recall_1: 0.9248\n",
            "Epoch 236: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.3102 - accuracy: 0.9344 - precision_1: 0.9435 - recall_1: 0.9258 - val_loss: 1.8285 - val_accuracy: 0.5589 - val_precision_1: 0.5603 - val_recall_1: 0.5386\n",
            "Epoch 237/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.3492 - accuracy: 0.9219 - precision_1: 0.9298 - recall_1: 0.9109\n",
            "Epoch 237: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.3511 - accuracy: 0.9222 - precision_1: 0.9309 - recall_1: 0.9105 - val_loss: 1.6998 - val_accuracy: 0.5467 - val_precision_1: 0.5662 - val_recall_1: 0.5386\n",
            "Epoch 238/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.3721 - accuracy: 0.9101 - precision_1: 0.9221 - recall_1: 0.8992\n",
            "Epoch 238: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3701 - accuracy: 0.9110 - precision_1: 0.9229 - recall_1: 0.9004 - val_loss: 1.9436 - val_accuracy: 0.4817 - val_precision_1: 0.4916 - val_recall_1: 0.4736\n",
            "Epoch 239/10000\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 0.3327 - accuracy: 0.9265 - precision_1: 0.9309 - recall_1: 0.9201\n",
            "Epoch 239: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.3309 - accuracy: 0.9273 - precision_1: 0.9321 - recall_1: 0.9207 - val_loss: 1.9421 - val_accuracy: 0.5000 - val_precision_1: 0.5064 - val_recall_1: 0.4817\n",
            "Epoch 240/10000\n",
            "125/132 [===========================>..] - ETA: 0s - loss: 0.3330 - accuracy: 0.9232 - precision_1: 0.9299 - recall_1: 0.9131\n",
            "Epoch 240: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3337 - accuracy: 0.9227 - precision_1: 0.9291 - recall_1: 0.9131 - val_loss: 2.0491 - val_accuracy: 0.5305 - val_precision_1: 0.5364 - val_recall_1: 0.5244\n",
            "Epoch 241/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.4230 - accuracy: 0.8974 - precision_1: 0.9063 - recall_1: 0.8870\n",
            "Epoch 241: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.4201 - accuracy: 0.8988 - precision_1: 0.9076 - recall_1: 0.8887 - val_loss: 1.4737 - val_accuracy: 0.5813 - val_precision_1: 0.6013 - val_recall_1: 0.5671\n",
            "Epoch 242/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.3063 - accuracy: 0.9390 - precision_1: 0.9473 - recall_1: 0.9292\n",
            "Epoch 242: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.3059 - accuracy: 0.9395 - precision_1: 0.9477 - recall_1: 0.9298 - val_loss: 1.8862 - val_accuracy: 0.5224 - val_precision_1: 0.5273 - val_recall_1: 0.5102\n",
            "Epoch 243/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.3362 - accuracy: 0.9272 - precision_1: 0.9327 - recall_1: 0.9170\n",
            "Epoch 243: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3360 - accuracy: 0.9273 - precision_1: 0.9328 - recall_1: 0.9171 - val_loss: 1.8669 - val_accuracy: 0.5081 - val_precision_1: 0.5148 - val_recall_1: 0.4959\n",
            "Epoch 244/10000\n",
            "130/132 [============================>.] - ETA: 0s - loss: 0.3757 - accuracy: 0.9113 - precision_1: 0.9221 - recall_1: 0.9046\n",
            "Epoch 244: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.3754 - accuracy: 0.9115 - precision_1: 0.9223 - recall_1: 0.9049 - val_loss: 1.9524 - val_accuracy: 0.5000 - val_precision_1: 0.5094 - val_recall_1: 0.4959\n",
            "Epoch 245/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.4646 - accuracy: 0.8894 - precision_1: 0.8985 - recall_1: 0.8786\n",
            "Epoch 245: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 2s 11ms/step - loss: 0.4610 - accuracy: 0.8907 - precision_1: 0.8997 - recall_1: 0.8800 - val_loss: 1.5164 - val_accuracy: 0.5854 - val_precision_1: 0.5882 - val_recall_1: 0.5691\n",
            "Epoch 246/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.3016 - accuracy: 0.9370 - precision_1: 0.9436 - recall_1: 0.9307\n",
            "Epoch 246: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3057 - accuracy: 0.9349 - precision_1: 0.9418 - recall_1: 0.9288 - val_loss: 1.6349 - val_accuracy: 0.5508 - val_precision_1: 0.5699 - val_recall_1: 0.5386\n",
            "Epoch 247/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.4002 - accuracy: 0.9111 - precision_1: 0.9192 - recall_1: 0.8992\n",
            "Epoch 247: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3985 - accuracy: 0.9115 - precision_1: 0.9195 - recall_1: 0.8998 - val_loss: 2.2196 - val_accuracy: 0.5000 - val_precision_1: 0.5031 - val_recall_1: 0.4919\n",
            "Epoch 248/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.2960 - accuracy: 0.9391 - precision_1: 0.9437 - recall_1: 0.9333\n",
            "Epoch 248: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.2959 - accuracy: 0.9395 - precision_1: 0.9440 - recall_1: 0.9334 - val_loss: 1.7410 - val_accuracy: 0.5264 - val_precision_1: 0.5230 - val_recall_1: 0.5081\n",
            "Epoch 249/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.3043 - accuracy: 0.9339 - precision_1: 0.9418 - recall_1: 0.9271\n",
            "Epoch 249: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3057 - accuracy: 0.9339 - precision_1: 0.9416 - recall_1: 0.9268 - val_loss: 2.0957 - val_accuracy: 0.5142 - val_precision_1: 0.5166 - val_recall_1: 0.5061\n",
            "Epoch 250/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.3165 - accuracy: 0.9318 - precision_1: 0.9366 - recall_1: 0.9235\n",
            "Epoch 250: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3169 - accuracy: 0.9319 - precision_1: 0.9366 - recall_1: 0.9237 - val_loss: 1.8977 - val_accuracy: 0.5224 - val_precision_1: 0.5312 - val_recall_1: 0.5183\n",
            "Epoch 251/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.3504 - accuracy: 0.9158 - precision_1: 0.9264 - recall_1: 0.9101\n",
            "Epoch 251: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.3485 - accuracy: 0.9171 - precision_1: 0.9276 - recall_1: 0.9115 - val_loss: 1.6232 - val_accuracy: 0.5854 - val_precision_1: 0.5897 - val_recall_1: 0.5813\n",
            "Epoch 252/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.2816 - accuracy: 0.9442 - precision_1: 0.9503 - recall_1: 0.9390\n",
            "Epoch 252: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.2833 - accuracy: 0.9431 - precision_1: 0.9491 - recall_1: 0.9380 - val_loss: 2.0224 - val_accuracy: 0.4959 - val_precision_1: 0.5011 - val_recall_1: 0.4837\n",
            "Epoch 253/10000\n",
            "130/132 [============================>.] - ETA: 0s - loss: 0.2962 - accuracy: 0.9390 - precision_1: 0.9455 - recall_1: 0.9344\n",
            "Epoch 253: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.2948 - accuracy: 0.9395 - precision_1: 0.9460 - recall_1: 0.9349 - val_loss: 1.9955 - val_accuracy: 0.5305 - val_precision_1: 0.5322 - val_recall_1: 0.5203\n",
            "Epoch 254/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.3402 - accuracy: 0.9234 - precision_1: 0.9338 - recall_1: 0.9182\n",
            "Epoch 254: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 11ms/step - loss: 0.3431 - accuracy: 0.9222 - precision_1: 0.9328 - recall_1: 0.9171 - val_loss: 1.3846 - val_accuracy: 0.6179 - val_precision_1: 0.6303 - val_recall_1: 0.6098\n",
            "Epoch 255/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.2907 - accuracy: 0.9370 - precision_1: 0.9466 - recall_1: 0.9318\n",
            "Epoch 255: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.2909 - accuracy: 0.9370 - precision_1: 0.9463 - recall_1: 0.9319 - val_loss: 2.2416 - val_accuracy: 0.4858 - val_precision_1: 0.4885 - val_recall_1: 0.4756\n",
            "Epoch 256/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.3074 - accuracy: 0.9288 - precision_1: 0.9370 - recall_1: 0.9237\n",
            "Epoch 256: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 10ms/step - loss: 0.3073 - accuracy: 0.9288 - precision_1: 0.9371 - recall_1: 0.9237 - val_loss: 1.8297 - val_accuracy: 0.5224 - val_precision_1: 0.5280 - val_recall_1: 0.5183\n",
            "Epoch 257/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.2590 - accuracy: 0.9504 - precision_1: 0.9535 - recall_1: 0.9432\n",
            "Epoch 257: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.2593 - accuracy: 0.9507 - precision_1: 0.9538 - recall_1: 0.9436 - val_loss: 1.9794 - val_accuracy: 0.4898 - val_precision_1: 0.4928 - val_recall_1: 0.4837\n",
            "Epoch 258/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.3353 - accuracy: 0.9276 - precision_1: 0.9339 - recall_1: 0.9202\n",
            "Epoch 258: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3377 - accuracy: 0.9273 - precision_1: 0.9334 - recall_1: 0.9197 - val_loss: 2.0149 - val_accuracy: 0.5183 - val_precision_1: 0.5189 - val_recall_1: 0.5020\n",
            "Epoch 259/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.3178 - accuracy: 0.9286 - precision_1: 0.9337 - recall_1: 0.9234\n",
            "Epoch 259: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3166 - accuracy: 0.9293 - precision_1: 0.9342 - recall_1: 0.9243 - val_loss: 1.5498 - val_accuracy: 0.5894 - val_precision_1: 0.5987 - val_recall_1: 0.5793\n",
            "Epoch 260/10000\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 0.3285 - accuracy: 0.9286 - precision_1: 0.9325 - recall_1: 0.9217\n",
            "Epoch 260: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3356 - accuracy: 0.9283 - precision_1: 0.9320 - recall_1: 0.9202 - val_loss: 1.9769 - val_accuracy: 0.5589 - val_precision_1: 0.5585 - val_recall_1: 0.5528\n",
            "Epoch 261/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.3182 - accuracy: 0.9365 - precision_1: 0.9440 - recall_1: 0.9312\n",
            "Epoch 261: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3164 - accuracy: 0.9375 - precision_1: 0.9448 - recall_1: 0.9319 - val_loss: 1.5303 - val_accuracy: 0.5569 - val_precision_1: 0.5626 - val_recall_1: 0.5386\n",
            "Epoch 262/10000\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 0.2782 - accuracy: 0.9407 - precision_1: 0.9486 - recall_1: 0.9370\n",
            "Epoch 262: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.2807 - accuracy: 0.9415 - precision_1: 0.9490 - recall_1: 0.9375 - val_loss: 2.0379 - val_accuracy: 0.5447 - val_precision_1: 0.5532 - val_recall_1: 0.5386\n",
            "Epoch 263/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.3548 - accuracy: 0.9244 - precision_1: 0.9311 - recall_1: 0.9155\n",
            "Epoch 263: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3517 - accuracy: 0.9258 - precision_1: 0.9323 - recall_1: 0.9166 - val_loss: 1.9639 - val_accuracy: 0.5569 - val_precision_1: 0.5542 - val_recall_1: 0.5407\n",
            "Epoch 264/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.3002 - accuracy: 0.9360 - precision_1: 0.9398 - recall_1: 0.9265\n",
            "Epoch 264: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 10ms/step - loss: 0.3005 - accuracy: 0.9354 - precision_1: 0.9392 - recall_1: 0.9263 - val_loss: 1.8325 - val_accuracy: 0.5122 - val_precision_1: 0.5230 - val_recall_1: 0.5081\n",
            "Epoch 265/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.3035 - accuracy: 0.9374 - precision_1: 0.9428 - recall_1: 0.9308\n",
            "Epoch 265: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 2s 13ms/step - loss: 0.3034 - accuracy: 0.9375 - precision_1: 0.9428 - recall_1: 0.9309 - val_loss: 1.4527 - val_accuracy: 0.6260 - val_precision_1: 0.6342 - val_recall_1: 0.6098\n",
            "Epoch 266/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.2751 - accuracy: 0.9466 - precision_1: 0.9496 - recall_1: 0.9394\n",
            "Epoch 266: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.2749 - accuracy: 0.9466 - precision_1: 0.9496 - recall_1: 0.9395 - val_loss: 1.8434 - val_accuracy: 0.5244 - val_precision_1: 0.5243 - val_recall_1: 0.5041\n",
            "Epoch 267/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.3101 - accuracy: 0.9339 - precision_1: 0.9434 - recall_1: 0.9281\n",
            "Epoch 267: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3202 - accuracy: 0.9309 - precision_1: 0.9406 - recall_1: 0.9253 - val_loss: 1.5821 - val_accuracy: 0.6199 - val_precision_1: 0.6253 - val_recall_1: 0.6037\n",
            "Epoch 268/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.3130 - accuracy: 0.9365 - precision_1: 0.9409 - recall_1: 0.9304\n",
            "Epoch 268: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3130 - accuracy: 0.9365 - precision_1: 0.9409 - recall_1: 0.9304 - val_loss: 1.8343 - val_accuracy: 0.5854 - val_precision_1: 0.5871 - val_recall_1: 0.5752\n",
            "Epoch 269/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.2781 - accuracy: 0.9433 - precision_1: 0.9465 - recall_1: 0.9375\n",
            "Epoch 269: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.2796 - accuracy: 0.9431 - precision_1: 0.9461 - recall_1: 0.9375 - val_loss: 2.2094 - val_accuracy: 0.5102 - val_precision_1: 0.5157 - val_recall_1: 0.5020\n",
            "Epoch 270/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.3027 - accuracy: 0.9349 - precision_1: 0.9379 - recall_1: 0.9286\n",
            "Epoch 270: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3025 - accuracy: 0.9349 - precision_1: 0.9379 - recall_1: 0.9288 - val_loss: 1.8575 - val_accuracy: 0.5610 - val_precision_1: 0.5667 - val_recall_1: 0.5528\n",
            "Epoch 271/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.3160 - accuracy: 0.9319 - precision_1: 0.9393 - recall_1: 0.9278\n",
            "Epoch 271: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3160 - accuracy: 0.9319 - precision_1: 0.9393 - recall_1: 0.9278 - val_loss: 1.6589 - val_accuracy: 0.5854 - val_precision_1: 0.5884 - val_recall_1: 0.5752\n",
            "Epoch 272/10000\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 0.2993 - accuracy: 0.9370 - precision_1: 0.9465 - recall_1: 0.9354\n",
            "Epoch 272: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.2960 - accuracy: 0.9380 - precision_1: 0.9470 - recall_1: 0.9365 - val_loss: 2.0011 - val_accuracy: 0.5549 - val_precision_1: 0.5608 - val_recall_1: 0.5528\n",
            "Epoch 273/10000\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 0.2909 - accuracy: 0.9370 - precision_1: 0.9427 - recall_1: 0.9312\n",
            "Epoch 273: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.2935 - accuracy: 0.9370 - precision_1: 0.9424 - recall_1: 0.9314 - val_loss: 1.8558 - val_accuracy: 0.5589 - val_precision_1: 0.5597 - val_recall_1: 0.5427\n",
            "Epoch 274/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.2663 - accuracy: 0.9502 - precision_1: 0.9529 - recall_1: 0.9456\n",
            "Epoch 274: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 11ms/step - loss: 0.2663 - accuracy: 0.9502 - precision_1: 0.9529 - recall_1: 0.9456 - val_loss: 2.1316 - val_accuracy: 0.4817 - val_precision_1: 0.4762 - val_recall_1: 0.4675\n",
            "Epoch 275/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.2811 - accuracy: 0.9359 - precision_1: 0.9420 - recall_1: 0.9318\n",
            "Epoch 275: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 2s 11ms/step - loss: 0.2791 - accuracy: 0.9370 - precision_1: 0.9430 - recall_1: 0.9329 - val_loss: 1.9165 - val_accuracy: 0.5671 - val_precision_1: 0.5747 - val_recall_1: 0.5630\n",
            "Epoch 276/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.2596 - accuracy: 0.9549 - precision_1: 0.9587 - recall_1: 0.9496\n",
            "Epoch 276: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.2630 - accuracy: 0.9522 - precision_1: 0.9564 - recall_1: 0.9471 - val_loss: 1.9852 - val_accuracy: 0.5386 - val_precision_1: 0.5470 - val_recall_1: 0.5325\n",
            "Epoch 277/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.3736 - accuracy: 0.9192 - precision_1: 0.9266 - recall_1: 0.9110\n",
            "Epoch 277: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3736 - accuracy: 0.9192 - precision_1: 0.9266 - recall_1: 0.9110 - val_loss: 2.2308 - val_accuracy: 0.5020 - val_precision_1: 0.5084 - val_recall_1: 0.4898\n",
            "Epoch 278/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.3281 - accuracy: 0.9339 - precision_1: 0.9396 - recall_1: 0.9307\n",
            "Epoch 278: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3272 - accuracy: 0.9339 - precision_1: 0.9395 - recall_1: 0.9309 - val_loss: 2.1766 - val_accuracy: 0.4817 - val_precision_1: 0.4854 - val_recall_1: 0.4715\n",
            "Epoch 279/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.3150 - accuracy: 0.9375 - precision_1: 0.9418 - recall_1: 0.9344\n",
            "Epoch 279: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3107 - accuracy: 0.9390 - precision_1: 0.9431 - recall_1: 0.9359 - val_loss: 2.2208 - val_accuracy: 0.5000 - val_precision_1: 0.5010 - val_recall_1: 0.4878\n",
            "Epoch 280/10000\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 0.2298 - accuracy: 0.9593 - precision_1: 0.9633 - recall_1: 0.9582\n",
            "Epoch 280: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.2306 - accuracy: 0.9593 - precision_1: 0.9632 - recall_1: 0.9583 - val_loss: 2.0842 - val_accuracy: 0.5366 - val_precision_1: 0.5343 - val_recall_1: 0.5224\n",
            "Epoch 281/10000\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 0.2915 - accuracy: 0.9392 - precision_1: 0.9419 - recall_1: 0.9349\n",
            "Epoch 281: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.2886 - accuracy: 0.9405 - precision_1: 0.9432 - recall_1: 0.9365 - val_loss: 1.8953 - val_accuracy: 0.5671 - val_precision_1: 0.5705 - val_recall_1: 0.5589\n",
            "Epoch 282/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.2401 - accuracy: 0.9627 - precision_1: 0.9662 - recall_1: 0.9617\n",
            "Epoch 282: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.2388 - accuracy: 0.9629 - precision_1: 0.9663 - recall_1: 0.9619 - val_loss: 2.1772 - val_accuracy: 0.4634 - val_precision_1: 0.4644 - val_recall_1: 0.4512\n",
            "Epoch 283/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.2276 - accuracy: 0.9629 - precision_1: 0.9642 - recall_1: 0.9578\n",
            "Epoch 283: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.2276 - accuracy: 0.9629 - precision_1: 0.9642 - recall_1: 0.9578 - val_loss: 2.0006 - val_accuracy: 0.5183 - val_precision_1: 0.5197 - val_recall_1: 0.5102\n",
            "Epoch 284/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.2476 - accuracy: 0.9491 - precision_1: 0.9540 - recall_1: 0.9470\n",
            "Epoch 284: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 11ms/step - loss: 0.2491 - accuracy: 0.9492 - precision_1: 0.9539 - recall_1: 0.9471 - val_loss: 1.9908 - val_accuracy: 0.4980 - val_precision_1: 0.4990 - val_recall_1: 0.4878\n",
            "Epoch 285/10000\n",
            "130/132 [============================>.] - ETA: 0s - loss: 0.3523 - accuracy: 0.9251 - precision_1: 0.9319 - recall_1: 0.9200\n",
            "Epoch 285: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 11ms/step - loss: 0.3512 - accuracy: 0.9253 - precision_1: 0.9325 - recall_1: 0.9202 - val_loss: 1.7815 - val_accuracy: 0.5772 - val_precision_1: 0.5870 - val_recall_1: 0.5691\n",
            "Epoch 286/10000\n",
            "126/132 [===========================>..] - ETA: 0s - loss: 0.3413 - accuracy: 0.9349 - precision_1: 0.9382 - recall_1: 0.9323\n",
            "Epoch 286: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3374 - accuracy: 0.9359 - precision_1: 0.9396 - recall_1: 0.9334 - val_loss: 1.8989 - val_accuracy: 0.5650 - val_precision_1: 0.5768 - val_recall_1: 0.5650\n",
            "Epoch 287/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.2732 - accuracy: 0.9468 - precision_1: 0.9516 - recall_1: 0.9457\n",
            "Epoch 287: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.2715 - accuracy: 0.9471 - precision_1: 0.9524 - recall_1: 0.9461 - val_loss: 2.1202 - val_accuracy: 0.4939 - val_precision_1: 0.4958 - val_recall_1: 0.4837\n",
            "Epoch 288/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.2056 - accuracy: 0.9635 - precision_1: 0.9670 - recall_1: 0.9604\n",
            "Epoch 288: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.2063 - accuracy: 0.9629 - precision_1: 0.9662 - recall_1: 0.9598 - val_loss: 2.3086 - val_accuracy: 0.5650 - val_precision_1: 0.5696 - val_recall_1: 0.5569\n",
            "Epoch 289/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.2289 - accuracy: 0.9599 - precision_1: 0.9623 - recall_1: 0.9573\n",
            "Epoch 289: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.2287 - accuracy: 0.9598 - precision_1: 0.9622 - recall_1: 0.9568 - val_loss: 2.0545 - val_accuracy: 0.5508 - val_precision_1: 0.5569 - val_recall_1: 0.5467\n",
            "Epoch 290/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.2815 - accuracy: 0.9438 - precision_1: 0.9501 - recall_1: 0.9402\n",
            "Epoch 290: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.2837 - accuracy: 0.9431 - precision_1: 0.9496 - recall_1: 0.9395 - val_loss: 2.6618 - val_accuracy: 0.4756 - val_precision_1: 0.4765 - val_recall_1: 0.4736\n",
            "Epoch 291/10000\n",
            "127/132 [===========================>..] - ETA: 0s - loss: 0.2866 - accuracy: 0.9438 - precision_1: 0.9470 - recall_1: 0.9381\n",
            "Epoch 291: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.2838 - accuracy: 0.9451 - precision_1: 0.9482 - recall_1: 0.9395 - val_loss: 2.2922 - val_accuracy: 0.5000 - val_precision_1: 0.5041 - val_recall_1: 0.4959\n",
            "Epoch 292/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.3075 - accuracy: 0.9417 - precision_1: 0.9452 - recall_1: 0.9344\n",
            "Epoch 292: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3054 - accuracy: 0.9420 - precision_1: 0.9455 - recall_1: 0.9349 - val_loss: 1.9918 - val_accuracy: 0.5163 - val_precision_1: 0.5199 - val_recall_1: 0.5041\n",
            "Epoch 293/10000\n",
            "130/132 [============================>.] - ETA: 0s - loss: 0.3231 - accuracy: 0.9349 - precision_1: 0.9427 - recall_1: 0.9287\n",
            "Epoch 293: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.3221 - accuracy: 0.9349 - precision_1: 0.9427 - recall_1: 0.9288 - val_loss: 2.4341 - val_accuracy: 0.4919 - val_precision_1: 0.5000 - val_recall_1: 0.4858\n",
            "Epoch 294/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.2337 - accuracy: 0.9644 - precision_1: 0.9678 - recall_1: 0.9623\n",
            "Epoch 294: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 11ms/step - loss: 0.2337 - accuracy: 0.9644 - precision_1: 0.9678 - recall_1: 0.9624 - val_loss: 2.6696 - val_accuracy: 0.5061 - val_precision_1: 0.5083 - val_recall_1: 0.4980\n",
            "Epoch 295/10000\n",
            "128/132 [============================>.] - ETA: 0s - loss: 0.3097 - accuracy: 0.9359 - precision_1: 0.9412 - recall_1: 0.9339\n",
            "Epoch 295: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 2s 12ms/step - loss: 0.3114 - accuracy: 0.9359 - precision_1: 0.9411 - recall_1: 0.9339 - val_loss: 1.8490 - val_accuracy: 0.5549 - val_precision_1: 0.5600 - val_recall_1: 0.5407\n",
            "Epoch 296/10000\n",
            "129/132 [============================>.] - ETA: 0s - loss: 0.2410 - accuracy: 0.9550 - precision_1: 0.9598 - recall_1: 0.9499\n",
            "Epoch 296: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 8ms/step - loss: 0.2405 - accuracy: 0.9553 - precision_1: 0.9599 - recall_1: 0.9497 - val_loss: 2.1340 - val_accuracy: 0.4837 - val_precision_1: 0.4866 - val_recall_1: 0.4797\n",
            "Epoch 297/10000\n",
            "131/132 [============================>.] - ETA: 0s - loss: 0.2365 - accuracy: 0.9573 - precision_1: 0.9591 - recall_1: 0.9542\n",
            "Epoch 297: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.2364 - accuracy: 0.9573 - precision_1: 0.9591 - recall_1: 0.9542 - val_loss: 2.1846 - val_accuracy: 0.5386 - val_precision_1: 0.5419 - val_recall_1: 0.5386\n",
            "Epoch 298/10000\n",
            "132/132 [==============================] - ETA: 0s - loss: 0.2232 - accuracy: 0.9614 - precision_1: 0.9641 - recall_1: 0.9568\n",
            "Epoch 298: val_accuracy did not improve from 0.64024\n",
            "132/132 [==============================] - 1s 9ms/step - loss: 0.2232 - accuracy: 0.9614 - precision_1: 0.9641 - recall_1: 0.9568 - val_loss: 2.1745 - val_accuracy: 0.4919 - val_precision_1: 0.4948 - val_recall_1: 0.4837\n",
            "Epoch 299/10000\n",
            "130/132 [============================>.] - ETA: 0s - loss: 0.2928 - accuracy: 0.9395 - precision_1: 0.9466 - recall_1: 0.9369"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense,Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.regularizers import l2\n",
        "\n",
        "\n",
        "\n",
        "# Assuming y_train is your target variable\n",
        "y_train_one_hot = to_categorical(y_train, num_classes=3)\n",
        "y_test_one_hot = to_categorical(y_test, num_classes=3)\n",
        "\n",
        "# Create a Sequential model\n",
        "model = Sequential()\n",
        "model.add(LSTM(512, input_shape=(backcandles, 27),kernel_regularizer=l2(0.2),activity_regularizer=l2(0.2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3, activation=\"softmax\"))\n",
        "\n",
        "\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy',metrics=['accuracy', metrics.Precision(), metrics.Recall()])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=1000, verbose=1)\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "\n",
        "\n",
        "model.fit(x=X_train, y=y_train_one_hot, batch_size=15, epochs=10000, shuffle=True, validation_data=(X_test, y_test_one_hot), callbacks=[early_stopping, model_checkpoint])\n",
        "\n",
        "# Loading the best weights\n",
        "model.load_weights('best_model.h5')\n",
        "\n",
        "# Making predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Print precision, recall, and F1-score for each class\n",
        "print(classification_report(np.argmax(y_test_one_hot, axis=1), y_pred_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0tQp_XB-VXc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyP5Ke0OCFpwI/JT6RQspIo9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}